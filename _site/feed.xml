<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>高傲的电工李</title>
    <description>欢迎来到我的个人博客</description>
    <link>https://wenboli-cn-de.github.io/</link>
    <atom:link href="https://wenboli-cn-de.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 30 Jun 2023 16:22:24 +0200</pubDate>
    <lastBuildDate>Fri, 30 Jun 2023 16:22:24 +0200</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>机器学习 Machine Learning - Neural Networks 神经网络</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;neural-networks-神经网络&quot;&gt;Neural Networks 神经网络&lt;/h1&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

We will learn today…

- What a (deep) neural network is&lt;br /&gt;
-  How do we train it?&lt;br /&gt;
-  … which requires a calculus refresher ☺&lt;br /&gt;
-  Why is everybody talking about it?&lt;br /&gt;
-  Various ways to accelerate gradient descent&lt;br /&gt;
-  Practical tips and tricks for training NNs
  
    &lt;/div&gt;

    &lt;div style=&quot;width: 50%;&quot;&gt;

我们今天将学习以下内容：&lt;br /&gt;
&lt;br /&gt;
- 什么是（深度）神经网络&lt;br /&gt;
- 如何训练神经网络？&lt;br /&gt;
- 这需要温习一下微积分 ☺&lt;br /&gt;
- 为什么大家都在谈论它？&lt;br /&gt;
- 加速梯度下降的各种方法&lt;br /&gt;
- 训练神经网络的实际技巧和诀窍&lt;br /&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

Today‘s Agenda!&lt;br /&gt;
&lt;br /&gt;
-  What is a Neuron?&lt;br /&gt;
-  Architectures and Activation Functions&lt;br /&gt;
-  Loss-functions&lt;br /&gt;
-  Backpropagation and the Chain Rule&lt;br /&gt;
-  Computation graphs&lt;br /&gt;
&lt;br /&gt;
Advanced Topics:
- Accelerating gradient descent
- Regularization in Neural Networks
- Practical considerations
  
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

今天的议程如下：&lt;br /&gt;
&lt;br /&gt;
- 什么是神经元？&lt;br /&gt;
- 架构和激活函数&lt;br /&gt;
- 损失函数&lt;br /&gt;
- 反向传播和链式法则&lt;br /&gt;
- 计算图&lt;br /&gt;
&lt;br /&gt;
深入话题:&lt;br /&gt;
- 加速梯度下降&lt;br /&gt;
- 神经网络中的正则化&lt;br /&gt;
- 实际考虑因素&lt;br /&gt;
  
    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;biological-inspiration-the-brain-生物学灵感大脑&quot;&gt;Biological Inspiration: The brain 生物学灵感：大脑&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;A neuron is the basic computational unit of the brain:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;神经元是大脑的基本计算单元：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144017.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our brain has ~ 1011 neurons&lt;/li&gt;
  &lt;li&gt;Each neuron is connected to ~ 104 other neurons (via synapses)&lt;/li&gt;
  &lt;li&gt;Synapses have different connectivity&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Approx. model: Input impulses are weighted by synapse strength and added up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;我们的大脑有大约10^11个神经元。&lt;/li&gt;
  &lt;li&gt;每个神经元通过大约10^4个突触连接到其他神经元。&lt;/li&gt;
  &lt;li&gt;突触具有不同的连接方式。&lt;/li&gt;
  &lt;li&gt;近似模型：输入脉冲通过突触的强度加权并相加。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Neurons receive input signals and accumulate voltage. After some threshold they will fire spiking responses (highly non-linear response).&lt;/p&gt;

&lt;p&gt;神经元接收输入信号并积累电压。 在达到某个阈值后，它们将激发尖峰响应（高度非线性响应）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144249.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;artificial-neurons-人工神经元&quot;&gt;Artificial Neurons 人工神经元&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;For neural nets, we use a much simpler unit (neuron, perceptron):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于神经网络，我们使用更简单的单元（神经元、感知器）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

3 ingredients:
- Weighting of the input
- Summation
- Non-linear activation function
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;
    
三个要素：
- 输入的加权
- 总和计算
- 非线性激活函数
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Example we already know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logistic regression 逻辑回归&lt;/li&gt;
&lt;/ul&gt;

\[y=\sigma\left(\mathbf{w}^T \mathbf{x}+b\right)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;feedforward-neural-networks-前馈神经网络&quot;&gt;Feedforward Neural Networks 前馈神经网络&lt;/h3&gt;

&lt;p&gt;Building a network:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We can connect lots of units
together into a directed acyclic
graph.&lt;/li&gt;
  &lt;li&gt;This gives a feed-forward
neural network. That’s in
contrast to recurrent neural
networks, which can have
cycles.&lt;/li&gt;
  &lt;li&gt;Typically, units are grouped
together into layers.&lt;/li&gt;
  &lt;li&gt;Each layer connects N input units to M output units.&lt;/li&gt;
  &lt;li&gt;In the simplest case, all input units are connected to all output units. We call this a fully
connected layer.&lt;/li&gt;
  &lt;li&gt;Note: the inputs and outputs for a layer are distinct from the inputs and outputs to the network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;构建一个网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们可以将很多单元连接在一起形成一个有向无环图。&lt;/li&gt;
  &lt;li&gt;这就得到了一个前馈神经网络。与循环神经网络形成对比，后者可以有循环。&lt;/li&gt;
  &lt;li&gt;通常，单元被分组成层。&lt;/li&gt;
  &lt;li&gt;每一层将N个输入单元连接到M个输出单元。&lt;/li&gt;
  &lt;li&gt;在最简单的情况下，所有输入单元都连接到所有输出单元。我们称之为全连接层。&lt;/li&gt;
  &lt;li&gt;注意：层的输入和输出与网络的输入和输出是不同的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I.e., each layer has a M x N weight matrix W&lt;/li&gt;
  &lt;li&gt;Equation in matrix form: $\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;Output units are a function of input units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Feedforward neural networks are also often called multi-layer perceptrons (MLPs)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;每一层具有一个大小为M x N的权重矩阵W。&lt;/li&gt;
  &lt;li&gt;以矩阵形式的方程为：$\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;输出单元是输入单元的函数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;前馈神经网络通常也被称为多层感知器（MLP）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145355.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;activation-funcitons-激活函数&quot;&gt;Activation funcitons 激活函数&lt;/h3&gt;

&lt;p&gt;Different activation functions for introducing non-linearities:
引入非线性的不同激活函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145629.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[\sigma(x)=\frac{1}{1+\exp (-x)}\]

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[0,1]&lt;/li&gt;
  &lt;li&gt;从历史上来看它们非常流行，因为它们可以很好地解释为神经元的饱和“发射率”
    &lt;blockquote&gt;
      &lt;p&gt;常用的激活函数（如Sigmoid函数）在输入值较大或较小的情况下会饱和，即输出值接近0或1，并具有类似于神经元发射的特性。因此，这些激活函数的输出值可以被解释为神经元的饱和“发射率”。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和的神经元会使得梯度消失&lt;/li&gt;
  &lt;li&gt;Sigmoid函数的输出不以零为中心（对于初始化很重要）&lt;/li&gt;
  &lt;li&gt;exp()计算耗费资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150009.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[-1,1]&lt;br /&gt;
✓ 以零为中心（很好）&lt;br /&gt;
× 当饱和时仍然会消失梯度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;修正线性单元（Rectified Linear Unit，ReLU）&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和（在正区间内）&lt;br /&gt;
✓ 计算效率非常高&lt;br /&gt;
✓ 在实践中比sigmoid/tanh函数收敛速度快得多（例如，快6倍）&lt;/p&gt;

&lt;p&gt;× 输出不以零为中心&lt;br /&gt;
× 对于x &amp;lt; 0没有梯度&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152248.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0.1 x, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和&lt;br /&gt;
✓ 计算效率高&lt;br /&gt;
✓ 在实践中收敛速度比sigmoid/tanh函数快很多！（例如，6倍）&lt;br /&gt;
✓ 不会“消失”&lt;/p&gt;

&lt;p&gt;Parametric Rectifier (PReLu):&lt;br /&gt;
参数整流器 (PReLu)：&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (\alpha x, x)$&lt;/p&gt;

&lt;p&gt;Also learn alpha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;指数线性单元&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[f(x)= \begin{cases}x &amp;amp; \text { if } x&amp;gt;0 \\ \alpha(\exp (x)-1) &amp;amp; \text { if } x \leq 0\end{cases}\]

&lt;p&gt;其中，alpha是一个预定义的常数，通常取一个较小的正数。&lt;/p&gt;

&lt;p&gt;✓ 具有ReLU的所有优点&lt;br /&gt;
✓ 输出接近零均值&lt;br /&gt;
× 计算过程中需要使用exp()函数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In practice:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用ReLU。在学习率和初始化时要小心。
    &lt;blockquote&gt;
      &lt;p&gt;对于学习率（learning rate），选择一个合适的值非常重要。过大的学习率可能导致训练不稳定或发散，而过小的学习率可能导致收敛速度过慢。&lt;/p&gt;

      &lt;p&gt;对于初始化（initialization），权重和偏置的初始值也需要谨慎选择。使用不合适的初始化方法可能导致梯度消失或梯度爆炸等问题，影响网络的训练效果。对于使用ReLU的网络，一种常见的初始化方法是使用较小的随机值，如从均匀分布或正态分布中采样得到的值。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;尝试使用Leaky ReLU / ELU。&lt;/li&gt;
  &lt;li&gt;尝试使用tanh函数，但不要期望太多。&lt;/li&gt;
  &lt;li&gt;不要使用sigmoid函数。
    &lt;ul&gt;
      &lt;li&gt;sigmoid函数仅在分类问题的输出激活中使用。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Formalisation:&lt;/p&gt;

&lt;p&gt;每层计算一个函数，因此网络计算函数的组合：&lt;/p&gt;

\[\begin{aligned}
\mathbf{h}^{(1)} &amp;amp; =f^{(1)}(\mathbf{x}) \\
\mathbf{h}^{(2)} &amp;amp; =f^{(2)}\left(\mathbf{h}^{(1)}\right) \\
\vdots &amp;amp;
\end{aligned}\]

&lt;p&gt;或者更简单地：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \mathbf{y}=f^{(L)}\left(\mathbf{h}^{(L-1)}\right) \\
&amp;amp; \mathbf{y}=f^L \circ f^{L-1} \circ \ldots f^{(1)}(\mathbf{x})
\end{aligned}\]

&lt;p&gt;神经网络提供模块化：我们可以将每一层的计算实现为一个黑盒子&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614154844.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-xor-异或&quot;&gt;Example: XOR 异或&lt;/h4&gt;

&lt;p&gt;设计一个实现 XOR 的网络：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161308.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单个单元无法计算!&lt;/li&gt;
  &lt;li&gt;经典的例子，为什么我们需要多层次&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;XOR in terms of elemental operations:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;XOR(a,b) = (a OR b) AND NOT (a AND b)&lt;/p&gt;

&lt;p&gt;设计一个实现XOR的网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;激活函数的硬阈值，x1和x2是二进制的&lt;/li&gt;
  &lt;li&gt;h1 计算 x1 OR x2&lt;/li&gt;
  &lt;li&gt;h2 计算 x1 AND x2&lt;/li&gt;
  &lt;li&gt;y 计算 h1 AND NOT h2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-architectures深层架构&quot;&gt;Deep Architectures深层架构&lt;/h3&gt;

&lt;p&gt;为什么我们需要深入？&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;任何线性层序列都可以用单个线性层等效地表示&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{y}=\underbrace{\mathbf{W}^{(3)} \mathbf{W}^{(2)} \mathbf{W}^{(1)}}_{\tilde{\mathbf{W}}} \mathbf{x}\]

&lt;p&gt;即，我们需要非线性，以利用多个层次&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;具有非线性激活函数的FF-NN是通用函数近似器：
    &lt;ul&gt;
      &lt;li&gt;给定一个潜在的无限量的单元，它们可以任意地逼近任何函数&lt;/li&gt;
      &lt;li&gt;通用函数逼近定理： 单层就足以实现 “普适性”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;那么，单层是否足够？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;尽管通用函数逼近定理表示单层理论上足够，但实际上我们需要指数级（与输入维度成正比）的神经元数量才能实现这一点。
    &lt;ul&gt;
      &lt;li&gt;如果可以学习任何函数，那么结果很可能会过拟合。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;相反，多层网络可以用更少的神经元实现类似的效果。
    &lt;ul&gt;
      &lt;li&gt;紧凑的表示方式比”通用表示”更有效。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-损失函数&quot;&gt;Loss-functions 损失函数&lt;/h2&gt;

&lt;p&gt;训练神经网络的目标函数：&lt;/p&gt;

&lt;p&gt;通用的机器学习方法：逐样本损失 + 正则化惩罚&lt;/p&gt;

\[\boldsymbol{\theta}^*=\underset{\text { parameters } \boldsymbol{\theta}}{\arg \min } \sum_{i=1}^N l\left(\boldsymbol{x}_i, \boldsymbol{\theta}\right)+\lambda \text { penalty }(\boldsymbol{\theta})\]

&lt;p&gt;对于不同的任务，损失函数和输出激活函数的选择有所不同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;回归任务（Regression）：通常使用均方误差（Mean Squared Error）作为损失函数，输出激活函数可以是线性函数或恒等函数。&lt;/li&gt;
  &lt;li&gt;二分类任务（Binary Classification）：常见的损失函数包括二元交叉熵（Binary Cross-Entropy）或对数损失（Log Loss），输出激活函数通常选择sigmoid函数。&lt;/li&gt;
  &lt;li&gt;多类别分类任务（Multi-class Classification）：常用的损失函数是多类别交叉熵（Categorical Cross-Entropy），输出激活函数则通常选择softmax函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Regression 回归&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\boldsymbol{b}^{(L)}
$$

&lt;b&gt;Loss：&lt;/b&gt;

squared error 方差

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\frac{1}{2}\left(\mathbf{f}\left(\mathbf{x}_i\right)-\mathbf{y}_i\right)^2
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

linear Gaussian

$$
p(\mathbf{y} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}, \mathbf{\Sigma}\right)
$$

&lt;br /&gt;

negative log-likelihood 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\log \mathcal{N}\left(\mathbf{y}_i \mid \boldsymbol{\mu}\left(\mathbf{x}_i\right), \boldsymbol{\Sigma}\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Binary classification 二元分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
f=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

hinge-loss 铰链损失

$$
l\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\max \left(0,1-y_i f\left(\boldsymbol{x}_i\right)\right)
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
f=\sigma\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
\begin{aligned}
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)= &amp;amp; -c_i \log f\left(\mathbf{x}_i\right)-\left(1-c_i\right) \log \left(1-f\left(\mathbf{x}_i\right)\right)
\end{aligned}
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中$y_i$是 -1/+1 labels, $c_i$ 是0/1 labels。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-class classification 多类别分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

Multi-class SVM loss 多类 SVM 损失&lt;br /&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
 Not covered
&lt;/div&gt;

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
\mathbf{f}=\operatorname{softmax}\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\sum_{k=1}^K \boldsymbol{h}_{c_i, k} \log y_k\left(\mathbf{x}_i\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中 $\boldsymbol{h}_{c_i, k}$ 是 one hot coding&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;One-hot encoding是一种常用的数据预处理技术，用于将离散特征表示为二进制向量的形式。它常用于机器学习和深度学习任务中，特别是当特征数据中包含分类变量时。&lt;/p&gt;

  &lt;p&gt;在One-hot encoding中，如果一个特征具有n个不同的类别，那么它将被表示为一个长度为n的二进制向量，其中只有一个位置为1，其他位置都为0。被设置为1的位置对应于该特征所属的类别。&lt;/p&gt;

  &lt;p&gt;这样的编码方式有助于解决以下问题：&lt;/p&gt;

  &lt;p&gt;解决分类变量的数值化问题：分类变量通常无法直接用于机器学习算法，因为算法通常期望输入是数值型数据。One-hot encoding可以将分类变量转换为数值型数据，使其适用于算法的处理。&lt;/p&gt;

  &lt;p&gt;避免特征之间的顺序关系：One-hot encoding将每个类别都独立地表示为一个二进制向量，不考虑类别之间的顺序关系。这在一些情况下是有益的，例如避免算法错误地学习到类别之间的顺序或大小关系。&lt;/p&gt;

  &lt;p&gt;需要注意的是，当原始特征具有大量类别时，One-hot encoding会导致特征空间的维度增加，可能会导致稀疏矩阵和计算资源的浪费。在处理高维稀疏数据时，可能需要考虑其他的特征编码方法。&lt;/p&gt;

  &lt;p&gt;在实践中，可以使用多种编程语言和库来执行One-hot encoding，例如Python中的scikit-learn、pandas和TensorFlow等。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Feature Learning 特征学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;神经网络可以被看作是一种学习特征的方式&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;最后一层是标准的线性回归/分类层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络学习特征$\psi(\mathbf{x})$使得线性回归/分类可以解决它&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165612.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165623.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</guid>
        
        <category>机器学习</category>
        
        
      </item>
    
      <item>
        <title>工程力学-动力学/Technische Mechanik IV – Dynamik - Integration der Eulerschen Gleichungen 欧拉方程的积分</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;integration-der-eulerschen-gleichungen-欧拉方程的积分&quot;&gt;Integration der Eulerschen Gleichungen 欧拉方程的积分&lt;/h1&gt;

&lt;p&gt;EULERSCHE Kreiselgleichungen 欧拉陀螺仪方程&lt;/p&gt;

&lt;p&gt;Eulersche Gleichungen beschreiben allgemeine Bewegung eines starren Körpers mit einem fixen Punkt.欧拉方程描述了具有固定点的刚体的一般运动。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162403.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Das Problem der analytischen Lösung dieser Gleichungen hat Wissenschaftler weit über 100 Jahre intensiv beschäftigt. Am Ende hat sich herausgestellt, dass es nur drei Fälle gibt, in denen diese Gleichungen vollständig lösbar sind. (Natürlich numerische Näherungslösung ist immer möglich). Die Nichtintegrierbarkeit dieser Gleichungen wurde ähnlich wir beim Dreikörperproblem auf die fundamentale Arbeiten vom französischen Mathematiker Henry Poincare Ende des XIX Jahrhundert zurückgeführt. Die drei Fälle der Integrierbarkeit werden nach ihren Erfinder genannt&lt;/p&gt;

&lt;p&gt;100 多年来，这些方程的解析解问题一直困扰着科学家们。 最后发现只有三种情况可以完全求解这些方程。  （当然，数值近似总是可能的）。 与三体问题类似，这些方程的不可积性问题可以追溯到19世纪末法国数学家亨利庞加莱的基础工作。 可积性的三种情况以其发明者的名字命名&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162341.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Der einfachste Falls wurde von Euler untersucht und beschäftigt sich mit einem Körper in der Situation, wo das resultierende Moment aller äußerer Kräfte verschwindet (gleich null ist). Dieser Fall wird realisiert, wenn ein schwerer Kreisel sich im homogenen Schwerekraft (z.B. der Erde befindet) und in seinem Schwerpunkt fixiert wird, d.h. der Aufhänge punkt befindet sich im Schwerpunkt des Körpers. In diesem Fall vereinfachen sich die Bewegungsgleichungen:&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-kreisel-der-eulersche-fall-陀螺仪&quot;&gt;Kräftefreier Kreisel (Der Eulersche Fall) 陀螺仪&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163321.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种最简单的情况是由欧拉研究的，涉及到一个物体在所有外力产生的力矩之和为零的情况。这种情况在一个重质量陀螺仪位于均匀重力场（例如地球）并且被固定在其质心的情况下实现，也就是悬挂点位于物体的质心。在这种情况下，运动方程变得更简化：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;Zunächst wird der einfachste Fall eines symmetrischen Körpers behandelt. In diesem Fall
können die Gleichungen in elementaren Funktionen integriert werden:&lt;/p&gt;

&lt;p&gt;首先，处理对称体的最简单情况。 在这种情况下，方程可以集成为初等函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; J_{11}=J_{22}=A ; \quad J_{33}=C \\
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0
\end{aligned}\]

&lt;h2 id=&quot;kräftefreier-symmetrischer-kreisel-kinetik-没有外力作用具有对称性的陀螺&quot;&gt;Kräftefreier symmetrischer Kreisel. Kinetik 没有外力作用、具有对称性的陀螺&lt;/h2&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0 \quad \dot{\omega}_3=0 \rightarrow \quad \omega_3=\omega_{30}=\text { konst } \\
&amp;amp; \left\{\begin{array}{l}
\dot{\omega}_1+\omega_2 \omega_{30} \frac{C-A}{A}=0 \\
\dot{\omega}_2-\omega_1 \omega_{30} \frac{C-A}{A}=0
\end{array} \rightarrow \quad \ddot{\omega}_2=\dot{\omega}_1 \omega_{30} \frac{C-A}{A}=-\omega_1\left(\omega_{30} \frac{C-A}{A}\right)^2\right. \\
&amp;amp; \ddot{\omega}_2+\left(\omega_{30} \frac{C-A}{A}\right)^2 \omega_2=0 \quad \rightarrow \quad \omega_2=\omega_0 \sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\frac{A}{C-A} \frac{1}{\omega_{30}} \dot{\omega}_2=\frac{A}{C-A} \frac{1}{\omega_{30}} \omega_0 \omega_{30} \frac{C-A}{A} \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\omega_0 \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Damit sind die Komponenten der Winkelgeschwindigkeit vollständig bestimmt.
Es bleiben die kinematischen Gleichungen zur Bestimmung der Eulerschen Winkel als
Funktionen der Zeit.&lt;br /&gt;
角速度的分量因此被完全确定。 用于确定作为时间函数的欧拉角的运动学方程仍然存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Geometrische Interpretation: Innerhalb des Körpers umläuft der Vektor der Winkelgeschwindigkeit einen Kreis. Die Umlaufgeschwindigkeit hängt von den Anfangsbedingungen und der Verhältnis der Massenträgheits-momente des Körpers ab.&lt;br /&gt;几何解释：在物体内部，角速度的矢量绕着一个圆旋转。旋转速度取决于初始条件和物体的转动惯量之比。&lt;/p&gt;

\[\Omega_{\text {Umlauf }}=\omega_{30} \frac{C-A}{A}\]

&lt;p&gt;Ermittlung &lt;strong&gt;kinematischer Größen&lt;/strong&gt; wird möglich, wenn wir beachten, dass die Zeitableitung des Drehmomentes im raumfesten Bezugssystem in Abwesenheit des äußeren Momentes gleich null ist.&lt;br /&gt;当我们注意到在没有外部力矩的情况下，相对于固定空间参考系的力矩的时间导数为零时，我们就可以确定&lt;strong&gt;运动学量&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“kinematische Größen” 指的是描述物体运动的量，而不考虑所受到的力或力矩的影响。它们通常包括位置、速度、加速度和角度等物理量。运动学是研究物体运动的分支，主要关注物体的运动状态和其随时间的变化，而不涉及导致这些变化的具体力量或力矩。因此，kinematische Größen 是用来描述物体运动的量，从而提供关于物体位置、速度和加速度等方面的信息。&lt;/p&gt;
&lt;/blockquote&gt;

\[\frac{ {\quad}^I d \vec{L}^{(s)}}{d t}=\overrightarrow{0} \quad \rightarrow \quad \vec{L}^{(s)}=\text { konst }\]

&lt;p&gt;Dies bedeutet, dass der Drall-Vektor in seiner Richtung und betrag konstant bleibt. Wählen wir die raumfesten Koordinaten so, dass der Basisvektor entlang des Drall i3 -Vektors gerichtet ist:&lt;br /&gt;这意味着扭曲矢量的方向和大小保持不变。 让我们选择空间固定坐标，使基本向量沿着扭曲 i3 向量定向：&lt;/p&gt;

\[\vec{L}^{(S)}=L\vec{i}_{\text{3}}\]

&lt;p&gt;Anderseits gilt (vgl. Vorlesung 2, Folie 10):
另一方面（参见第 2 讲，幻灯片 10）：&lt;/p&gt;

\[\vec{L}^{(S)}=\vec{\vec{J}}^{(S)}\cdot{}^I\vec{\omega}^K=A\omega_1\vec{e}_1+A\omega_2\vec{e}_2+C\omega_3\vec{e}_3\]

&lt;p&gt;Aus der Definition der Euler-Winkeln folgt dann: &lt;br /&gt;根据欧拉角的定义，可以得出：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;C\omega_3=L\cos\theta \\
&amp;amp;A\omega_1 =L\sin\theta\sin\varphi  \\
&amp;amp;A\omega_2 =L\sin\theta\cos\varphi 
\end{aligned}\]

&lt;p&gt;Hinweis: Drehung um $\psi$ verändert den Drall-Vektor nicht.&lt;br /&gt;注意：关于$\psi$的旋转不会改变扭曲向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Daraus folgt sofort:&lt;/p&gt;

\[\begin{aligned}
&amp;amp; C \omega_3=L \cos \theta \rightarrow \quad \cos \theta=\frac{C \omega_3}{L}=\frac{C \omega_{30}}{L}=\text { konst } \\
&amp;amp; \theta=\theta_0=\arccos \left(\frac{C \omega_{30}}{L}\right) \\
&amp;amp; \left.\begin{array}{l}
A \omega_1=L \sin \theta \sin \varphi \\
A \omega_2=L \sin \theta \cos \varphi
\end{array}\right\} \\
&amp;amp; \rightarrow \tan \varphi=\frac{\omega_1}{\omega_2}=\frac{\cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}{\sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}=\cot \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \varphi=\frac{\pi}{2}-\omega_{30} \frac{C-A}{A} t+\alpha_0 ; \quad \dot{\varphi}=-\omega_{30} \frac{C-A}{A}=\text { konst } \\
&amp;amp; \dot{\psi} \cos \theta+\dot{\varphi}=\omega_{30} \quad \rightarrow \quad \dot{\psi} \frac{C \omega_{30}}{L}-\omega_{30} \frac{C-A}{A}=\omega_{30} \\
&amp;amp; \dot{\psi} \frac{C}{L}-\frac{C-A}{A}=1 \quad \rightarrow \quad \dot{\psi}=\frac{L}{A}=\text { konst } \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Nutationskegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;自旋轴&lt;/strong&gt;相对于固定空间的进动轴所形成的圆锥。这个圆锥的顶点位于陀螺体的自旋轴上，而圆锥的轴线则与进动轴重合。由于陀螺体的自旋轴会绕着进动轴进行进动，所以形成了这个进动圆锥。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 意味着这个进动圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着进动圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Nutationskegel” 指的是固定在空间中的进动圆锥，用于描述陀螺体或旋转物体的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Spurkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;迹点（运动轨迹上的点）&lt;/strong&gt;相对于固定空间的运动形成的圆锥。这个圆锥的顶点位于迹点所在的位置，而圆锥的轴线则与迹点在空间中的运动方向相对应。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 表示这个迹圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着迹圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Spurkegel” 指的是固定在空间中的迹圆锥，用于描述陀螺体或旋转物体迹点的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Polkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;极轴&lt;/strong&gt;所形成的圆锥。这个圆锥的顶点位于极轴所在的位置，而圆锥的轴线则与极轴重合。&lt;/p&gt;

  &lt;p&gt;“Körperfester” 表示这个极锥是相对于陀螺体自身来定义和测量的，而不是相对于外部空间。这意味着极锥的方向和位置随着陀螺体的运动而变化，取决于陀螺体自身的姿态和旋转状态。&lt;/p&gt;

  &lt;p&gt;因此，”Körperfester Polkegel” 指的是固定在陀螺体自身的极锥，用于描述陀螺体的旋转特性和姿态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;geometrische-interpretation-几何解释&quot;&gt;Geometrische Interpretation 几何解释&lt;/h3&gt;

&lt;p&gt;Der Körper dreht sich mit konstanter Geschwindigkeit $\dot{\varphi}$ um seine Hauptachse $\overrightarrow{e_{3}}$.&lt;/p&gt;

&lt;p&gt;Diese Achse selbst dreht sich mit konstanter Geschwindigkeit $\vec{i}_3$ um die raumfeste Achse, d.h. um den Drall-Vektor $\dot{\psi}$.&lt;/p&gt;

&lt;p&gt;Diese Bewegung wird als reguläre freie Präzession bezeichnet.&lt;/p&gt;

&lt;p&gt;物体以恒定速度 $\dot{\varphi}$ 绕其主轴 $\overrightarrow{e_{3}}$ 自转。&lt;/p&gt;

&lt;p&gt;这个轴本身以恒定速度 $\vec{i}_3$ 绕固定轴旋转，即绕着进动矢量 $\dot{\psi}$。&lt;/p&gt;

&lt;p&gt;这种运动被称为规则的自由进动。&lt;/p&gt;

\[\left.\begin{array}{l}
\dot{\psi}=\frac{L}{A} \\
\cos \theta=\frac{C \omega_{30}}{L} \\
\dot{\varphi}=-\omega_{30} \frac{C-A}{A}
\end{array}\right\}\]

\[\begin{gathered}
L=A \dot{\psi} \\
\rightarrow \quad \omega_{30}=\frac{L}{C} \cos \theta=\frac{A}{C} \dot{\psi} \cos \theta \\
\dot{\varphi}+\frac{C-A}{A} \dot{\psi} \cos \theta=0
\end{gathered}\]

&lt;p&gt;Die letzte Gleichung enthält keine Anfangsbedingungen und stellt den kinematischen Zusammenhang (vgl. Kepplersche Gesetze) dar.&lt;br /&gt;
Die Bewegung kann wie Abrollen des körperfesten Polkegels (von außen) auf dem raumfesten Spurkegel interpretiert werden. Punkte des Körpers bewegen sich auf &lt;strong&gt;Epizykloiden&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后一个方程不包含任何初始条件并表示运动学关系（参见开普勒定律）。
&lt;br /&gt;
该运动可以解释为固定体极锥（从外部）在固定空间轨道锥上的滚动。物体的点在&lt;strong&gt;外摆线&lt;/strong&gt;上移动&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613195029.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Auch hier kann die Bewegung wie Abrollen des körperfesten Polkegels (von innen) auf dem raumfesten Spurkegels interpretiert werden. Punkte des Körpers bewegen sich auf Perizykloiden&lt;br /&gt;
这里的运动也可以解释为刚体固定的极锥（从内部）在固定的迹锥上滚动。物体上的点沿着柏拉克罗侧线运动。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这句话描述了一种运动的解释，其中涉及到刚体固定的极锥和固定的迹锥之间的关系。具体而言，它提到了刚体固定的极锥从内部滚动在固定的迹锥上的过程。在这个过程中，物体上的点按照柏拉克罗侧线的路径进行运动。&lt;/p&gt;

  &lt;p&gt;“Perizykloiden”（柏拉克罗侧线）是一个几何学术语，指的是由一个固定圆与一个在其上滚动的小圆所形成的曲线。在这种描述中，物体上的点运动的路径类似于柏拉克罗侧线。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204331.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-unsymmetrischer-kreisel非对称陀螺仪&quot;&gt;Kräftefreier unsymmetrischer Kreisel.非对称陀螺仪。&lt;/h2&gt;

&lt;h3 id=&quot;der-fall-von-euler---poinsot&quot;&gt;Der Fall von Euler - Poinsot&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Euler-Poinsot陀螺，也称为Euler-Poinsot陀螺体或Euler陀螺，是一种具有特殊运动特性的刚体模型，它展示了一种被称为Euler-Poinsot情形的旋转现象。&lt;/p&gt;

  &lt;p&gt;在Euler-Poinsot情形下，刚体围绕其一个主惯性轴（也称为长轴）旋转，同时绕另外两个互相垂直的瞬时旋转轴（也称为短轴）进行进动。这种运动形式是非常特殊和复杂的，因为它涉及到刚体的自旋和进动的相互耦合。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot陀螺的运动过程中，其自旋和进动的角速度以及角动量都会发生变化。这种陀螺的稳定性和运动特性使其成为研究刚体动力学和旋转物体行为的重要示例。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot情形得名于法国数学家与物理学家Leonhard Euler和Louis Poinsot，他们在18世纪分别独立地研究和描述了这种陀螺的运动。这种情形为刚体动力学领域提供了重要的理论基础，并在许多相关学科中被广泛应用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204539.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jetzt wir der allgemeiner Fall mit drei unterschiedlichen Hauptmassenträgheitsmomenten untersucht (triaxiales Trägheitsellipsoid):&lt;/p&gt;

&lt;p&gt;现在检查具有三个不同主要质量惯性矩的一般情况（三轴惯性椭球）：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

&lt;p&gt;Zwei Integrale des Systems sind einfach zu erkennen. Das erste Integral druck die Erhaltung
der Energie des Systems aus. In diesem Fall ist das nur die kinetische Energie des Körpers.&lt;/p&gt;

&lt;p&gt;系统的两个积分很容易辨认出来。第一个积分表示系统能量的守恒。在这种情况下，它只表示物体的动能。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}-\omega_1 \omega_2 \omega_3\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}\right)=0 \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2
\end{aligned}\]

&lt;p&gt;Das zweite Integral druckt die Erhaltung des Drehimpulses aus:&lt;/p&gt;

&lt;p&gt;第二个积分表示角动量守恒：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3 J_{11}\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1 J_{22}\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1 J_{33}\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3\left(J_{11} J_{22}-J_{11} J_{33}+J_{22} J_{33}-J_{22} J_{11}+J_{33} J_{11}-J_{33} J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2\right)=0 \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \quad A \text { und } \Omega \text { sind Integrationskonstanten. }
\end{aligned}\]

&lt;p&gt;Integrationskonstanten – 积分常数&lt;/p&gt;

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：&lt;/p&gt;

\[J_{11}&amp;lt;J_{22}&amp;lt;J_{33}\]

&lt;p&gt;Aus der Definition der Parameter wird ersichtlich:&lt;/p&gt;

&lt;p&gt;参数的定义显示：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; A=\frac{A^2 \Omega^2}{A \Omega^2}=\frac{\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2}{\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}} \quad \rightarrow \quad J_{11} \leq A \leq J_{33} \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{11} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_2^2 J_{22}\left(J_{22}-J_{11}\right)+\omega_3^2 J_{33}\left(J_{33}-J_{11}\right)=A \Omega^2\left(A-J_{11}\right) \\
&amp;amp; \omega_3^2=\frac{A\left(A-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \Omega^2-\omega_2^2}_{\lambda_3^2})=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：
Analog bekommt man&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{33} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_1^2 J_{11}\left(J_{33}-J_{11}\right)+\omega_2^2 J_{22}\left(J_{33}-J_{22}\right)=A \Omega^2\left(J_{33}-A\right) \\
&amp;amp; \omega_1^2=\frac{A\left(J_{33}-A\right)}{J_{11}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(J_{33}-A\right)}{J_{22}\left(J_{33}-J_{22}\right)} \Omega^2}_{\lambda_1^2}-\omega_2^2)=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Diese Ausdrucke können wir in die letzte übriggebliebene Gleichung einsetzen:
我们可以将这些表达式代入最后剩下的等式：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \left.\begin{array}{l}
\omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right) \\
\omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{array}\right\} \\
&amp;amp; \omega_3 \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \omega_3 \omega_1= \pm \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2 J_{22}= \pm \omega_3 \omega_1\left(J_{33}-J_{11}\right) \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp;
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \frac{d \omega_2}{\sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Es wird beispielhaft der Fall $J_{22}&amp;lt;A&amp;lt;J_{33}$ untersucht. Es werden eine neue Variable und zwei neue Parameter eingeführt:&lt;/p&gt;

&lt;p&gt;在研究 $J_{22}&amp;lt;A&amp;lt;J_{33}$ 的示例情况时，引入了一个新的变量和两个新的参数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2=\lambda_1 u \\
&amp;amp; k^2=\frac{\lambda_1^2}{\lambda_3^2}=\frac{\left(J_{22}-J_{11}\right)\left(J_{33}-A\right)}{\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}&amp;lt;1 \\
&amp;amp; \frac{\lambda_1 d u}{\lambda_1 \lambda_3 \sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp; n=\lambda_3 \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}}=\Omega \sqrt{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \\
&amp;amp; =\Omega \sqrt{\frac{A\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}{J_{11} J_{22} J_{33}}}
\end{aligned}\]

&lt;p&gt;Damit kommen wir zur folgenden Lösung&lt;/p&gt;

&lt;p&gt;这给我们带来了以下解决方案&lt;/p&gt;

\[\pm n\left(t-t_0\right)=\int_0^U \frac{d u}{\sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}\]

&lt;p&gt;Weitere Transformation führt sofort zum elliptischen Integral:&lt;/p&gt;

&lt;p&gt;进一步变换立即得到椭圆积分：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; u=\sin \Phi \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{\cos \vartheta d \vartheta}{\sqrt{1-\sin ^2 \vartheta} \sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}=w(\Phi, k)
\end{aligned}\]

&lt;p&gt;Das ist das unvollständige elliptische Integral 1. Art. Sein Reziprok
führt auf elliptische Funktionen von Jakobi.&lt;/p&gt;

&lt;p&gt;这是第一类不完全椭圆积分，它的倒数导出Jakobi的椭圆函数。&lt;/p&gt;

&lt;p&gt;Definition (Legendre-Normalform) 定义（勒让德范式）&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reziprok davon wird als elliptische Amplitude bezeichnet&lt;/p&gt;

&lt;p&gt;这个的倒数称为椭圆振幅&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \rightarrow \quad \Phi(w)=a m(w)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205828.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ausgehend von dieser Funktion werden die elliptischen Funktionen
von Jacobi eingeführt:&lt;/p&gt;

&lt;p&gt;基于此函数，引入雅可比的椭圆函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \operatorname{sn}(w)=\sin \Phi=\sin (a m(w)) \\
&amp;amp; c n(w)=\cos \Phi=\cos (a m(w)) \\
&amp;amp; d n(w)=\sqrt{1-k^2 \sin ^2 \Phi}=\sqrt{1-k^2 \operatorname{sn}^2(w)}
\end{aligned}\]

&lt;p&gt;Sie werden als &lt;strong&gt;sinus amplitudinis&lt;/strong&gt;, &lt;strong&gt;cosinus amplitudinis&lt;/strong&gt; und  &lt;strong&gt;delta amplitudinis&lt;/strong&gt; bezeichnet.&lt;/p&gt;

&lt;p&gt;Diese Funktionen sind periodisch mit der Periode, die vom Parameter k abhängig ist. Die Abhängigkeit hängt mit dem kompletten elliptischen Integral zusammen:&lt;/p&gt;

&lt;p&gt;它们被称为&lt;strong&gt;正弦波&lt;/strong&gt;、&lt;strong&gt;余弦波&lt;/strong&gt;和&lt;strong&gt;三角波&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这些函数是周期性的，周期取决于参数 k。 依赖关系与完全椭圆积分有关：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; K(k)=\int_0^{\frac{\pi}{2}} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; d n(w+2 K)=d n(w) \\
&amp;amp; \operatorname{sn}(w+4 K)=\operatorname{sn}(w) \\
&amp;amp; c n(w+4 K)=c n(w) \\
&amp;amp; s n^2(w)+c n^2(w)=1
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210148.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210206.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210222.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210241.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mithilfe dieser Funktionen können wir die Komponenten der Winkelgeschwindigkeit sofort bestimmen:&lt;/p&gt;

&lt;p&gt;使用这些函数，我们可以立即确定角速度的分量：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2= \pm \lambda_1 \operatorname{sn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \sqrt{\lambda_1^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \lambda_1 \operatorname{cn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \sqrt{\lambda_3^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 \sqrt{1-k^2 s^2\left(n\left(t-t_0\right)\right)} \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 d n\left(n\left(t-t_0\right)\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Kinematische Teilaufgabe führt sofort zu einer weiteren Quadratur.
运动学子任务立即导致另一个正交。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; L \sin \varphi \sin \theta=J_{11} \omega_1 \\
&amp;amp; L \cos \varphi \sin \theta=J_{22} \omega_2 \\
&amp;amp; L \cos \theta=J_{33} \omega_3 \\
&amp;amp; \theta=\arccos \left(\frac{J_{33} \omega_3}{L}\right) \\
&amp;amp; \tan \varphi=\frac{J_{11} \omega_1}{J_{22} \omega_2} \rightarrow \quad \varphi=\arctan \left(\frac{J_{11} \omega_1}{J_{22} \omega_2}\right)
\end{aligned}\]

&lt;p&gt;Für Winkel $\varphi$ bleibt eine Differentialgleichung 1. Ordnung, die bei Bedarf integriert werden kann:&lt;/p&gt;

&lt;p&gt;角度 $\varphi$ 的一阶微分方程仍然存在，必要时可以对其进行积分：&lt;/p&gt;

\[\dot{\psi} \cos \theta+\dot{\varphi}=\omega_3 \quad \rightarrow \quad \dot{\psi}=\frac{\omega_3-\dot{\varphi}}{\cos \theta}=L \frac{J_{11} \omega_1^2+J_{11} \omega_2^2}{J_{11}^2 \omega_1^2+J_{22}^2 \omega_2^2}\]

&lt;p&gt;Der zweite Fall $J_{11}&amp;lt;A&amp;lt;J_{22}$ kann analog untersucht werden.&lt;/p&gt;

&lt;p&gt;第二种情况$J_{11}&amp;lt;A&amp;lt;J_{22}$可以类推.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Qualitativer Charakter der Bewegung:&lt;/p&gt;

&lt;p&gt;Ein rotationssymmetrischer Körper bewegt sich so, dass der Nutationswinkel konstant bleibt. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse bleiben auch konstant.&lt;/p&gt;

&lt;p&gt;Bei einem nicht rotationssymmetrischen Körper (einem dreiachsigen Ellipsoid) wird das alles gestört. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse werden zeitvariabel. Auch der Nutationswinkel wird zeitveränderlich, aber alle kinematischen Größen der Bewegung können in geschlossener Form (aber nicht in elementaren Funktionen) bestimmt werden.&lt;/p&gt;

&lt;p&gt;运动的定性特征：&lt;/p&gt;

&lt;p&gt;对于一个具有旋转对称性的物体，其运动使得进动角保持恒定。进动和自转的速度也保持恒定。&lt;/p&gt;

&lt;p&gt;然而，对于一个非旋转对称的物体（如一个三轴椭球体），这些特性会受到扰动。进动和自转的速度将随时间变化。进动角度也会随时间变化。尽管如此，运动的所有运动学量可以以闭合形式（但不是基本函数）确定&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/TM4-03/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/TM4-03/</guid>
        
        <category>工程力学</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Behavior Recognition</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/08-BehaviorRecognition/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/08-BehaviorRecognition/</guid>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Road Recognition</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/07-RoadRecognition/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/07-RoadRecognition/</guid>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - SLAM</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-6-self-localization-and-mapping&quot;&gt;Chapter 6: Self-Localization and Mapping&lt;/h1&gt;

&lt;p&gt;欢迎回到汽车视觉的第六章，我们将讨论以相机为基础的自我定位和映射的主题。&lt;/p&gt;

&lt;p&gt;自我定位和映射的主题是机器人技术和制图和地理信息学领域进行大量研究的领域。例如，在Tune Burger和Fox的《概率机器人》一书中，第七到十三章覆盖了这些主题。IEEE机器人与自动化杂志上的一篇分成几部分的同时定位和映射教程，由Duran、White和Bailey编写。你还可以在《机器人手册》中找到关于定位和映射的基础知识。&lt;/p&gt;

&lt;p&gt;另外，如果你对涵盖这些主题的德语机器人书籍感兴趣，你可能会考虑Hartsback、Lingaman和Nishta的《移动机器人：信息科学导论》。第五和六章中你可以找到这些主题。最后，Cox在1991年撰写的一篇原创论文，描述了一种用于多种情况的算法，即最近迭代点算法，这也可能是一篇有趣的论文，以了解整个领域在1990年代初如何启动。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sebastian Thrun, Wolfram Burgard, Dieter Fox, Probabilistic Robotics. MIT Press,
2005, Chapter 7-13 (partly)&lt;/li&gt;
  &lt;li&gt;Hugh Durrant-Whyte, Tim Bailey, Simultaneous Localization and Mapping: Part I,
IEEE Robotics and Automation Magazine, 13(2), pg. 99-110, 2006&lt;/li&gt;
  &lt;li&gt;Tim Bailey, Hugh Durrant-Whyte, Simultaneous Localization and Mapping: Part II,
IEEE Robotics and Automation Magazine, 13(3), pg. 108-117, 2006&lt;/li&gt;
  &lt;li&gt;Bruno Siciliano, Khatib Oussama (Hrsg.), Springer Handbook of Robotics, Springer,
2008, Chapter 37&lt;/li&gt;
  &lt;li&gt;Joachim Hertzberg, Kai Lingemann, Andreas Nüchter, Mobile Roboter – Eine
Einführung aus Sicht der Informatik, Springer 2012, Chapters 5+6&lt;/li&gt;
  &lt;li&gt;Ingemar J. Cox, Blanche – an Experiment in Guidance and Navigation of an
Autonomous Robot Vehicle. IEEE Transactions on Robots and Automation, 7(2),
pg. 193-204, 1991&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Self Localization 自定位&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自我定位领域对许多不同的应用都很重要，其中之一就是自动驾驶，其他的还包括移动机器人或甚至制图。&lt;/p&gt;

&lt;p&gt;在所有这些应用中，任务都可以通过三个元素来描述。&lt;strong&gt;第一个元素是环境的地图&lt;/strong&gt;，我们假设我们知道那张地图。在这种情况下，地图总是数字地图，也就是存储环境中相关对象位置和几何形状的数据库。对于自动驾驶车辆，这些地图可能包含道路几何形状，道路旁边的相关对象的位置，比如树木、交通灯、交通标志或房屋。它可能包含车道标线的几何形状等等。我们不知道的，但我们想要估计的是车辆的位置和方向。这对位置和方向的配对通常被称为&lt;strong&gt;车辆的姿态&lt;/strong&gt;。此外，我们假设车辆配备了能够识别本地环境元素的传感器。例如，摄像头可能识别到车道标线，或者激光雷达传感器可能识别到交通标志的柱子或树木。因此，我们想要做的是，我们想要使用这种&lt;strong&gt;本地感知&lt;/strong&gt;，并以某种方式将其与地图结合起来，以确定车辆的姿态。&lt;/p&gt;

&lt;p&gt;self localization problem 自定位问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;environment is known (map) 环境是已知的&lt;/li&gt;
  &lt;li&gt;vehicle position and orientation are unkonown 车辆位置和方向未知&lt;/li&gt;
  &lt;li&gt;vehicle observes the (local) environment 车辆观察（本地）环境&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;让我们从一个非常简单的例子开始，即足球机器人。假设你应该为一个移动机器人实现一个程序，使机器人能够踢足球。当然，对于足球机器人来说，知道它在球场上的位置，以及它在球场上的方向，是非常重要的。通常，我们知道足球场是什么样子的，我们知道球场的尺寸，我们知道球场的标线是怎么画的，所以我们可以创建一个精确描述这个场地外观的数字地图，在场地上我们找到哪些元素。假设机器人配备了一些传感器，比如一些摄像系统，感知机器人的本地环境。由这样的摄像机创建的可能的图像可以在右手边看到。所以，这展示了机器人的视角。我们可以看到足球场和场地标记，我们还可以看到其他一些对象，比如其他机器人或球之类的东西，这些对象是移动的，不是地图的一部分。&lt;/p&gt;

&lt;p&gt;所以，现在的问题是，当我们考虑机器人的这种视角时，我们能否推断出机器人当前的位置和方向。当然，作为人类，我们可以很容易地看到，我们以某种方式正朝着足球场的一个角落看去，所以我们可以推断出，我们必须位于某个区域，以某种方向看向角落。此外，我们看到一部分罚球区的标记，所以我们可以推断出，机器人位于现在在足球场上可见的这两个位置中的一个。箭头指示机器人当前朝向的方向。&lt;/p&gt;

&lt;p&gt;当然，在这种情况下，很明显有两个可能的位置，因为足球场是对称的，所以有时候我们不能确定位置，但我们仍然有几个可能的位置，机器人可能在那里，而且由于机器人的视野有限，我们不能解决这种歧义。但是，如果我们随着时间的推移跟踪自我位置，我们可能稍后能够找出我们目前位于哪个歧义的位置。所以让我们从最简单的方式开始这个自我定位的主题，即使用&lt;strong&gt;地标的定位&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612161042.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;localization-with-landmarks-地标定位&quot;&gt;Localization with landmarks 地标定位&lt;/h2&gt;

&lt;h3 id=&quot;landmarks-地标&quot;&gt;landmarks 地标：&lt;/h3&gt;

&lt;p&gt;地标是什么呢？地标是环境中的一个物体，是静态的，不会移动，我们知道它的位置，所以它必须是地图的一部分，我们必须知道那个物体的位置。此外，地标应该在机器人或车辆使用的传感器中容易识别。当然，一个典型的地标就是早期用于船只自我定位的灯塔，它们清晰可见，易于识别，它们在世界上是静态的，可以通过船上的一些光学仪器来看到，这就是一个典型的地标示例。当然，我们并不是为船只做定位任务，而是为车辆或机器人做定位任务，但你可以为移动机器人或移动车辆的自我定位假设类似的事情。例如，在路上，你可能会找到一些物体，比如交通标志或交通灯，它们在世界上是静态的，一点也不动，很容易识别，可以用来进行自我定位。&lt;/p&gt;

&lt;p&gt;现在，让我们假设我们正在处理一个二维问题，或者更准确地说，是在二维平面中自我定位的问题。&lt;/p&gt;

&lt;p&gt;那么，当我们观察到其中一个地标时，我们能得出什么结论呢？首先，假设我们的传感器能够测量到地标的距离，当我们能够确定到地标的距离时，我们能够对机器人或车辆的位置得出什么结论呢？假设我们知道地标的位置，我们可以在地图上标记出来，这是中心的红色点。我们知道我们与地标的距离，也就是说，我们可以推断出机器人必须位于蓝色圆圈上，给定的距离为半径，所以这个圆圈描述了机器人可能的所有位置。当然，只知道距离不能确定方向。&lt;/p&gt;

&lt;p&gt;假设我们正在观察两个地标，比如两个灯塔。&lt;/p&gt;

&lt;p&gt;对于每一个灯塔或地标，我们确定距离，也就是说，我们可以创建两个蓝色的圆圈，描述了车辆的可能位置。当我们观察到两个地标时，我们就知道机器人或车辆必须位于这两个圆圈的交点，也就是说，我们得到了两个可能的位置，但仍然不能确定机器人的方向。当然，我们可以继续，如果我们可以观察到三个地标，那么我们可以画出三个圆，希望所有的圆都在一个交点相交，然后我们就可以推断出这个单一的交点就是机器人的位置。&lt;/p&gt;

&lt;p&gt;consistently identifiable points in the world. E.g. lighthouses, feature points in imaging&lt;/p&gt;

&lt;p&gt;一直可以被识别的点，例如灯塔、图像中的特征点&lt;/p&gt;

&lt;p&gt;#### what can we conclude from… 2d：我们可以从…中得出什么结论 ?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the distance to a given landmark?到一个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position on a circle&lt;/li&gt;
      &lt;li&gt;unknown orientatioin&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between two landmarks?到两个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;2 possible positons&lt;/li&gt;
      &lt;li&gt;unknown orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between three landmarks?到三个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position(some exceptions are possible)机器人位置（可能有一些例外）&lt;/li&gt;
      &lt;li&gt;orientationo unknown&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162130.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，总的来说，如果我们知道距离地标的距离，我们可以确定位置，但我们不能确定方向。那么，如果我们知道我们观察的角度呢？假设我们有一个地标，我们可以确定与我们自我定位的角度，即相对于我们的机器人或车辆自我定位，我们识别到的对象的角度。&lt;/p&gt;

&lt;p&gt;答案是，经过一些数学或几何推理后，我们得出的结论是，使用单个地标，我们无法确定机器人的位置，机器人仍然可以位于二维平面上的任何点。但是，如果我们知道机器人的位置，并且我们有一个角度测量，我们可以确定机器人的方向。也就是说，如果机器人位于用蓝圈标出的点，我们在某个角度感知到地标，那么我们可以推断出机器人具有由箭头给出的某个方向。也就是说，知道我们感知到地标的角度允许我们确定机器人的方向，前提是我们知道它的位置。也就是说，对于每个可能的位置，我们得到一个不同的机器人方向。现在，让我们看看如果我们能感知到两个地标，能确定我们观察到这两个地标的角度，会发生什么。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the angle, from which a landmark is being observed 地标的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;positon unknown&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162831.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过一点点的几何知识，我们可以确定，如果我们知道这两个测量值，我们可以创建一个圆弧，我们可以推断机器人必须位于这个圆弧上。这个圆经过两个地标位置，这里用两个红点表示，我们可以推断出机器人必须位于这个圆弧的某个地方。我们还不知道具体是哪个位置，但我们已经可以将它限制在这个圆，这个圆的一部分上。当然，对于每个位置，我们又可以确定机器人的方向。这也意味着，如果我们能够观察到三个地标，并确定我们感知到地标的角度，那么我们可以创建两个或者甚至三个这样的圆弧，它们会在一个交点相交，这意味着，有了三个地标，知道对这些地标的角度，就能确定机器人的位置和机器人的方向。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the angle from which two landmarks are being observed? 两个地标之间的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;robot position on an arc or line segment 圆弧或线段上的机器人位置&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;approch: inscribed angle theorem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162950.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;linear-landmarks-线性地标&quot;&gt;linear landmarks 线性地标&lt;/h4&gt;

&lt;p&gt;我们之前讨论的是，我们可以从地图上的单点地标得出的结论，比如一个灯塔，如果我们将灯塔投影到地面上，它就是一个单点。然而，在实践中，有时候利用环境中的其他对象进行定位是有用的，这些对象并不仅仅是单点。例如，线。我们可以在足球场上找到这些线，足球场上的线，是用于自我定位非常有用的线，它们并不仅仅是单点。或者对于一个自动驾驶的车辆，我们可能想使用车道标记，或者我们可能想使用路缘石，或者某些紧挨着路边的房屋的墙壁，并使用它们作为自我定位的地标。所以问题是，如果我们可以测量到这些地标的正交距离，我们能从这些地标中得出什么结论？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;例如： roadway lines, curbs, and walls 道路线、路缘和墙壁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612163335.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;what-can-we-conclude-from-我们可以从中得出什么结论-&quot;&gt;what can we conclude from… ：我们可以从…中得出什么结论 ?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;the orthogonal distance,in which a line is being observed 观测一条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;position on two parallel lines 两条平行线&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the orthogonal distance to two lines 两条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;4 points / 2 points&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，我们假设我们知道某条线或线性地标，我们知道它的位置和它的确切几何形状，我们测量到这个地标的正交距离，想要推断我们在哪里。&lt;/p&gt;

&lt;p&gt;好吧，让我们来可视化这个。如果我们假设红线是地标，我们可以测量到一定的距离，由虚线箭头表示，那么我们可以推断出，机器人或车辆必须位于两条与红线平行的蓝线上。也就是说，我们知道，车辆或机器人位于蓝线的其中一条上，我们不知道具体是哪一条，我们也不知道它是位于上面的还是下面的，但我们仍然能够发现，它位于这些线中的一条上。当然，如果不只有一条线，而是我们可以观察到的两条线，我们可以做一些更复杂的几何推理。对于每条线，我们计算出平行线，它们与地标的距离等于我们感知到的距离，然后我们知道我们必须位于这些平行线上。如果我们考虑右手边的图，我们可以推断出，我们最终位于蓝线的四个交点之一。如果两个地标线的交角不是90度，考虑到这些我们构造的线相交的角度，我们甚至可能能够将可能的位置数量限制在两个。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612164044.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;one-shot-localization-一次性定位算法&quot;&gt;One-Shot Localization 一次性定位算法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;“One-Shot Localization” 是指在&lt;strong&gt;仅有一次观测&lt;/strong&gt;或信息的情况下进行定位或位置估计的过程。它是指通过&lt;strong&gt;一次观测或一次输入&lt;/strong&gt;，从未知位置或环境中准确地确定目标的位置或姿态。在传感器技术和机器人领域中，这个术语通常用于描述使用单个数据样本进行&lt;strong&gt;位置估计&lt;/strong&gt;的方法或算法。这种方法可能利用传感器数据、图像处理技术或其他信息源来实现目标的定位。与传统的迭代定位算法相比，One-Shot Localization 着重于通过单次观测尽可能准确地确定目标的位置，从而减少计算和时间成本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;给定：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a map with a set of landmarks&lt;/li&gt;
  &lt;li&gt;a set of boserved landmarks from seen from a vehicle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;任务：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;how do I have to shift and rotate the vehicle so that the observed landmarks match best the land marks in the map?&lt;/li&gt;
  &lt;li&gt;我如何移动和旋转车辆，以便观察到的地标与地图中的地标最匹配？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在，你应该对自我定位如何工作以及基本概念有了基本的了解，所以现在是时候使事情变得更加数学化了。在我们的语境中，地图是一组对象，对于每个对象，我们都知道它的位置。在这个时候，让我们限制到点地标，也就是说，地标可以在地图上仅仅表示为一个单点。在这个例子中，你可以在幻灯片的右侧看到，我们有八个点P1到P8，它们在二维平面上排列。这些向量Pi在固定在世界中的世界坐标系中表示，我用希腊字母I和η表示这个字母坐标系的坐标轴。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;车辆使用其车载传感器进行一些观察，它观察到其中的一些标记。在这个例子中，它可能只观察到2、3、4和5号标记的某些位置，这些位置在车辆坐标系中表示。坐标轴以X和Y表示，所以这并不一定是相机的坐标系，可能是相机的坐标系，但也可能不是。我们可能已经从相机坐标系转换到了一些车辆坐标系，但是这个坐标系本身是随车辆移动的。所以，知道坐标系的原点和坐标系的方向意味着我们也知道车辆的位置和车辆的方向。&lt;/p&gt;

&lt;p&gt;我们的&lt;strong&gt;任务是找到一个平移向量和一个旋转矩阵&lt;/strong&gt;，使得最终我们用车载传感器感知到的位置和地图上的标记位置尽可能的一致。平移向量表示车辆的位置，旋转矩阵表示车辆的方向。所以，任务是找到这个平移向量和这个旋转矩阵。我们如何做到这一点呢?&lt;/p&gt;

&lt;p&gt;为此，我们需要一些数学。因为最终我们想解决一个优化问题。所以我们首先陈述优化问题，然后讨论如何解决它。&lt;/p&gt;

&lt;p&gt;我们再次开始从&lt;strong&gt;地图上的点位置&lt;/strong&gt;，它们由&lt;strong&gt;向量Pi&lt;/strong&gt;表示，所以P1指的是第一个标记，P2指的是第二个标记，以此类推。车载传感器检测到的&lt;strong&gt;观察标记位置&lt;/strong&gt;在车辆坐标系中表示，并由&lt;strong&gt;qi&lt;/strong&gt;表示。我们假设索引与标记的索引一致，也就是说，qi指的是位于位置pi的标记。如果不是这样，我们只需要重新编号所有的标记就可以得到这个结果，这只是一个简化表示的技巧。现在，我们想要解决以下的优化问题，以确定车辆未知的位置和方向。&lt;/p&gt;

&lt;p&gt;让我们看看这个术语的细节。在这个部分，我们计算r乘以qi加t，这是什么呢？Qi是从车载传感器看到的第i个标记的感知位置。如果R和T是车辆的真实方向和位置，那么R乘以qi加T就是将观察到的第i个标记投影到世界坐标系中。&lt;/p&gt;

&lt;p&gt;这也意味着，&lt;strong&gt;pi减去rqi加T是真实位置的第i个标记pi和投影位置的标记rqi加T之间的差值&lt;/strong&gt;。当然，&lt;strong&gt;我们期望这两个位置非常接近，这意味着这两个向量之间的差应该是一个非常短的向量&lt;/strong&gt;。因此，我们计算该向量的长度，即欧几里得长度，并取其平方。这个表达式应该是小的，而且它不仅应该对单个标记小，而且应该对我们观察到的所有标记都小。因此，我们将这些项加总。&lt;/p&gt;

&lt;p&gt;最后，我们希望找到最小化这个误差项的T和R的值，并认为这些最小化误差项的T和R的值是车辆最可能的位置和最可能的方向。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数学方法：mathematically&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;which movement (translation + rotation) transforms &lt;em&gt;vehicle coordinates&lt;/em&gt; into &lt;em&gt;world coordinates&lt;/em&gt; such that observed &lt;strong&gt;landmark positions fit to map position&lt;/strong&gt;?&lt;/li&gt;
  &lt;li&gt;哪种运动（平移+旋转）将&lt;em&gt;车辆坐标&lt;/em&gt;转换为&lt;em&gt;世界坐标&lt;/em&gt;，以便观察到的&lt;strong&gt;地标位置适配到地图位置&lt;/strong&gt;？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165001.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;landmark positions in world coordinates (map) 世界坐标中的地标位置（地图）：&lt;/li&gt;
&lt;/ul&gt;

\[\vec{p_{1}},\cdots,\vec{p_{i}},...\]

&lt;ul&gt;
  &lt;li&gt;observed landmark positions in vehicle coordinates 在车辆坐标中观察到的地标位置:&lt;/li&gt;
&lt;/ul&gt;

\[\vec{q}_{1},\cdot\cdot\cdot,\vec{q}_{i},\cdot\cdot\cdot,\vec{q}_{N}\]

&lt;p&gt;现在，我们已经看到了优化问题，但是如何解决这个优化问题还不清楚。&lt;/p&gt;

&lt;p&gt;我们想要最小化这个依赖于未知旋转矩阵和平移向量的误差项。为了简化接下来的步骤，我们首先做一些替换。我们引入P bar作为我们观察到的所有标记的平均位置，所以它是1除以n乘以所有标记位置的和，即所有这些标记的重心。我们引入新变量p i Prime，它等于Pi减去P bar，这意味着我们从所有的标记中减去了重心，然后对于这些p i Prime变量，我们知道它们的平均值最后是零。我们对qi变量做同样的操作，我们引入Q Bar作为qi变量的重心，并从每一个qi测量中减去这个重心，得到qi Prime值。现在，我们在误差项中将Pi替换为Pi prime加P bar，将Q I替换为q i prime加Q Bar，得到最底部的项。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;optimization problem:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612182552.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以现在我们看到了优化问题，但是还不清楚我们如何解决这个优化问题。&lt;/p&gt;

&lt;p&gt;现在我们可以更详细地看看不同的部分。我们可以看到，在这一点上，我们有所有的p i Prime变量的平均值，但我们选择了这样的pi primes，使得它们的平均值等于零，所以这个项实际上等于零。同样的，对于QI Prime部分也是如此，我们选择了QI Prime变量，使得它们的平均值等于零，所以我们得到了零向量，零向量乘以旋转矩阵R也会得到零向量，所以整个和的右边的括号内的项总和等于零，这意味着我们可以忽略掉整个和的第三部分，将项简化为我们在第五行找到的那样。现在我们可以看看第二项，它是P bar减去r乘以Q Bar减去t的平方范数。你可以观察到，第一项不依赖于平移向量T，只依赖于旋转矩阵R，只有第二项依赖于平移向量。这意味着，无论我们找到的旋转矩阵是什么，我们总是可以确定一个适当的平移向量T，使得第二部分等于零，即通过选择t等于P bar减去r乘以Q Bar。对于这样的向量T的选择，第二项总是等于0，并且取得最小值。所以，我们已经知道如何根据R来选择T，剩下的就是第一项。现在的问题是，我们如何确定旋转矩阵R，使得第一项最小。这个第一项可以再次被重写。所以，再次我们看到，我们有这个欧几里得距离的平方，欧几里得距离中有两个变量的差，我们可以再次分解这个平方欧几里得距离，得到我们在这里看到的结果。所以，实际上这是两个项的和，第一项是p i Prime的长度的平方，我们将它视为常数，并将它提出来。然后我们有QI Prime，QI Prime变量在旋转矩阵R的作用下，再加上p i Prime和r乘以QI Prime的标量积的两倍。这意味着，我们可以找到一个矩阵R，使得所有的pi Prime的向量和所有的r乘以QI Prime的向量成正比，那么第一项会消失，我们得到的只是这个求和，它是关于所有的标记的，它包含了所有标记位置的平方长度的和，这是一个常数。所以我们得到的就是一个常数减去另一个项，而这个项实际上是这个对应的标量积的两倍。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最小化下面的式子：minimize&lt;/li&gt;
&lt;/ul&gt;

\[E(R,\bar{t})=\frac{1}{N}\sum_{i=1}^{N}||\vec{p_{i}}-(R\vec{q_{i}}+\vec{t})||^{2}\]

&lt;p&gt;with：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; E(R, \vec{t})=\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}+\bar{p}-\left(R\left(\vec{q}_i^{\prime}+\bar{q}\right)+\vec{t}\right)\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right)+(\bar{p}-R \bar{q}-\vec{t})\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+\frac{2}{N} \sum_{i=1}^N(\bar{p}-R \bar{q}-\vec{t})^T\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+2(\bar{p}-R \bar{q}-\vec{t})^T\left(\frac{1}{N} \sum_{i=1}^N \vec{p}_i^{\prime}-R \frac{1}{N} \sum_{i=1}^N \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\underbrace{\|\bar{p}-R \bar{q}-\vec{t}\|^2} \\
&amp;amp; =0 \quad \underbrace{N}_{=0} \\
&amp;amp; \Rightarrow \vec{t}=\bar{p}-R \bar{q} \\
&amp;amp; =\left\|\vec{p}_i^{\prime}\right\|^2+\left\|\vec{q}_i^{\prime}\right\|^2-2\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime} \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;最大化：&lt;/p&gt;

&lt;p&gt;$\sum_{i=1}^N\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime}$&lt;/p&gt;

&lt;p&gt;所以现在的问题就转化为找到一个旋转矩阵R，使得所有的PI Prime和所有的R乘以QI Prime的向量尽可能的接近。这个问题可以通过奇异值分解来解决。我们可以定义一个新的矩阵S，这个矩阵是对应于每个观察到的标记，每个观察到的标记都产生一个对应的项，这个项是qi Prime乘以pi Prime的转置，这样我们得到一个3乘3的矩阵，我们将这些矩阵加起来，就得到了我们的矩阵S。然后我们对这个矩阵进行奇异值分解，得到U，D和V，然后我们可以得到旋转矩阵R，即UV的转置。&lt;/p&gt;

&lt;p&gt;总结一下，我们找到了一个能够最小化我们的误差项的旋转矩阵R和一个平移向量T。对于T，我们只是选择了让我们误差项中的第二部分最小化的向量。然后，我们通过奇异值分解来寻找最优的旋转矩阵R。&lt;/p&gt;

&lt;p&gt;这就是我们如何进行点云配准，或者说，如何找到最适合我们观察到的标记的车辆的位置和方向。&lt;/p&gt;

&lt;p&gt;我们现在需要最大化这个项，包括因子R，这有点复杂，有几种方法可以做到这一点。我在这里介绍的方法基于一个叫做奇异值分解（SVD）的技术。为了应用它，我们需要以以下方式稍微变换这个项。经过一点点尝试，你会发现p&lt;sub&gt;i&lt;/sub&gt;‘转置乘以R再乘以q&lt;sub&gt;i&lt;/sub&gt;‘转置的和可以被重写为R矩阵的迹乘以q&lt;sub&gt;i&lt;/sub&gt;‘乘以p&lt;sub&gt;i&lt;/sub&gt;‘转置的和，简单来说，就是矩阵R和H的迹，其中H是对q&lt;sub&gt;i&lt;/sub&gt;‘和p&lt;sub&gt;i&lt;/sub&gt;‘转置向量的求和。&lt;/p&gt;

&lt;p&gt;因为q&lt;sub&gt;i&lt;/sub&gt;‘和p&lt;sub&gt;i&lt;/sub&gt;‘是列向量，所以H是一个2x2的矩阵，如果我们处理的是二维位置的p&lt;sub&gt;i&lt;/sub&gt;‘和q&lt;sub&gt;i&lt;/sub&gt;‘，或者它是一个3x3的矩阵，如果我们处理的是三维向量的p&lt;sub&gt;i&lt;/sub&gt;‘和q&lt;sub&gt;i&lt;/sub&gt;‘。这个关系可能不易看出，但你可以试试看并轻松证明出来，如果你不信任的话，就试试看。所以，矩阵的迹是什么呢？&lt;strong&gt;矩阵的迹就是矩阵对角线元素的和。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在让我们看看奇异值分解。奇异值分解是线性代数中的一个定理，它声明对于任何实矩阵H都存在正交矩阵U和V以及对角线上有非负项的对角矩阵D，使得H等于UDV转置。所以我们可以把任何实值矩阵H分解为两个正交矩阵、一个对角线上有非负项的对角矩阵和另一个正交矩阵的乘积。&lt;/p&gt;

&lt;p&gt;注意，矩阵U和V是正方形矩阵，而矩阵D可能是一个非正方形的长方形矩阵。根据H的大小，在我们的例子中，H本身就是一个正方形矩阵，因此U、V和D都是正方形矩阵。&lt;/p&gt;

&lt;p&gt;我们并不想证明这个定理，你可以在所有线性代数的教科书中找到它，它对于数值计算非常重要，但在这里我们只是想使用这个结果。&lt;/p&gt;

&lt;p&gt;经过一些推理，我们可能会发现我们可以将我们上面显示的优化问题解决为以下解决方案：如果H分解为UDV，使用奇异值分解，那么我们期望的旋转矩阵，它最大化这个误差项，就计算为V乘以U转置，如果V乘以U转置的行列式等于1，或者它是V乘以对角线上除最后一项外其他项都是1的对角矩阵，最后一项是-1，再乘以U转置。所以如果V乘以U转置的行列式等于-1，那么这个情况就是有效的。这就是解决方案。&lt;/p&gt;

&lt;p&gt;所以我们基于q&lt;sub&gt;i&lt;/sub&gt;‘和p&lt;sub&gt;i&lt;/sub&gt;‘的值计算H，然后我们用奇异值分解计算U和V，然后我们检查V和U的行列式，并检查V和U的行列式是否等于1，然后我们返回V乘以U转置，或者V乘以对角线上的元素都是1，除了最后一个元素等于-1的对角矩阵，再乘以U转置。如果你想检查证明，你可以查看原始论文，它显示在底部的行中，这个证明不是很复杂，我认为你有机会理解它，它并不太难，但它需要一点点技术思考和一点点数学。&lt;/p&gt;

&lt;p&gt;所以现在我们知道我们怎么计算那些最优的旋转矩阵R和平移向量T，然而我们假设我们确切地知道我们正在观察哪些地标，也就是说，我们能够准确地识别每一个地标。这在某些情况下可能是不可能的，例如，假设我们正在处理特征点方法，并且我们使用车辆环境中的特征点作为地标。每个特征点都带有一个描述符，这些描述符或多或少都是独一无二的，所以一旦我们确定了这样一个特征点，我们就知道我们观察到了哪个特征点，不仅仅是在某个位置有一个特征点，而且我们确切地知道我们观察到了哪个特征点，所以我们知道我们要考虑哪个p&lt;sub&gt;i&lt;/sub&gt;变量。这并不总是这样，例如，如果你假设我们正在处理道路上的交通标志，我们观察到了某个交通标志，我们想把它作为一个地标。当然我们可以分析这个交通标志，我们可以区分不同的交通标志，所以我们不会把停止标志和优先道路标志混淆，例如，但是还可能有几个停止标志或者几个交通标志有完全相同的外观，那么我们就不能说我们观察到了地标5号或者地标10号，但我们只能说，好吧，我们观察到了一些地标，但我们并不确切地知道我们观察到了哪些地标。这当然是更复杂的情况，其中地标并不能被唯一识别。我们如何扩展这种方法，以处理这种情况？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不同的方法，例如 SVD：&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{i=1}^{N}\left(\vec{p}_{i}^{\prime}\right)^{T} R \vec{q}_{i}^{\prime}=\sum_{i=1}^{N} \operatorname{Tr}\left(R \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\right)=\operatorname{Tr}(R H) \quad \text { with } H=\sum_{i=1}^{N} \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;mathematical theorem (singular value decomposition, SVD):
for every real matrix H exist orthogonal matrices U,V, and a diagonal matrix D with nonnegative entries, such that:
数学定理（奇异值分解，SVD）：对于每个实数矩阵 H，存在正交矩阵 U、V 和具有非负项的对角矩阵 D，使得：$H=U D V^{T}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;solution：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612190302.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

\[(Derivation and proof: K.S.Arun, T.S.Hunang, S.D.Blostein, Least Squares Fitting of Two 3-D Point Sets,
IEEE Transactions on Pattern Analysis and Machine Intelligence 9(5), 1987)\]

&lt;ul&gt;
  &lt;li&gt;what to do if landmarks are not uniquely identifiable?如果地标不是唯一可识别的怎么办？
    &lt;ul&gt;
      &lt;li&gt;$\vec{q_{i}}\ \mathrm{\bf~might~rester~to~any~of}\ \ \vec{p_{1}},\ …,\vec{p_{i}},…$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;brute force solution: try all possible combinations 蛮力解决方案：尝试所有可能的组合
    &lt;ul&gt;
      &lt;li&gt;computationally too expensive 计算成本太高&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然，总会有一个暴力解决方案，我们可以尝试所有可能的组合，这就意味着我们假设我们观察到了地标1，我们假设我们观察到了地标2，我们假设我们观察到了地标3，等等，所以我们可以枚举所有可能的组合，并对每一个都计算剩下的误差，然后在所有这些组合中搜索最小值。然而，这在计算上似乎比较昂贵，因为可能的组合的数量增长非常快，通常我们不仅仅处理5个或10个不同的地标，而是处理几百个或几千个地标，这些地标的组合数量如此之大，以至于我们在实时计算中永远无法解决这个任务，所以我们需要找到另一种解决方案。我们的想法是使用迭代的贪婪分配策略，我们假设我们知道一个整数，我们有车辆位置和车辆方向的初始猜测，基于此，我们可以将所有观察到的地标投影到地图上，然后我们可以在地图上搜索最近的地标，也就是说，对于每个q&lt;sub&gt;i&lt;/sub&gt;，我们搜索地图上最近的地标，考虑到车辆位置和车辆姿态的初始猜测，然后我们使用这些地标作为分配的真地标，并应用我们刚刚介绍的算法来计算最优的旋转和平移。当然，在计算了这个旋转和平移之后，我们可能会发现，现在投影所有观察到的地标会得到另一个分配，也就是说，在计算了这个旋转和平移，得到了车辆位置更好的猜测之后，我们可能会发现，现在一个特定的观察到的地标更接近另一个地标，而不是我们在前一步中假设的那个地标。所以在这种情况下，我们需要重新分配所有的观察，然后再计算R和T的最优参数。这提供了一个更好的车辆姿态的猜测，再次，我们将所有观察到的地标投影到地图上，到世界坐标系中，并比较哪个地标在地图上是最近的。根据这个，我们分配观察到的地标和地图上的地标，我们再计算一个旋转矩阵和平移向量，这提供了一个更好的车辆姿态的猜测，等等，直到整个过程收敛。&lt;strong&gt;这产生了一个被称为迭代最近点的算法，或者ICP算法。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;iterative, greedy assignments: 迭代，贪婪的分配：
    &lt;ul&gt;
      &lt;li&gt;$\text { assign } \vec{q}_i \text { to closest landmark among } \vec{p}_1, \ldots, \vec{p}_i, \ldots$&lt;/li&gt;
      &lt;li&gt;reassign all observations incrementally 逐步重新分配所有观察结果&lt;/li&gt;
      &lt;li&gt;👉 ICP algorithm 迭代最近算法&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;icp-algorithm-三维点云配准&quot;&gt;ICP algorithm 三维点云配准&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;ICP（Iterative Closest Point）算法是一种迭代的点云配准算法，用于将两个或多个点云之间进行对齐和匹配。它是一种常用的三维点云配准算法，在计算机视觉、机器人和地图构建等领域得到广泛应用。&lt;/p&gt;

  &lt;p&gt;ICP算法的基本思想是通过迭代的方式，将待配准的目标点云与参考点云对齐，使它们在空间中尽可能重合。算法的核心是找到两个点云之间的最佳刚性变换（旋转和平移），使得它们的重叠部分最大化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612192547.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果我们在步骤四中的分配方式与上一轮循环中的不同，那么我们需要继续进行步骤八。如果相同，意味着在上一轮我们将观察值分配给了相同的地标，那么我们知道算法已经收敛，不会再有任何改变，此时我们可以退出循环，并返回计算得出的旋转矩阵和平移向量。如果不是这种情况，我们就执行步骤八。在步骤八中，我们应用幻灯片10到12中介绍的算法，计算尽可能最好地将点从Q映射到P的新变换R~和t~。&lt;/p&gt;

&lt;p&gt;然后，我们把到目前为止计算得出的变换进行串联。我们的前一个猜测是车辆的位置T和车辆的方向R，通过这个增量步骤，我们用矩阵R~和t~进行确定。串联这些变换后，我们得到一个新的旋转矩阵R为R~ * R，新的平移向量或车辆位置t为R~ * t + t~。这样我们就可以一直进行循环，直到我们能在步骤六中退出循环。&lt;/p&gt;

&lt;p&gt;如前所述，这种算法被称为迭代最近点，简称ICP算法，于1992年提出。它可以用来找到车辆的最优位置和最优方向，如果我们观察到一组点地标，并且我们不能确定我们究竟观察到了哪些地标。算法保证会在某一点终止，它会收敛到这个误差项的局部最优解，不一定会收敛到全局最小值，这非常依赖于车辆姿态的初始猜测。如果初始猜测是好的，ICP算法很可能会收敛到全局最小值。如果初始猜测是差的，它可能不会收敛到全局最小值，只会收敛到次优的局部最小值。&lt;/p&gt;

&lt;p&gt;如果我们遍历这个算法，我们会看到在算法的每一步中，这个误差项都在减少或保持不变。这尤其适用于我们重新计算R和T的步骤八，因为在这里我们直接解决了一个优化问题，并且我们已经看到我们找到了这个优化问题的解析解。这意味着我们可以得出结论，我们真正达到了最优解，全局最优解，假设在pi和Qi地标之间的分配是固定的。&lt;/p&gt;

&lt;p&gt;此外，在我们重新分配qi点到pi点中最近的点的步骤四中，我们也减少了这个误差项的值，或者我们保持它不变，但我们从不增加这个距离项e。这意味着在整个循环中，在这个循环中的所有步骤中，我们都在减少这个误差项，或者我们保持它不变，所以它永远不会增加，这是一个重要的属性。此外，我们知道，qi点和pi点之间的可能分配数量是有限的，可能很大，但仍然是有限的。如果我们有这样一个有限数量的可能性，并且我们有一个在这些可能性之间的序列，使得误差项总是变小或保持不变，那么我们可以得出结论，从某一点开始，我们总是有这样的配置，在这种配置中，误差已经达到了最小，而且不再减小。这种观察到一个单调递减序列的有限集合的可能性的原则，被称为鸽巢原理或德里克雷原理。从这个论点我们可以得出结论，从某一点开始，算法收敛，这意味着这些分配不再改变，算法终止。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Iterative Closest Point (ICP)(Besl, McKay 1992)
    &lt;ul&gt;
      &lt;li&gt;calculates rotation $R$ and translation $\overrightarrow{t}$ in order to transform a set of points $Q$ onto another set of points $P$ 计算旋转矩阵 $R$ 和平移向量 $\overrightarrow{t}$，以将点集 $Q$ 变换到另一个点集 $P$&lt;/li&gt;
      &lt;li&gt;ICP always terminates ICP总是终止&lt;/li&gt;
      &lt;li&gt;ICP converges to local minimum of &lt;br /&gt; 收敛到局部最小值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[E(R,\vec{t})\longrightarrow\frac{1}{N}\sum_{i=1}^{N}\,||\vec{p}_{j}(i)-\left(R\vec{q}_{i}+\vec{t}\right)||^{2}\]

&lt;ul&gt;
  &lt;li&gt;简要证明
    &lt;ul&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 8 assuming fixed assignments between points 根据结构，在步骤8中，$E(R,\overrightarrow{t})$是最小化的，假设点之间有固定的分配。&lt;/li&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 4 assuming fixed translation and rotation 根据结构，在步骤4中，假设固定的平移和旋转，$E(R,\overrightarrow{t})$被最小化了&lt;/li&gt;
      &lt;li&gt;hence, $E(R,\overrightarrow{t})$ never increases&lt;/li&gt;
      &lt;li&gt;since number of possible assignments is finite, we cannot generate new
permutations in step 4 from a certain point on (pigeonhole/Dirichlet principle) 由于可能的分配数量是有限的，我们不能在第 4 步中从某个点生成新的排列（pigeonhole/Dirichlet principle）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ICP example 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ICP算法的一个例子是，有一个非常小的观察集。在这里，蓝色的是集合P，也就是地标在世界坐标系统中的真实位置，红色的是观察值，它们是使用车辆位置的某个初始猜测投射到世界坐标系统中的。任务是以某种方式旋转和平移红色的交叉点，使它们与蓝色的圆圈更或少的重合。在第一步中，我们搜索最近的点，对于每个红色的交叉点，我们搜索最近的蓝色圆圈，这是由虚线表示的。如我们所见，可能会出现两个观察值，对于两个红色的交叉点，分配给同一个地图中的地标的情况，这并不是算法的问题，我们不关心这个，我们就把它当作它是的。下一步是我们计算一个旋转矩阵和一个平移向量，以某种方式推动交叉点和圆圈一起。在这之后，我们再次投射红色的交叉点，也就是观察到的测量值到世界坐标系统中，现在的情况可能看起来像这样。再次，我们检查在P中最近的点，也就是在这种情况下最近的蓝色圆圈，并将红色交叉点分配给蓝色圆圈。然后我们再次计算旋转矩阵和平移向量。应用它们会使红色交叉点完美地移动到蓝色圆圈中。现在，如果我们再次搜索每个红色交叉点的最近点，我们会发现红色交叉点和蓝色圆圈之间的分配保持不变，所以算法必须停止，我们可以返回结果旋转和平移。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630144917.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630144953.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630145010.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630145027.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630145117.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ICP example 2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里有另一个例子，包含一些更多的点。这个例子包含一些随机采样的蓝色点，观察值是通过将蓝色点旋转45度并添加一些小的偏移量创建的。我没有添加任何噪声，所以我们假设有一个完美的传感器，没有任何不精确。那么，如果我们应用ICP算法，算法会进行几个步骤。&lt;/p&gt;

&lt;p&gt;现在，它已经收敛。如我们所见，在这些条件下，算法仍然能够找到全局最优。接下来我们看一个观测测量值和真实位置之间有较大平移的例子，这里我们有一个大的偏移，没有噪声。在这里，ICP算法的第一步是将红点向蓝点推动，使得它们的重心重合，然后再次补偿45度旋转，直到算法收敛。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/5fe4d6ee-ffa2-4ac1-8b88-f9ec726d8ab6.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ICP example 3&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接下来我们看一个观测测量值和真实位置之间有较大平移的例子，这里我们有一个大的偏移，没有噪声。在这里，ICP算法的第一步是将红点向蓝点推动，使得它们的重心重合，然后再次补偿45度旋转，直到算法收敛。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/jhjjjhg.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ICP example 4&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;再来一个例子，偏移很大，但现在旋转90度。我们开始算法的第一步，算法使得重心重合，然后稍微旋转一下红点，但只是这样。现在，算法已经收敛，我们可以看到它收敛到一个局部最小值，而不是全局最优。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/fdgzfsa.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个展示了一个情况，即地图中的地标数量（也就是集合P）比观测到的地标数量（也就是集合Q）要多得多。这在应用中是很典型的，因为我们假设地图包含了大面积的区域，所以它有来自这个大面积的所有部分的地标。然而，机器人或者车辆只能观测到它的局部环境中的地标，它不能观测到所有其他的地标。所以，观测到的地标只会是地图中所有地标的一个子集。当我们看到找到的位置时，我们可以看到，在左边，只要ICP开始时假设的位置和真实位置之间的偏移足够小，ICP算法仍然适用于这种场景。然而，如果这个偏移过大，我们可以在右边看到，我们虽然收敛，但我们没有收敛到全局最优或真实位置，而是收敛到一个远离全局最优的局部最优。这是ICP的典型行为，只有当我们有足够好的姿态的初始猜测时，它才会收敛。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630152014.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ICP example real&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们看一个真实的例子，即机器人足球。正如我们在开始时介绍的，我们可以使用场地标记作为地标，并使用机器人上的摄像头来检测摄像头图像中的这些线，然后我们可以以某种方式使用ICP算法或者ICP算法的变体来计算观测线和地图中线的最佳匹配。&lt;/p&gt;

&lt;p&gt;在这里，我们的想法是使用这种足球机器人中使用的全向摄像头的摄像头图像，这些摄像头可以感知到机器人的整个环境，你可以在中心的摄像头图像中看到这一点。我们看到的是摄像头的镜头，它在摄像头顶部反射在一个镜子上。所以这就是所谓的中心，然后我们看到的一些部分是这个镜子在摄像头顶部的安装。这些区域当然不是我们感兴趣的，我们对那些不感兴趣的区域进行了遮罩，所以这里用灰色的像素遮住了这些区域。这些区域不是我们算法要考虑的。现在我们在图像中搜索场地标记，为了在此过程中保持高效并不浪费太多时间，我们做的是我们在一些搜索线或者搜索光线上进行搜索，这里用红线表示。我们只考虑这些线上的像素，我们遵循这些线，每当我们发现一些白色像素，它们被绿色像素跟随，我们就说这里必须有一个场地标记的元素。所以这会产生一些点，这些点可能是我们用这种摄像头能检测到的。我们可以识别到距离3.5米的场地标记。当然这项工作有点旧，这是在2003年到2008年之间完成的工作。所以现在，使用新的高分辨率摄像头和更强大的计算机，这个算法当然也适用于更远的场地标记。现在我们将所有检测到的场地标记转换到车辆坐标系中，也就是固定在机器人中心的坐标系，其x轴指向前方，y轴指向左边，或者反过来，这种情况下，x轴指向右边，y轴指向前方。这在这个图中产生了黑色的菱形。现在我们知道有一个足球场的地图，也就是我们知道场地标记在哪里，我们使用了ICP算法的一种数值变体来通过最小化观测点与真实场地标记位置之间的距离来确定机器人的位置和方向。最后，在优化后，我们可能已经确定了机器人位于它的目标前方，稍微向左旋转，就像你在图中看到的那样。这种方法对于足球角色扮演工作得非常好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630152132.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这里你可以看到一个例子，右边我们再次看到了足球场，在蓝色中我们看到了观测到的场地标记，在计算出最佳匹配后。&lt;/p&gt;

&lt;p&gt;在这种情况下，我们得到了优化问题的唯一解，或者更准确地说，因为足球场是对称的，我们得到了两个解，一个我们可以在这里看到，另一个就在场地的对方。然而，除了这种歧义性，我们得到了一个唯一的解。在左侧，我们看到我们实际上最小化的误差项。误差项用灰度值表示，像素越深，误差越大。当然，除了场地标记像素的线外，这些线在这里仅仅是为了比较的目的。我们可以看到，最优解（蓝圈的中心）确实是误差项的全局最小值。我们也可以看到，这个误差项是高度复杂的，因此存在许多局部最小值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630152151.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是另一个例子。&lt;/p&gt;

&lt;p&gt;再次，对于我们在误差项图中看到的每个位置，我们可以看到剩余的误差，那是对于该像素位置的最佳方向的误差。我们可以看到，在这种情况下，只找到了一条线上的元素，这导致了一个问题，因为如果你只看到一条线，我们不能确定机器人的完全位置，我们只能说机器人位于两条平行线中的一条上，但我们不知道机器人位于线的哪个地方。就像我们在误差图中看到的那样，有两个小误差项的值是平行于我们看到的线的。在这种情况下，我们可以确定关于机器人位置和机器人方向的一些信息，但不是全部信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230630152247.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;incremental-localization-增量本地化&quot;&gt;Incremental Localization 增量本地化&lt;/h2&gt;

&lt;p&gt;我们如何克服在自我定位中找不到唯一解的情况呢？一种方法是使用增量式定位。通常，我们不是在没有任何关于我们可能在哪里的先验知识的情况下被问到”你在哪里”，而通常是你想知道车辆在哪里，并且我们已经知道机器人在一段时间前的位置。所以我们可以使用这个先验知识来确定现在的位置，这实际上就是增量定位。&lt;/p&gt;

&lt;p&gt;这结合了两种技术，一种是我们介绍过的一次性定位，例如使用ICP算法，它在没有任何先验知识的情况下取一些地标，并确定机器人的位置；另一种是追踪方法，如卡尔曼滤波器或回归，它假设我们已经对当前状态有了一些了解，对于这个自我组织问题来说，就是车辆当前的位置，并用我们通过车载传感器获取的当前测量来更新它。这种增量定位的优势是，它比一次性定位更稳定，比一次性定位更高效，它可能为误差项最小化创造适当的图像值，例如对于ICP算法，我们可以做一个初步的相关地标选择，所有类型的数据关联或门控技术。我们还可以容忍有少量地标的区域，所以如果我们看到的地标太少，我们仍然可以依赖我们之前的位置和我们是如何移动的来确定我们现在的位置。&lt;/p&gt;

&lt;p&gt;基本的思路很简单，我们假设我们使用一种状态空间模型，其中车辆的姿态（即车辆的位置和方向）产生一个状态空间。我们有一个过滤后的姿态，这是我们现在所在位置的先验知识。然后我们可以应用一个预测步骤，例如卡尔曼滤波器，以得到一个预测的姿态。然后我们使用车载传感器进行测量，并使用一些类似ICP的算法确定这些传感器的姿态。然后，我们使用这个姿态来刷新我们对车辆姿态的了解，这样我们就可以再次获得过滤后的姿态。这个步骤很简单也很容易。当然，我们需要一个初始猜测，无论是预测的姿态还是过滤后的姿态，以完成整个过程。让我们看一个机器人足球定位的例子。我们从一个过滤后的姿态开始，这反映了我们之前所在位置的先验知识，如在小型足球场地图中显示的红色十字标志。然后，我们可能使用卡尔曼滤波器来预测过滤后的姿态，并得到预测的姿态，如这里显示的蓝色十字标志。我们也可能使用机器人的里程计，也就是测量轮子转动的程度，例如轮子的旋转程度，来确定我们已经开多远了，是在转弯还是在直线行驶。现在，我们有了预测的姿态，从那里开始，我们开始最小化误差项的过程，预测的姿态作为初始猜测，所以它可以提高搜索算法的效率。搜索算法收敛到误差项的局部最小值，得到一个从摄像机图像中确定的最佳位置，然后我们使用它作为卡尔曼滤波器创新步骤的测量值。所以现在我们已经闭环了，我们可以像这样以增量的方式继续下去。这个方法工作得相当好，这里是一个例子，一个非常简短的序列，显示了在这个机器人足球环境中的工作方式。你会看到这个机器人的符号是青色的，然后有四个圈，实际上一个圈标注为old，这是以前的位置，然后有一个标为odor的圈，这是预测的位置，然后有一个标注为dis，并且有一个紫色圈包围的圈，这实际上是通过匹配观察到的场地标记和地图确定的位置，然后第四个是一个标注为filter的圈，这实际上是创新步骤完成后的位置。所以现在这个图像是循环的，我们可以看到这些位置随着时间的推移是如何演变的。过滤器在一段时间内对观察到的东西进行了一些平滑处理，所以整个位置不会像我们只是考虑通过匹配观察到的场地标记和真实场地标记确定的位置那样跳动。&lt;/p&gt;

&lt;h2 id=&quot;mapping-映射&quot;&gt;Mapping 映射&lt;/h2&gt;

&lt;h2 id=&quot;simultaneous-localization-and-mappingslam&quot;&gt;Simultaneous Localization and Mapping(SLAM)&lt;/h2&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/%E6%B1%BD%E8%BD%A6%E8%A7%86%E8%A7%89/06-SLAM/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/%E6%B1%BD%E8%BD%A6%E8%A7%86%E8%A7%89/06-SLAM/</guid>
        
        <category>汽车视觉</category>
        
        
        <category>汽车视觉</category>
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Tracking Moving Objects 追踪移动物体</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-5-tracking-moving-objects-追踪移动物体&quot;&gt;Chapter 5 Tracking Moving Objects 追踪移动物体&lt;/h1&gt;

&lt;p&gt;欢迎来到《汽车视觉》课程中关于跟踪运动物体的第五章。在本章中，我们将讨论&lt;strong&gt;如何利用相机、激光雷达传感器或其他环境传感器来估计场景中物体的运动。与像素级方法不同，我们将把注意力转移到物体级别上&lt;/strong&gt;。这意味着我们假设环境中的物体已经被检测出来，并且我们能够确定它们的三维位置。&lt;/p&gt;

&lt;p&gt;我们想要估计的运动是物体的三维运动，而不仅仅是二维的光流向量。在本章中，我们将探讨各种物体跟踪技术。以下是与本章相关的专业文献列表：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Greg Welch and Gary Bishop, An Introduction to the Kalman Filter, Technical
Report University of North Carolina at Chapel Hill, 1995
(http://www.cs.unc.edu/~welch/kalman/)&lt;/li&gt;
  &lt;li&gt;Simon J. Julier, Jeffrey K. Uhlmann, Hugh F. Durrant-Whyte, A new approach for
filtering nonlinear systems. Proceedings American Control Conference, 1995, pp.
1628-1632&lt;/li&gt;
  &lt;li&gt;Sebastian Thrun, Wolfram Burgard, Dieter Fox, Probabilistic Robotics. MIT Press,
2005, Chapters 2-4&lt;/li&gt;
  &lt;li&gt;Arthur Gelb, Applied optimal estimation. M.I.T. Press, 2006.&lt;/li&gt;
  &lt;li&gt;Yaakov Bar-Shalom, X. Rong Li, Thiagalingam Kirubarajan: Estimation with
Applications to Tracking and Navigation: Theory Algorithms and Software. Wiley,
2001&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;motion-estimation-by-regression-通过回归进行运动估计&quot;&gt;Motion Estimation by Regression 通过回归进行运动估计&lt;/h2&gt;

&lt;p&gt;现在，让我们从一个在文献中通常没有明确提到但在实践中仍然相关和有用的物体跟踪简单方法开始：&lt;strong&gt;回归运动估计&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在这个估计问题中，我们在不同的时间点观察到一个物体，并以一定的准确度知道它的位置。我们的目标是尽可能准确地估计物体的精确位置、速度甚至加速度。速度包括运动的速度和方向。&lt;/p&gt;

&lt;p&gt;让我们从一个简单的例子开始。假设我们观察到在红灯前等待的汽车。我们在不同的时间点进行多次测量，得到表示车辆X位置的一维测量结果。由于测量噪声，这些测量结果会有变化，就像例子中展示的那样。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为了估计车辆的准确位置并消除测量结果中的随机变化，我们可以对测量结果进行平均。通过计算所得测量结果的均值，我们可以估计一个更可靠的车辆位置。我们还可以估计测量结果的方差，这提供了我们知识的不确定性或扩散的指示。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;回归&quot;&gt;回归&lt;/h3&gt;

&lt;p&gt;这种平均技术是基本而直观的，大多数人都会自然地使用它。现在，让我们思考是否可以将这种技术扩展到车辆开始移动的情况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621190209.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

\[\widehat{x}=\frac{1}{n} \sum_{i=1}^n x_i \quad \operatorname{Var}(x)=\frac{1}{n} \sum_{i=1}^n\left(x_i-\widehat{x}\right)^2\]

&lt;p&gt;在第二种情况中，假设我们观察到一辆&lt;strong&gt;以恒定速度移动的车辆&lt;/strong&gt;。同样，我们在不同的时间点上获取了车辆位置的多次测量结果，如表格所示。我们的目标仍然是尽可能准确地估计车辆的位置和速度，考虑到测量过程中的随机误差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621190338.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;假设：匀速行驶&lt;/li&gt;
&lt;/ul&gt;

\[x(t)=x_0+v \cdot t \text { (十noise) }\]

&lt;ul&gt;
  &lt;li&gt;寻找最适合测量的$x_0$和$v$。&lt;/li&gt;
&lt;/ul&gt;

\[\operatorname{minimize}_{x_o, v} \sum_{i=1}^n\left(x_0+v t_i-x_i\right)^2\]

&lt;p&gt;测量结果与真实位置相似但并不完全相同。以与之前类似的方式，我们可以建立一个运动模型。如果我们假设恒定速度，我们可以将时间T的测量位置表示为初始位置x₀加上未知速度V乘以时间t的积分。然而，测量结果受到额外噪声的影响。&lt;/p&gt;

&lt;p&gt;现在，我们的目标是以最佳方式找到运动模型的未知参数，即x₀和V，以使它们最好地适应我们获得的测量结果。我们可以将其制定为优化问题。对于给定的速度V和初始位置x₀，我们计算根据运动模型预期位置与测量得到的位置Xᵢ之间的差异。我们对每个差异进行平方，将它们在所有测量结果上求和，并通过优化x₀和V来最小化这个总和。我们可以通过计算对于x₀和V的总和的偏导数，然后解决得到的方程组来实现这一目标。&lt;/p&gt;

&lt;p&gt;这一步并不特别困难。您可以在家用纸张尝试一下。得到的方程将如下所示：&lt;/p&gt;

&lt;p&gt;最小化问题可以通过将导数（就$x_0$和$v$而言）设为零而得到解决。&lt;/p&gt;

&lt;p&gt;$\rightarrow$ linear regression:&lt;/p&gt;

\[\left(\begin{array}{cc}
n &amp;amp; \sum_i t_i \\
\sum_i t_i &amp;amp; \sum_i t_i^2
\end{array}\right)\left(\begin{array}{c}
x_o \\
v
\end{array}\right)=\left(\begin{array}{c}
\sum_i x_i \\
\sum_i t_i x_i
\end{array}\right)\]

&lt;p&gt;这被称为线性回归，只要左侧的矩阵具有满秩，您就可以解决这个线性方程组以找到唯一的解，而这通常在您至少拥有两个车辆测量时可以实现。&lt;/p&gt;

&lt;p&gt;使用这种方法，您可以轻松地得出x₀和V的估计值。此外，您还可以得出x₀和V的方差，以评估估计值的质量。您可以对车辆在未来时间T的位置进行预测，甚至计算该预测的方差以确定其可靠性。&lt;/p&gt;

&lt;p&gt;现在让我们扩展这种方法。假设车辆从交通灯开始，在灯变绿时，车辆加速。假设车辆处于固定位置或以恒定速度移动已不再有效。因此，我们需要通过引入加速度项来增强运动模型。具有恒定加速度的加速运动的运动模型如下：&lt;/p&gt;

&lt;p&gt;X(t) = x₀ + V₀t + (1/2)at²&lt;/p&gt;

&lt;p&gt;同样，我们需要考虑到我们的测量结果受到噪声的影响，因此时间T的感知位置与运动模型中的项并不完全匹配。&lt;/p&gt;

&lt;p&gt;我们可以按照类似于之前的过程，并创建一个优化问题，在其中最小化随时间变化的感知位置与基于运动模型的预期位置之间的误差。使用类似于恒定速度情况的技术，我们可以推导出一个线性方程组，并解决它以获得x₀、V₀和a的有效估计值，分别表示位置、速度和加速度。这个案例也是线性回归的一个示例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621190948.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;假设：恒定加速度&lt;/li&gt;
&lt;/ul&gt;

\[x(t)=x_0+v_0 \cdot t+\frac{1}{2} a t^2 \text { (+noise) }\]

&lt;ul&gt;
  &lt;li&gt;寻找最适合测量的$x_0、v$和$a$。&lt;/li&gt;
&lt;/ul&gt;

\[\underset{x_0, v_0, a}{\operatorname{minimize}} \sum_{i=1}^n\left(x_0+v_0 t_i+\frac{1}{2} a t_i^2-x_i\right)^2\]

&lt;p&gt;$\rightarrow$ linear regression&lt;/p&gt;

&lt;p&gt;正如我们所见，回归方法在许多方面优于其他方法。它们使用简单且计算高效。根据我的经验，它们非常适用于许多对象跟踪和运动估计任务。只要运动模型在未知参数上呈线性依赖，回归可以用于估计一维、二维甚至三维的直线运动。我鼓励您在面对运动估计任务时尝试使用回归方法，看看它是否提供了令人满意的解决方案。本章介绍的其他方法，如卡尔曼滤波器或粒子滤波器，使用起来更加复杂。因此，我的初步建议始终是探索回归方法。&lt;/p&gt;

&lt;p&gt;当然，回归方法也有局限性。在处理可以通过解析方法求解的直线运动时，它们效果良好。然而，在处理曲线轨迹时，情况变得更加具有挑战性。通常，我们会遇到无法通过解析方法解决的优化问题，需要使用数值求解器。与通过解析方法解决系统相比，这可能会降低效率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621191347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们看看如何通过一个来自机器人足球领域的示例成功应用回归方法。图片显示了两支配备有摄像机的自主机器人队伍，这些摄像机提供了对环境的全方位视图。球，为了便于识别，被涂成橙色，它在比赛中扮演着核心角色。准确估计球的运动对于机器人做出明智的决策至关重要。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621191420.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我们的方法基于这样一个假设&lt;/strong&gt;：将球的位置投影到地面时，我们通常观察到具有恒定速度和方向的运动。尽管由于弹跳、碰撞以及被机器人踢动或带球等原因，这个假设并不总是准确的，但在短时间内（大约200-300毫秒）是成立的。在垂直方向上，由于重力的影响，运动是不同的，因此我们建模了一个具有已知因子（重力）的加速运动。此外，我们考虑了球的偏转和与地面的碰撞。通过将这些因素纳入运动模型，我们将任务视为一个回归问题。&lt;/p&gt;

&lt;p&gt;我们使用了3到15个观测值，每33毫秒进行一次观测，从而得到总的观测时间范围从67毫秒到500毫秒不等。我们根据球的偏转、踢球或与物体碰撞来调整观测时间。如果观察到这些现象，我们将观测长度减少到三个观测值。当运动可以准确地建模为具有恒定速度的直线运动时，我们逐渐增加观测数量，最多达到15个。通过应用讲座中介绍的回归方法并进行一些调整，我们成功地获得了球的速度估计值。&lt;/p&gt;

&lt;p&gt;让我们来看看这种方法在我们实验室进行的一项实验中的表现。在实验中，一个机器人被放置在左侧的某个位置（用青色三角形表示），而一个球从右向左滚动到机器人前面。&lt;/p&gt;

&lt;p&gt;球的感知位置用深红色虚线圆圈表示，而使用回归方法估计的球位置则用浅红色圆圈表示。从浅红色圆圈中心开始的线表示球的估计运动方向和速度。线越长表示球的移动速度越快。&lt;/p&gt;

&lt;p&gt;视频以俯视图展示了情景，并以循环方式播放，球始终从底部滚动到顶部，然后再次从底部开始。在前两个循环中，没有估计到球的位置，因为我们只有两个观测值，而对于第一个估计，我们需要至少三个观测值。然而，在此之后我们获得了有效的位置和运动估计。需要注意的是，由于设置的低分辨率，对球的三维位置估计的精度有限。尽管如此，我们还是成功地得到了球的位置和速度的令人满意的估计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/f145412d-882f-43fd-b407-0daa9113eee3.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在比赛场景中，观测机器人也在运动中，我们需要考虑机器人的自我运动并在估计球的位置之前对其进行补偿。这个估计必须在与足球场固定坐标系中进行，而不是机器人坐标系。否则，球的速度估计中可能出现人工的伪影。&lt;/p&gt;

&lt;p&gt;当时，这种方法被证明非常成功，我们是足球机器人联赛中的顶级团队。这意味着我们对球的运动估计是相当准确的。&lt;/p&gt;

&lt;h2 id=&quot;basic-of-probability-theory-概率论基础&quot;&gt;Basic of Probability Theory 概率论基础&lt;/h2&gt;

&lt;p&gt;在我们深入研究其他对象跟踪技术之前，让我们简要回顾一些概率论的基础知识。概率论涉及随机事件，这些事件偶尔发生但并非总是发生。事件的概率表示其发生频率。如果一个事件总是发生，其概率为一；如果从不发生，则概率为零。概率用大写字母 “P” 表示，例如 P(A) 表示事件 A 的概率。&lt;/p&gt;

&lt;p&gt;当多个事件同时发生时，我们可以定义联合概率来确定所有这些事件同时发生的频率。另一方面，条件概率涉及多个事件，并询问在事件 B 已经发生的情况下事件 A 发生的频率。&lt;/p&gt;

&lt;p&gt;为了理解这些概率类型之间的关系，我们引入随机变量。随机变量可以被视为在随机过程中取值的变量。有两种类型：离散随机变量，其具有有限或可数的值集（例如计算自行车的数量），以及连续随机变量，它可以取任何实数值（例如测量车辆的速度）。&lt;/p&gt;

&lt;p&gt;对于离散随机变量，随机事件对应于随机变量具有特定值或落在某些范围内。对这些事件分配概率是直接的。然而，对于连续随机变量，随机事件是使用区间来定义的。例如，一个事件可能涉及变量落在特定区间内或区间的并集内。对于连续随机变量，只能使用区间来定义随机事件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192401.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192414.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192431.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192454.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192514.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192534.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;高斯分布&quot;&gt;高斯分布&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621192645.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hidden-markov-models-隐马尔科夫模型&quot;&gt;Hidden Markov Models 隐马尔科夫模型&lt;/h2&gt;

&lt;p&gt;让我们继续学习关于对象跟踪的章节，并介绍一种称为隐马尔可夫模型（Hidden Markov Models，HMMs）的对象行为概率模型。HMMs的主要思想是我们假设我们要观察的对象可以通过状态和随时间变化的状态序列来描述。&lt;/p&gt;

&lt;p&gt;为了实现这一点，我们的目标是创建一个概率模型，可以描述系统处于某个特定状态的可能性，以及在该状态下观察到特定观测的可能性，以及从一个状态转换到另一个状态的可能性。&lt;strong&gt;让我们考虑一个简单的例子，观察一个以恒定速度行驶的汽车。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这个例子中，我们可以使用两个变量来描述系统：汽车的当前位置和当前速度。我们可以将这些变量总结为一个向量，并将系统状态定义为这两个变量的组合。一旦我们知道了状态，我们还可以定义一个转移模型。例如，如果车辆在时间t处于某个位置并以某个速度行驶，那么在时间t + Delta时，它将位于某个后继位置，可以计算为旧位置加上Delta乘以当前速度。后继速度将与当前速度相同。在这种情况下，我们可以将一步之后的状态与当前状态之间的关系表示为矩阵-向量乘法。&lt;/p&gt;

&lt;p&gt;然而，现实世界中的系统并不完美，通常会偏离确定性行为。我们可以通过在状态转移函数中添加一个随机噪声项来对优化行为的随机偏差进行建模。这个噪声项代表小的随机数，考虑到系统与优化行为的偏差。&lt;/p&gt;

&lt;p&gt;此外，我们假设我们可以使用传感器来观察系统。这些传感器测量与系统当前状态相关的某些物理变量，尽管它们可能不直接测量状态本身，这可能是具有挑战性的。例如，如果我们有一个观察场景的摄像机，我们可以测量车辆的位置。这允许我们建立状态与位置之间的映射，将位置视为观测。在测量过程中，我们还考虑了一些测量噪声，它会干扰测量结果。通常，测量值接近实际位置但并非完全相同。这种测量不准确性可以通过添加一个加性噪声项来建模，这是一个接近零的小随机变量。如果系统的状态由包含汽车位置和速度的向量描述，我们可以将观测表示为车辆位置加上一小部分噪声。这也可以用矩阵-向量表示法表示。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;example: car with constant velocity - system state: position, velocity&lt;/li&gt;
&lt;/ul&gt;

\[s(t)=\left(\begin{array}{l}
x(t) \\
v(t)
\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;transition:&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}
&amp;amp; x(t+\Delta)=x(t)+\Delta \cdot v(t)+\text { noise } \\
&amp;amp; v(t+\Delta)=v(t)+\text { noise } \\
&amp;amp; s(t+\Delta)=\left(\begin{array}{cc}
1 &amp;amp; \Delta \\
0 &amp;amp; 1
\end{array}\right) s(t)+\text { noise }
\end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;system state is not directly observable&lt;/li&gt;
  &lt;li&gt;observations:
every state produces an observation&lt;/li&gt;
&lt;/ul&gt;

\[s(t) \mapsto z(t)+\text { noise }\]

&lt;ul&gt;
  &lt;li&gt;example: camera observing a car.&lt;/li&gt;
  &lt;li&gt;system state&lt;/li&gt;
&lt;/ul&gt;

\[s(t)=\left(\begin{array}{l}
x(t) \\
v(t)
\end{array}\right)\]

&lt;p&gt;this is interesting for us, but it cannot be observed&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;velocity is not observable&lt;/li&gt;
  &lt;li&gt;position can be observed up to small random errors&lt;/li&gt;
&lt;/ul&gt;

\[\left.\begin{array}{rl}
z(t) &amp;amp; =x(t)+\text { noise } \\
&amp;amp; =(1,0) \text {. })_{\text {tep figprog }}(t)+\text { noise }
\end{array}\right\} \text { this can be observed }\]

&lt;p&gt;this can be observed&lt;/p&gt;

&lt;p&gt;此时，重要的是要理解我们的主要兴趣在于估计系统的状态。我们想要估计车辆的位置和速度，但我们无法直接测量状态。相反，我们可以测量观测值。因此，具有挑战性的任务是在给定一系列观测的情况下推导出状态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;现在让我们正式介绍隐马尔可夫模型（Hidden Markov Model，HMM）。隐马尔可夫模型是一个离散时间的随机状态转移系统，其中观测和后继状态完全依赖于当前状态，而不依赖于先前的状态或观测。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数学上，这个特性通过下面的两个公式描述，但让我们逐步解释定义。首先，HMM是一个状态转移系统，正如我们所见。我们使用当前状态来描述系统，并假设当前状态与下一个状态之间存在随机关系。这些关系为系统引入了随机性，使其成为随机的。系统是离散时间的，这意味着我们只关注系统在特定时间点的状态，例如每秒一次，不考虑其之间发生的情况。&lt;/p&gt;

&lt;p&gt;定义还说明观测和后继状态完全依赖于当前状态，而不依赖于先前的数据或观测。这个假设被称为随机独立性。它意味着如果我们知道当前状态，我们就拥有了预测系统未来行为和提供的观测的所需信息。对历史、先前状态和观测的了解对确定未来行为没有贡献。这种独立性假设允许我们简化所涉及的条件概率。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;形式上，这可以通过所示的两个公式来表达。在右侧，我们有一个条件概率，表示给定时间t的当前状态和当前观测集T的情况下，时间t+1的后继状态的概率，记为P(St+1&lt;/td&gt;
      &lt;td&gt;St, T)。通过假设随机独立性，我们可以通过消除所有过去的状态和观测来简化这个条件概率，将其简化为仅考虑当前状态下St+1给定St的条件分布。观测也是如此，其中给定St和所有过去的观测和状态的情况下，特定观测集T的条件概率可以简化为给定St的当前观测的概率，而不考虑过去的情况。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A Hidden Markov Model (HMM) is a time-discrete, stochastic state transitioning system. Its observation and its successor state depend entirely on its present state and do not depend on previous states or observations.&lt;/p&gt;

\[\begin{aligned}
P\left(s_{t+1} \mid s_t\right) &amp;amp; =P\left(s_{t+1} \mid s_t, z_t, s_{t-1}, z_{t-1}, \ldots, s_0\right) \\
P\left(z_t \mid s_t\right) &amp;amp; =P\left(z_t \mid s_t, z_{t-1}, s_{t-1}, \ldots, s_0\right)
\end{aligned}\]

&lt;p&gt;当使用HMM对世界进行建模时，我们希望根据一系列观测来确定当前状态。虽然我们无法精确知道随机系统中的当前状态，但我们的目标是估计最可能的状态及其概率。我们想要计算给定迄今为止所有观测的条件下的当前状态的概率。&lt;/p&gt;

&lt;p&gt;相关的任务是预测，我们希望预测系统未来一步的状态。给定时间t的观测，我们想要进行预测并估计最可能的未来状态及其概率。这两个问题是相互关联的，可以同时计算。幻灯片中展示了它们之间的关系，通过公式表示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621194222.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;总结这个公式，从左侧的下方公式开始，我们有预测概率。它表示给定时间t迄今为止的一系列观测的情况下，在下一个时间步中观察到某个特定状态的可能性。公式的第一行使用边缘化规则对St的所有可能值求和，消除了St的影响。在从第一行到第二行的转换中，使用条件概率的定义重写了条件概率。St被移至垂直符号的右侧，并且为了补偿这个变化，我们将术语乘以St给定所有观测的条件概率。第二行的第一项，P(St+1&lt;/td&gt;
      &lt;td&gt;St, T)和所有过去的观测，可以根据随机独立性的假设进行简化。该项不依赖于观测，因此可以从条件部分中去除，结果为第三行。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;第三行中出现的状态转移概率表示系统从状态St转移到状态St+1的概率。在使用HMM对世界进行建模时，我们需要提供这个转移概率。第二行中的第二项表示给定到该时间点为止的所有观测的概率。这个概率是从上方的方程中导出的，其中我们使用贝叶斯规则重新排列了术语。通过这样做，将St给定到时间T-1的观测的概率乘以分子，并添加了一个分母，其中包含给定所有先前观测的St到时间T的概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621194314.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在我们可以观察到分子中的第一项具有一个形式，我们可以应用随机独立性的假设。它表示给定状态和一些先前观测的情况下观测的概率。根据HMM中的随机独立性假设，我们可以从该项中删除先前的观测，从而显著简化了分子。&lt;/p&gt;

&lt;p&gt;分母包含一个与当前状态完全独立的项。它表示获得这些观测的概率。由于它不依赖于当前状态，可以将其视为一个常数，与当前状态无关。由于我们对当前状态的概率感兴趣，这个项作为一个归一化因子。我们可以在符号∝（与之成比例）中隐藏它，如公式的第二行所示。在第二行中，第一项表示作出某个观测的概率。这一方面描述了传感器和测量过程。例如，如果一个车辆位于某个位置，并且我们有一个观测它的摄像头，这个项表示观测到该车辆的特定观测的可能性。这是隐马尔可夫模型中的常见建模方面。&lt;/p&gt;

&lt;p&gt;第二项具有一种概率形式，它使我们能够根据先前时间T-1的所有观测对时间t的状态进行预测。它表示左侧幻灯片的第二部分涉及的概率。然而，我们可以观察到这两个项之间的索引已经增加了。这表示我们在第一项的计算中使用了第二部分的计算结果作为输入。这两个步骤之间的时间发生了演化。&lt;/p&gt;

&lt;p&gt;这引导了一个基于迭代过程的基本思想，用于逐步估计给定观测序列的系统概率。&lt;strong&gt;它由两个步骤组成，即预测步骤和创新或校正步骤&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在预测步骤中，我们计算预测状态概率，即给定时间T的观测序列的情况下的St+1的概率。这个步骤允许我们对系统的下一个状态进行预测。
在创新或校正步骤中，我们采用在时间T+1处的新观测，将在预测步骤中计算的概率纳入其中，并计算给定所有观测的时间T+1的状态概率，包括时间T+1的观测。这个步骤将新的测量结果纳入，并将其整合到我们对系统状态的了解中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621194759.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如图所示，整个过程从预测状态概率的初始估计开始。然后，我们融入一个测量并计算状态概率。我们通过在预测和创新步骤之间交替进行，进行预测、融合测量并更新对系统状态的了解，重复这个过程。&lt;/p&gt;

&lt;p&gt;这个迭代过程使我们能够根据观测序列逐步估计系统的概率，考虑到系统的动态性和新的可用测量。&lt;/p&gt;

&lt;p&gt;这个过程可以逐步进行说明。我们从计算在没有任何观测的情况下处于状态S1的概率开始。我们对这个概率做出一个初始猜测。然后，我们融入一个测量并计算在给定观测Z1的情况下处于S1的概率。接下来，我们进行预测步骤，计算在给定Z1的情况下处于S2的概率。然后，我们执行另一个创新步骤，计算在给定Z2和Z1的情况下处于S2的概率。我们继续进行预测步骤，计算在给定Z2和Z1的情况下处于S3的概率。随后，我们进行创新步骤，将新的测量Z3纳入计算。这个过程继续进行，对每个后续的时间点进行预测和创新步骤，例如预测时间4的状态并融入时间4的测量。这个迭代过程重复进行，根据可用的观测估计状态概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621195431.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;值得一提的是，并不总是必须从创新步骤开始。根据应用的不同，我们也可以从预测步骤开始。例如，我们的初始猜测可以是在没有任何观测的情况下时间0的初始状态的概率。然后，我们可以通过预测步骤启动过程，计算在没有任何观测的情况下处于状态1的概率。选择从预测或创新步骤开始取决于具体的场景和最合适的方法。&lt;/p&gt;

&lt;p&gt;在隐马尔可夫模型中使用预测和创新步骤来估计状态概率的基本思想是优雅的。然而，在实践中，评估这些推导出的方程有时可能具有挑战性。但在特殊情况下，例如处理具有有限状态和观测数量的离散状态变量和离散观测时，可以将隐马尔可夫模型表示为图形，并在表中组织概率。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;特殊情况：
    &lt;ul&gt;
      &lt;li&gt;有限数量的可能状态和观察&lt;/li&gt;
      &lt;li&gt;过渡和观察概率可以用图和/或表来表示&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面是这样一个表的示例。在左侧，我们有用椭圆表示的状态，黑色箭头表示状态之间的可能转换。箭头旁边的数字表示与每个转换相关的概率。请注意，还可能有表示系统保持在某个状态的概率的反射箭头。在这个示例中，我们对状态A有一个反射箭头，表示保持在状态A的概率为80%。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621195648.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在右侧，我们有观测模型。在这种情况下，我们有两个观测，U和V。对于每个观测，我们有由虚线箭头和相应数字表示的观测概率。这些数字表示在我们假设处于某个状态时进行特定观测的概率。重要的是记住这些概率的顺序。此时，我们不关心观测特定测量时处于某个状态的可能性。相反，我们关注的是如果我们确定处于特定状态，进行某个观测的概率。这些概率对于建模传感器和其特性很有用。另一方面，我们在之前介绍的两步算法中旨在估计的概率是给定观测序列的情况下处于特定状态的概率。&lt;/p&gt;

&lt;p&gt;还要记住，根据概率论，从一个状态出发的所有传出转换箭头的概率之和必须等于1。类似地，从同一状态开始的所有传出观测箭头的概率之和也必须等于1，以符合概率论的原则。&lt;/p&gt;

&lt;p&gt;有了这个模型和表格，我们可以执行算法，并且例如确定在观测序列U、U、V、U之后处于状态A、B或C的概率。如果我们假设初始状态分布中A和B的概率都是0.5，初始状态为C的概率为0，我们可以计算所需的概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621195808.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;让我们为这个例子执行算法，从创新步骤开始。在初始化中，我们有预测的概率：预测概率为0.5时，我们处于状态A；预测概率为0.5时，我们处于状态B；概率为0.0时，我们处于状态C。&lt;/p&gt;

&lt;p&gt;现在，当我们进行创新步骤时，我们将这个知识与观测概率相结合。在下面的图中，观测在状态A中观测到”u”的概率为0.6。我们将这两个项相乘：0.5乘以0.6等于0.3。然而，当我们回到之前的几张幻灯片中推导出的创新步骤的公式时，我们发现它不是一个等式，而是一个比例符号。这意味着我们还不知道概率是0.3，它可能是不同的，但我们知道概率与0.3成比例。&lt;/p&gt;

&lt;p&gt;让我们计算状态B的概率。预测概率为0.5，观测概率从图中可以看出是0.2。我们得到0.5乘以0.2，得到0.1。&lt;/p&gt;

&lt;p&gt;对于状态C，我们得到0.0作为上一个概率乘以观测概率的结果，在这种情况下观测概率为0.7，结果为零。&lt;/p&gt;

&lt;p&gt;因此，我们知道对于状态A，概率与0.3成比例；对于状态B，概率与0.1成比例；对于状态C，概率与零成比例。根据概率论，这些概率必须相加等于1。&lt;/p&gt;

&lt;p&gt;现在我们可以计算比例因子，即1除以(0.3 + 0.1 + 0)，即1除以0.4。&lt;/p&gt;

&lt;p&gt;综合起来，对于状态A，我们得到0.3除以0.4，得到0.75。对于状态B，我们得到0.1除以0.4，得到0.25。对于状态C，我们得到0除以0.4，仍然是零。&lt;/p&gt;

&lt;p&gt;现在我们已经计算了给定第一个观测的当前状态的概率。我们算法的下一步是应用预测步骤，由表格的上三行到下三行的蓝色箭头表示。让我们也执行这一步。&lt;/p&gt;

&lt;p&gt;因此，我们要计算的是在下一步中我们处于状态A的概率。现在，我们必须考虑进入状态A或保持在状态A的所有方式。在第二个时间点上，处于状态A的可能性有三种。&lt;/p&gt;

&lt;p&gt;第一种可能性是我们已经在状态A并保持在状态A。在第一个时间点上处于状态A的概率为0.75，保持在状态A的概率为0.8。因此，&lt;/p&gt;

&lt;p&gt;我们得到此路径的概率为0.75乘以0.8。&lt;/p&gt;

&lt;p&gt;第二种可能性是我们在时间点1处于状态B，但很不幸，从转换图中可以看出，至少没有直接的方式从状态B转移到状态A。因此，从B到A的转换概率为零，这种路径的概率也为零。&lt;/p&gt;

&lt;p&gt;第三种可能性是我们在状态C，并进行状态转换到状态A。然而，在第一个时间点上处于状态C的概率为零，而转换概率为0.5。因此，两者的乘积为零。&lt;/p&gt;

&lt;p&gt;剩下的是从A转到A的可能性，即0.75乘以0.8，得到0.6。&lt;/p&gt;

&lt;p&gt;要计算在第二个时间点处于状态B的预测概率，我们需要考虑所有到达状态B的可能性。我们可能在时间点1处于状态A，概率为0.75，并以概率0.2转移到状态B。因此，我们得到0.75乘以0.2。&lt;/p&gt;

&lt;p&gt;另一种可能性是我们在状态B并保持在状态B，但由于没有反射转换，无法沿此路径进行转换。因此，整体概率为零。&lt;/p&gt;

&lt;p&gt;第三种可能性是我们在状态C并返回到状态B。然而，在第一个时间点上处于状态C的概率为零，因此此路径的整体概率也为零。&lt;/p&gt;

&lt;p&gt;剩下的是0.75乘以0.2。&lt;/p&gt;

&lt;p&gt;对于第三个状态，状态C的概率是多少？所有可能性：我们可以从状态A转移到状态C，但根据转换图，这是不可能的。第二种可能性是从状态B转移到状态C。这显然是可能的，并且最终概率为0.25乘以1。而在状态C并保持在那里的概率再次为零。&lt;/p&gt;

&lt;p&gt;因此，我们得到的概率为0.25。
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621200141.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;让我们执行创新步骤，然后进行预测步骤，再进行一次创新步骤和预测步骤。正如我们在前一张幻灯片中看到的表格，对于状态和观测由离散随机变量表示的情况，可以使用预测和创新步骤执行这个两步算法。我们可以将所有的概率存储在表格中。然而，当处理连续随机变量时，情况变得更加困难，因为表格已经不足以表示概率密度函数。&lt;/p&gt;

&lt;p&gt;然而，至少从理论上讲，连续随机变量的情况并不真正更困难，因为我们已经看到可以使用相同的规则来处理概率密度函数，就像我们用来处理概率的规则一样。我们只需要用概率密度函数代替概率，用积分代替求和，然后得到表示创新步骤和预测步骤的公式。然而，在实践中，实现这些公式在计算机程序中却更加困难。
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621201549.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一个问题是概率密度函数很难表示，我们无法列举所有可能的值并将它们存储在表格中。我们需要使用适当的概率密度函数类型。另一个问题是预测步骤中所需的积分可能难以在解析上表示。&lt;/p&gt;

&lt;h3 id=&quot;linear-gaussian-model-线性高斯模型&quot;&gt;Linear Gaussian Model 线性高斯模型&lt;/h3&gt;

&lt;p&gt;然而，好消息是，还有一种特殊情况可以解决并在解析上表示，这就是所谓的&lt;strong&gt;线性高斯模型&lt;/strong&gt;。线性高斯模型意味着在隐藏马尔可夫模型中发生的所有操作都可以表示为线性操作，而&lt;strong&gt;所有随机项都被建模为高斯变量，即高斯概率密度&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这意味着在线性高斯模型中，状态转移公式是一个线性公式：St+1 = At * St + Ut + Epsilon t。在这里，At是一个适当的矩阵，Ut只是一个偏移量，Epsilon t是一个随机项。我们假设Epsilon t按照高斯分布分布。&lt;/p&gt;

&lt;p&gt;在文献中，有时会以稍微不同的方式使用Ut作为控制输入，并与第二个矩阵B相乘，用于控制系统。但对于我们的目的，我们只处理测量部分，直接将Ut表示为一个常数偏移量就足够了。指数t表示这些矩阵At和偏移量Ut可能随着时间的推移而变化。它们不需要是常数；它们可以改变，但不能依赖于St。它们可以依赖于其他时间点上的内容，但不依赖于系统的当前状态。&lt;/p&gt;

&lt;p&gt;所以，我们可以看到，&lt;strong&gt;我们对于转移模型的公式是关于St的线性函数，而所有的随机项都是高斯随机项&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230621201627.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;类似地，对于观测方程，我们假设观测St可以通过将St与测量矩阵H相乘来得到。这个测量矩阵H可能也会随时间而变化，但它不能依赖于St+1。然而，它可能依赖于时间。另外，我们有一个额外的偏移量Delta t，它是一个随机项，用于模拟测量的不确定性。同样，我们假设Delta t按照高斯分布分布。&lt;/p&gt;

&lt;p&gt;总结一下，该模型是线性的，并具有由矩阵At和偏移量Ut给出的线性状态转移。第二件事是Epsilon t是一个高斯随机变量，并且我们假设其均值为零。高斯分布通常被称为白噪声，因为没有偏移量。Epsilon t的协方差矩阵可能也随时间变化，但不能依赖于当前状态。&lt;/p&gt;

&lt;p&gt;在该模型中，Ht表示用于推导观测结果的乘法因子，它可能取决于时间，但不取决于状态。Delta T表示测量噪声，假设为具有特定协方差矩阵RT的白噪声。协方差矩阵RT可以随时间变化，但不应取决于当前的状态或观测结果。&lt;/p&gt;

&lt;p&gt;同时假设噪声项Epsilon T和Delta T是随机独立的。这个假设是构建隐藏马尔可夫模型所必需的。&lt;/p&gt;

&lt;p&gt;需要注意的是，在文献中，可能会遇到省略了索引T的模型版本。这个版本假设矩阵A、U和H是常数，并且随时间不变。然而，这不是最一般的版本。在实践中，通常需要调整这些矩阵。例如，如果时间点不均匀或存在异步时间点，就需要修改矩阵A，以考虑上一个时间点和当前时间点之间的不同时间间隔。&lt;/p&gt;

&lt;p&gt;总结起来，虽然该模型允许时间依赖性，但变量A、H、QT、RT和UT不应取决于当前的状态或观测结果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;再举一个例子。回到观测匀速运动的车辆。我们已经知道可以用线性方式建模这种运动：x(t+1) = x(t) + （到上次观测的时间间隔）*（速度）+（额外的白噪声项），其中速度保持不变，还有一个额外的噪声项。&lt;/p&gt;

&lt;p&gt;在这种情况下，delta T代表时间间隔，即两个步骤之间的时间间隔长度。epsilon项代表随机过渡噪声和速度测量中的随机不准确性。&lt;/p&gt;

&lt;p&gt;因此，我们得到的状态表示如下：如果我们将这两个方程按矩阵-向量形式排列，可以写成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624211238.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从这个形式中，我们可以得到我们需要的项：矩阵A(t)形式为[1 deltaT; 0 1]，偏移向量（在这种情况下为零向量），以及epsilon噪声项，其中包含位置和速度的两个噪声项。&lt;/p&gt;

&lt;p&gt;现在，状态向量包含当前位置和速度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624211643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;继续讨论观测问题，假设我们有一个立体摄像头设置，在每个时间点测量车辆的位置。因此，我们的测量集T等于x(t)加上一些测量噪声delta T。这可以重新写成我们需要的线性高斯模型的矩阵-向量乘法形式。&lt;/p&gt;

&lt;p&gt;现在，矩阵H(t)是一个包含单行条目[1 0]的矩阵，适用于线性转换模型。如果当前状态概率分布是高斯分布，那么预测的下一个状态概率分布也是高斯分布。&lt;/p&gt;

&lt;p&gt;这实现了预测步骤，将高斯分布映射到高斯分布。为了表示高斯分布，我们只需要知道mu向量（均值）和方差或协方差矩阵Sigma。因此，线性高斯模型的预测步骤接受一个mu向量和一个Sigma矩阵，并产生一个新的mu向量和一个新的Sigma矩阵。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624212000.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;创新步骤类似。如果预测的状态概率分布是高斯分布，那么下一个状态的概率分布也是高斯分布。这意味着创新步骤将高斯分布映射到高斯分布。它接受一个mu向量、一个Sigma矩阵和一个测量，并产生一个新的mu向量和一个新的Sigma向量。这种高斯到高斯的映射非常有用，因为在这个算法中，我们只需要将mu和Sigma映射到新值，而无需表示具有数百个参数来描述形状的复杂概率密度函数。我们只需要这两个参数：mu和Sigma。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624212017.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;算法的结构如下：我们有两种类型的分布——状态分布和预测的状态分布，以及两个步骤——预测步骤和创新步骤。创新步骤集成了新的观测，而预测步骤预测了下一个时间点的状态分布。我们从一个初始的高斯状态分布开始整个过程，可以是预测的状态分布或状态分布，两种选择都可以。因此，第一步要么是创新步骤，要么是预测步骤。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624212149.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kalman-filter-卡尔曼滤波&quot;&gt;Kalman Filter 卡尔曼滤波&lt;/h3&gt;

&lt;p&gt;这个算法有一个名字，叫做卡尔曼滤波器。预测步骤在这里给出，正如所说的，预测步骤接受一个mu向量和一个Sigma矩阵，并返回一个新的mu向量和一个新的Sigma矩阵，现在用上标“predicted”来表示。我们可以推导出这个公式，但在这里的讲座中，我只给出结果，有趣的是，我们可以解释这个公式，例如，如果我们看一下MU值的公式，这里发生了什么，实际上我们只是将状态转移函数应用到先前的mu向量上，因此我们应用了状态转移矩阵A，并且在偏移量上不添加任何额外的噪声，因为我们想要估计状态而不是创建新的状态，但是要估计状态，我们在这一点上忽略了噪声。然而，当我们看到Sigma更新规则时，噪声就会出现了，在Sigma更新规则中，第一部分即将迄今为止的Sigma矩阵乘以A左乘和右乘只是将状态转移公式应用到Sigma协方差矩阵上，第二项额外的QT考虑了状态转移中的随机性，因此它反映了状态转移中的不准确性，并为我们的估计增加了一些不确定性，因此它告诉滤波器，预测的状态分布比先前的状态分布更加不确定，因为转换本身是嘈杂的，因此不确定性增加了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624212742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;创新步骤的形式如下：我们给定了从预测步骤获得的MU T predicted和Sigma T predicted值以及新的测量集T，然后我们得到mu T和sigma T。这里可以看到公式，我们首先计算一个中间变量KT，通常称为卡尔曼增益。正如你所看到的，它看起来有点复杂。然后我们计算新的mu T值，然后计算一个新的协方差矩阵Sigma T。&lt;/p&gt;

&lt;p&gt;创新步骤的解释比预测步骤的解释更加困难，但我们可以将卡尔曼增益KT视为一种加权因子，它对迄今为止的知识和迄今为止的知识的不确定性进行加权。这种不确定性表示在Sigma predicted中，以及从测量中获得的不确定性，它们以逆矩阵的参数作为参数，例如h t乘以Sigma T predicted乘以h t的转置加上RT。这个部分有时会包含关于测量的不确定性的陈述，因此它计算了一种加权因子，然后这个加权因子在更新mu T U T时使用，在mu T U T的更新中，我们可以看到它是从预测的mu T开始计算的，加上一些加权因子KT乘以括号中的项。如果我们看一下括号中的项，我们会看到set T是当前的测量，h t乘以mu T predicted是我们预期的测量，如果mu T predicted是系统的真实状态，那么h t乘以mu T predicted就是我们预期的观测值。因此，这个括号的作用是将实际测量与预期测量进行比较，并基于此对MU值进行校正，即估计的状态。&lt;/p&gt;

&lt;p&gt;对于表示Sigma更新规则的第三行的解释相对困难，因此对于这里发生的事情并没有一个简单的直观解释，但我们可以说，迄今为止的预测状态分布的不确定性与从测量中得到的不确定性以某种方式结合，而结果不确定性比先前的预测状态的不确定性更小，因为测量提供了一些额外的信息，使我们能够得到更好的估计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624212814.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;example:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们看一个简单的例子，再次是一个以恒定速度移动的汽车，我们假设我们每秒进行一次测量，这意味着我们的时间点在时间轴上等间隔地以一秒的距离分布。转换模型如下所示，这是我们已经推导出的，矩阵A与时间无关，是1 1 0 1，偏移向量是0 0，测量矩阵H是行向量1 0。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624214100.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于不确定性估计，即Q和R的估计，总是有点棘手的，一个粗略的想法是说，保持非对角线元素为零，并且对于对角线元素，考虑一下你预计的不确定性最大是什么，也就是你对应变量的错误最大预期是什么，然后取它的一半，并对其进行平方，这样就得到了一些合理的值，但你可能需要略微调整，得到这些矩阵的好值总是有点棘手的，对于我们这里的目的，让我们这样做，并使用这些矩阵。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624214135.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后我们需要对状态进行初始分布，如果我们对起始状态一无所知，我们希望表达我们对它一无所知，我们该怎么办？思路是说，既然我们不知道是哪个状态，我们就随便取一个任意的mu值，例如0 0，出于数值原因，这是一个不错的选择。对于Sigma协方差矩阵，我们采用对角矩阵形式，将非对角线元素保持为零，对于对角线元素，我们取非常大的数值，例如1000的平方或者100的平方。这表示我们给出了一个初始猜测0 0，作为我们所能做的最好猜测，但我们也告诉你我们对它非常非常不确定。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624214301.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在在Matlab中实现这个算法，并创建了一个小的测试环境并生成了一些测量数据，现在我们可以看到结果。在上面的图片中，水平轴表示时间，垂直轴表示位置，红色加号表示我们得到的位置测量值，蓝色叉表示估计的位置，即创新步骤的MU值，垂直条代表不确定性，这些条越大，协方差矩阵中对应的条目越大，也就是估计的不确定性越大。我们还可以看到估计的位置跟随真实位置，并且不确定性随时间稍微减小。我们还可以看到，与感知位置相比，估计位置更加平滑。&lt;/p&gt;

&lt;p&gt;下方的图像显示了估计的速度，在第一个时间步中，我们得到了一个速度估计值为零，因为根据一个测量值无法估计速度，所以我们得到的初始估计值为零，但正如我们所看到的，我们非常不确定，因此卡尔曼滤波器告诉我们，是零，但我们不能确定它就是零，它也可能是其他值，例如在-7和+7之间。然后经过几次观察，滤波器基本上得到了正确的估计值，即在本例中为每秒一米的速度，我们可以清楚地看到不确定性减小，并且滤波器对车辆的速度越来越确定。不确定性不会变为零，在每个转换步骤中，都会再次添加一定的不确定性，但在本例中，它单调减小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624214356.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是前一个例子的一个小变化，前22秒，车辆以每秒一米的速度向前行驶，然后在20秒后开始倒车，以每秒一米的速度向后行驶，正如我们所看到的，测量值在时间点20之前增加，然后再次线性减小。估计位置的滤波值在开始时非常接近真实位置，就像我们之前看到的例子一样，在时间点20处变得奇怪，因为滤波器仍然预期车辆以大致每秒一米的速度向前行驶，但实际上并非如此，整个建模的假设在某个时间点上被违反了，然后需要一段时间，卡尔曼滤波器才意识到车辆确实在倒车并适应新的运动方式，这是非常典型的情况，因为这里的实际情况在某个时间点与我们在隐马尔可夫模型中建模的情况有所不同，因此卡尔曼滤波器不能立即跟随新的行为。如果我们观察估计的速度，也可以看到相同的行为，开始时与之前的行为相同，在时间点20之后，我们可以看到需要多长时间估计的速度才会收敛到新的实际速度-1米/秒。有趣的是，不确定性并不增加，尽管估计的速度与实际速度不匹配，但这是由于卡尔曼滤波器的独立性假设，如果我们使用回归方法，并仅使用最后的5或10秒数据进行跟踪，那么情况将不同，我们会看到在这些情况下不确定性再次增加，当假设破裂时，但在卡尔曼滤波器中，不会发生这种情况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624214637.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，这是一个比较卡尔曼滤波器和线性回归方法的好时机，我们在本章开始时介绍了线性回归方法。&lt;/p&gt;

&lt;p&gt;现在让我们使用非常相似的模型。两者都使用线性模型，并假设高斯噪声，因此它们非常相似。在卡尔曼滤波器中，我们希望估计一个状态向量，而线性回归中的回归系数扮演着状态向量的角色，所以它们也非常相似。然而，随机性假设略有不同。在卡尔曼滤波器中，我们有马尔可夫假设，假设状态转移与过去无关，并且观测与过去无关。但我们允许状态随时间变化。这在线性回归中是不同的。在线性回归中，我们假设观测在时间上是独立的，并经常用i.i.d.（独立同分布）来表示。然而，我们假设状态在时间上是恒定的，即状态向量不会改变。这是一个重要的区别。&lt;/p&gt;

&lt;p&gt;在卡尔曼滤波器中进行的是增量计算，因此我们不需要存储过去的观测。我们只需要存储我们计算得到的最后一个mu和sigma值，这包含了我们进一步处理所需的所有知识。而在线性回归中，情况不同。在这里，我们需要重复计算回归，因此我们必须以某种方式存储我们要用于线性回归的所有观测。当然，我们可以在时间上使用滑动窗口，只使用最近的10或20个观测，并删除离开滑动窗口的观测。但对于滑动窗口内的观测，我们需要存储它们。&lt;/p&gt;

&lt;p&gt;是这就是我们在这里看到的情况。因此，对于卡尔曼滤波器，我们只需要记住状态和协方差矩阵，而对于线性回归，我们需要记住所有的观测。&lt;/p&gt;

&lt;p&gt;那么观测随时间的影响如何？在线性回归中，所有的观测对线性回归具有相同的影响。无论观测是旧的还是新的，它们对回归的影响基本相同。而在卡尔曼滤波器中，情况不同。如果你分析观测随时间的影响，你会发现随着时间的增加，观测的影响减小。这意味着旧观测只对当前状态估计有很小的影响，而新观测则有很强的影响。在线性回归中，我们也可以通过添加一些额外的权重来模拟这种情况，但在标准回归中，这种情况并不适用。&lt;/p&gt;

&lt;p&gt;如果想要使用卡尔曼滤波器，状态和测量的噪声必须是已知的。因此，我们必须能够提供Q和R矩阵。这在使用卡尔曼滤波器时有时很难推导出来，是使用卡尔曼滤波器的一个重要障碍。而在线性回归中，我们不需要知道噪声，我们只需要知道噪声对所有测量都是相同的，但我们不需要提供任何关于噪声的协方差矩阵。这通常是一个优势。&lt;/p&gt;

&lt;p&gt;我们从卡尔曼滤波器中得到的方差，也就是不确定性的测量结果，随时间基本上呈渐近下降的趋势。而在线性回归中，它们是变化的。有时它们变大，有时变小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230624215021.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;nonlinear-extensions-of-the-kalman-filter-卡尔曼滤波的非线性扩展&quot;&gt;Nonlinear Extensions of the Kalman Filter 卡尔曼滤波的非线性扩展&lt;/h3&gt;

&lt;p&gt;在许多情况下，线性系统模型可能不可用，但需要使用非线性函数来以非线性方式描述系统。这个非线性函数被表示为f，它将时间t的当前状态映射到时间t+1的后继状态。此外，可能还存在一个非线性观测函数，表示为H，它将时间t的当前状态映射到时间t的当前观测集合。在这种情况下，标准的卡尔曼滤波器不适用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625143730.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这种情况下，有几种可以用于扩展卡尔曼滤波器的方法，最简单的方法是使用所谓的扩展卡尔曼滤波器（EKF），它的一个变种是无损卡尔曼滤波器（UKF），还有一个非常通用的扩展是粒子滤波器。接下来，&lt;strong&gt;我们将介绍这三种滤波器的工作原理。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625144002.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;扩展卡尔曼滤波器使用数学技巧，将线性问题的解应用于非线性问题。其思想是在必要时通过使用一阶泰勒多项式作为非线性状态转移函数或观测函数的近似来线性化非线性问题。通过这样做，我们得到了以下形式的预测步骤：&lt;/p&gt;

&lt;p&gt;扩展卡尔曼滤波器（EKF）使用数学技巧将线性问题的解应用于非线性问题。其思想是在必要时通过使用一阶泰勒多项式作为非线性状态转移函数或观测函数的近似来线性化非线性问题。通过这样做，我们得到了以下形式的预测步骤：&lt;/p&gt;

&lt;p&gt;预测步骤：
预测状态向量：μ_t+1_predicted = f(μ_t)
更新协方差矩阵：Σ_t+1_predicted = F_t * Σ_t * F_t^T + Q_t&lt;/p&gt;

&lt;p&gt;在这里，预期的状态向量μ_t具有状态向量的结构，因此我们可以直接应用状态转移函数f来获得预测的状态向量μ_t+1_predicted。然而，更新协方差矩阵并不直接。我们需要使用f的一阶泰勒多项式，而不是直接应用状态转移函数f。矩阵F_t表示非线性函数f在当前状态估计μ_t处的雅可比矩阵。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625144737.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;扩展卡尔曼滤波器的创新步骤与卡尔曼滤波器类似。卡尔曼增益的计算方式类似，但矩阵H_t不是像卡尔曼滤波器中的系统观测矩阵那样。相反，它表示观测函数h的一阶导数。在更新步骤中，我们直接将预测的状态向量μ_t+1_predicted应用于观测函数h，因为μ_t+1_predicted具有状态向量的结构。然而，我们仍然需要使用雅可比矩阵，因为协方差矩阵没有状态向量的形状。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625144801.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与扩展卡尔曼滤波器相比，&lt;strong&gt;无损卡尔曼滤波器(UKF)&lt;/strong&gt; 使用了一种不同的线性化方法。其基本思想是使用代表性点称为Sigma点来表示高斯分布。在二维空间中，这些Sigma点可以被视为捕捉高斯分布形状的点。&lt;/p&gt;

&lt;p&gt;在UKF中，高斯分布通过多个Sigma点而不仅仅是均值向量和协方差矩阵来表示。这些Sigma点被策略性地选择以捕捉高斯分布的形状和传播。通常情况下，对于二维高斯分布，会有五个Sigma点，包括一个位于中心（对应于均值向量）以及每个坐标轴上的两个点。这些点不一定与坐标轴对齐，而可以是倾斜的。&lt;/p&gt;

&lt;p&gt;为了计算Sigma点，协方差矩阵被分成列向量，并且使用这些向量进行计算。具体的计算细节可以在文献中找到。&lt;/p&gt;

&lt;p&gt;下一步是将状态转移函数应用于Sigma点，并将其映射到状态空间中适当的点，以表示后继状态的位置。由于Sigma点具有状态向量的结构，非线性函数f可以直接应用于它们。这样就可以在状态空间中获得其他五个点，表示状态的预测分布。&lt;/p&gt;

&lt;p&gt;第三步是从这些Sigma点重新估计高斯分布。这涉及计算这些点的平均值和传播，以得出新的协方差矩阵和均值向量。再次强调，这些计算的具体细节可以在文献中找到。&lt;/p&gt;

&lt;p&gt;到目前为止，我们已经将系统的非线性动态应用于代表性点。然而，为了考虑到这种转变中的不确定性，需要将协方差矩阵Q表示的附加高斯噪声添加到到目前为止获得的估计协方差矩阵中。&lt;/p&gt;

&lt;p&gt;通过考虑这种附加的不确定性，我们可以实施预测步骤。创新步骤的工作方式类似，为当前状态分布创建Sigma点，然后将这些点应用于观测函数H。从中获得了观测的估计分布，并基于此进行校正步骤。&lt;/p&gt;

&lt;p&gt;有关UKF及其实现的更详细信息，请参考相关文献。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625145425.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example: Determine Ego Motion Visually 通过视觉确定自我运动&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625152341.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，我们需要思考如何对问题进行建模，如何选择状态向量，如何使用转换模型，我们拥有哪些观察数据以及我们需要使用哪种观察模型。让我们从状态向量和状态转换函数开始。运动可以很容易地用速度来描述，因为我们有三个坐标轴，我们使用三个速度变量vx、vy和vz，来描述车辆在各个方向的运动。&lt;/p&gt;

&lt;p&gt;此外，我们需要模拟车辆的转向。我们通过引入三个相对于三个坐标轴的角速度 Omega X、Omega Y 和 Omega Z 来实现这一点。所以总的来说，我们需要六个变量来描述车辆的运动，因此我们的状态向量包含这六个变量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625152440.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于状态转换，我们假设至少在时间局部上，车辆是以恒定速度移动的。这意味着所有的速度变化都只是可能出现的一点点随机性，但总体上，车辆会保持其速度不变。这意味着状态转换模型相当简单，我们可以得出新状态在 t+1 时刻等于旧状态在 t 时刻，换句话说，St+1 等于单位矩阵乘以 St，当然还有一些额外的随机噪声，这些噪声模拟了驾驶员可能会稍微减速、稍微加速或稍微改变转向运动。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625152550.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;观察模型稍微复杂一些。让我们关注四张图片，从时间点 T 和时间点 T-1 的图片对，让我们讨论这些图片之间的关系。首先，我们分析这些图片并选择所有的特征点，例如 shift 特征点或者来自其他特征点方法的特征点。所以在这里，我用一个红色圆圈标出了其中一个特征点，我们可以看到，这个特征点在所有四张图片中的位置都不同，这是由于左摄像头与右摄像头的位置不同，以及摄像头设置在两个连续时间点的不同位置所致。现在，我们想在这四个看到该特征点的图像坐标之间建立一种关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625152640.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，我们知道我们有一个立体相机对，这意味着如果我们在旧的图像对，也就是在时间点 T-1，我们可以取左右摄像头图像的两个位置，并根据这两个图像坐标计算出视差。基于这个计算，我们可以得到该点的三维位置，我们将其表示为 p p（蓝色符号 p p），下标大写的 P 代表前一张图片，第二个下标 L 或 R 代表左或右。&lt;/p&gt;

&lt;p&gt;现在，如果我们知道或者至少对当前状态向量有一个好的猜测，那么我们就知道车辆的速度和角速度。这意味着，如果我们知道该特征点在空间中相对于车辆在时间点 T-1 的位置，如果我们知道车辆的速度，我们就不能预测这个点在时间点 t 时相对于车辆的位置会在哪里。这个三维位置用蓝色符号 p c 表示，大写的 C 代表当前时间点。&lt;/p&gt;

&lt;p&gt;如果我们知道PC，也就是一个点的三维位置，我们可以很容易地使用针孔相机模型将它的位置投影到时间点T的相机图像中，从而得到位置PCL和PCR。我们可以看到，从PPL和PPR开始，通过PP到PC，最后计算PCL和PCR，有一系列的计算过程。这个计算过程是确定性的，当然是非线性的，因为计算一个点的深度需要非线性操作，而且当我们将点投影到图像中时，针孔相机模型也需要非线性操作。尽管我们可能难以将这一系列计算在一个公式中表达出来，但我们可以看到这是一种操作，或者是一系列相对不太复杂、可微分的计算过程。我们可以连贯地进行这些计算，从而建立一个观测模型。&lt;/p&gt;

&lt;p&gt;这个观测模型以状态向量ST和前一图像中特征点的位置（我们视其为常数）为输入，计算出在当前时间点t的相机图像中，这些点的预期位置。正如我们在这里看到的，实际上这些操作中存在一些不确定性，因此我们需要添加一些小的高斯噪声。所以函数h是存在的，我们知道如何计算它，至少理论上我们可以把它写下来，虽然需要一些空间，而且我们知道它是非线性的，但是可微的。&lt;strong&gt;所以我们有一个非线性的观测模型，我们可以使用扩展卡尔曼滤波器或者无迹卡尔曼滤波器来估计车辆的自我运动，也就是状态向量。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625152837.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总的来说，我们有一个六维的状态向量，包含了线性和角速度。我们有一个线性的状态转换模型，我们有一个非线性的观测模型，这意味着我们可以使用扩展卡尔曼滤波器或者无迹卡尔曼滤波器来估计状态向量。在这一点上，我要指出，实际上在图像中我们不只有一个特征点可以用于观测模型，我们有几十个，甚至几百个特征点可以用于观测模型。如果我们有几个这样的点，我们可以在观测模型中同时考虑所有这些特征点，这样做是为了减少运动估计中的误差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625153512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们已经在软件中实现了这个想法，并在我们的实验车辆上进行了测试。在这张幻灯片上，你可以看到结果。四幅图显示了双目相机系统左右相机在现在时间点和之前时间点的相机图像。&lt;strong&gt;黄色的交叉线标记了用于鹰眼运动估计的特征点的位置。红色的交叉线是预测的特征点位置。红色和黄色的交叉线越接近，估计就越好&lt;/strong&gt;。在右边，我们可以看到情况的顶视图。&lt;strong&gt;在右上角，我们可以看到现在时间点的四个相机的布局。相机的当前位置由黑色符号表示，而之前的位置由红色和蓝色符号表示。在右下角，我们可以看到车辆已经走过的路径的顶视图。这条轨迹是通过鹰眼运动估计并积分速度来估计的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625153631.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们开始播放视频。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/c5a016c2-2883-45e2-b692-c38a79ec6ac1.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看到，估计的结果非常符合车辆的运动。现在，车辆停了下来，我们可以看到鹰眼运动也被估计为零。现在，车辆再次加速，我们可以清楚地看到，上一步和当前步骤的相机位置之间的距离正在增大。同样，估计的轨迹看起来相当好。在顶视图中，可以清楚地看到车辆驾驶的曲线。&lt;/p&gt;

&lt;p&gt;以下视频显示了在复杂操作中鹰眼运动估计过程的行为。&lt;strong&gt;在顶部，你可以看到相机图像，底部是估计轨迹的顶视图&lt;/strong&gt;。你可以看到两条线，一条蓝线和一条红线，一条是地面真实位置，另一条是车辆的估计位置或估计轨迹。尽管这个操作相当复杂，但估计的位置和估计的轨迹与地面真实情况相当接近。当然，由于估计过程中的随机性，两条曲线有轻微的偏差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/30285aba-8180-4956-ace9-b60201f4aa99.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;non-gaussian-models--非高斯模型&quot;&gt;Non-Gaussian Models  非高斯模型&lt;/h3&gt;

&lt;p&gt;到目前为止，我们了解的卡尔曼滤波器及其非线性变体适用于所有噪声分布为高斯分布，系统动力学是线性的或至少在局部环境中接近线性的情况。然而，如果这些条件不再满足，也就是说，当我们处理非高斯分布或系统模型与线性函数偏差很大时，我们该怎么办？当然，我们仍然可以推导出当前状态的分布，给出了到目前为止所有的观测，以及未来状态的分布，给出了到目前为止所有的观测。这描述了预测步骤和创新步骤，它生成了预测状态分布和观察后状态分布之间的关系。在符号级别上，这仍然是可能写下来的。然而，这里出现的积分的计算和所有这些分布的表示变得困难。在这些情况下，我们需要对一般的概率密度进行数值表示。我们该如何做？哪些表示存在？我们可以用哪种表示来完成我们的任务？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625161925.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;numerical-representation-数值表示法&quot;&gt;Numerical Representation 数值表示法&lt;/h4&gt;

&lt;p&gt;也许最常见的方法是用&lt;strong&gt;直方图&lt;/strong&gt;来近似概率密度的数值表示。在直方图中，我们将随机变量的空间分割成不同的单元，并为每个单元计算随机变量取值在该单元内的概率。在连续随机变量的最简单情况下，我们用阶跃函数来近似概率密度函数，每个阶跃的高度表示随机变量在此阶跃所表示的区间内取值的概率。这是一种很好的方法，可以很容易地做到。结果是，我们通过对离散变量（即模拟连续随机变量的值落入哪个单元的变量）的分布来表示概率密度。对于离散随机变量，我们已经看到，我们可以使用我们的基本思想，即用创新步骤和预测步骤的算法来估计这个状态。然而，如果我们处理的是高维的状态空间，将这些空间划分为小的单元需要大量的单元，然后整个过程就会变得非常耗时和占用内存。所以，这可能不是表示概率密度的最好方法。一个关键的问题是，概率密度在大部分空间几乎为零，对于这些，我们需要为每个单元保存概率。然而，对于许多这样的单元，概率接近于零，所以我们在表示对我们来说完全不感兴趣的区域时浪费了时间和内存。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625162201.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;直方图的一个替代方案是使用&lt;strong&gt;随机样本来&lt;/strong&gt;表示概率密度。我们做的是，我们会取一个概率密度和这种概率密度的随机数生成器，从这个分布生成一个随机样本。这在底部显示。所以，我们不是使用左边显示的密度函数，而是使用我们从这个分布中随机生成的一组点。这些点在幻灯片上作为小的红色刻度在x轴上显示。&lt;/p&gt;

&lt;p&gt;现在，我们可以&lt;strong&gt;继续基于随机样本进行所有的计算，而不是直接在概率密度函数上进行计算&lt;/strong&gt;。这个想法类似于无迹卡尔曼滤波器的做法，它也为分布生成一些代表性的点，然后&lt;strong&gt;仅在这些点上进行计算&lt;/strong&gt;，而不是对整个密度函数进行计算。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625162227.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看到，对于这种表示，我们可以用更少的样本表示概率密度，因为我们只表示概率密度较高的区域，不表示那些密度几乎为零的区域。然而，这个问题的关键是，我们如何从这样的随机样本中生成新的样本？我们如何对新的样本进行预测，以及如何在观察到新的信息后更新这些样本？这个问题的答案就是粒子滤波器的基础，它是一种基于随机样本的贝叶斯滤波器，也被称为蒙特卡洛滤波器。在下一个章节，我会详细解释粒子滤波器的原理，以及如何用它来解决我们的自我运动估计问题。&lt;/p&gt;

&lt;p&gt;那么我们应该&lt;strong&gt;如何选择权重&lt;/strong&gt;呢？我们应该如何选择它们以使得加权样本可以在恰当的方式下代表概率分布呢？其中一个方法是使用一种称为&lt;strong&gt;重要性抽样&lt;/strong&gt;的技术。在重要性抽样中，我们要处理的是一个目标分布，假设为p，它代表了我们想要建模的分布。我们有一个样本分布，假设为Q，它有另一个概率密度函数，如图中的绿色曲线所示。对于分布Q，我们需要有一个随机数生成器。对于p，我们不需要有这样的生成器。我们所做的就是从分布Q中抽取样本，使用该分布的随机数生成器。然而，我们当然想要表示的是分布p，而不是Q。为了处理p和Q之间的差异，我们使用了重要性权重。在所有目标分布p的概率密度函数明显大于我们已经从中生成随机样本的分布Q的概率密度函数的区域中，我们会增加权重。因为在这些区域，分布Q给了我们远少于我们预期得到的随机样本点。为了补偿这个区域的代表性不足，我们增加了重要性权重。&lt;/p&gt;

&lt;p&gt;在其他区域，分布Q将会提供比我们需要表示分布p的随机样本点更多的样本点。在这些情况下，这个区域在样本中的代表性过高，因此我们降低了这些样本点的重要性权重。&lt;/p&gt;

&lt;p&gt;在数学上，我们选择的重要性权重wi与pi(x_i)和Q(x_i)的比值成正比，其中x_i是我们从分布Q中生成的一个样本点。另外，我们必须保证所有重要性权重的总和等于1，这意味着我们可以把这些重要性权重解释为概率。把这些结合起来，最终产生了一个加权样本，尽管样本点x_i是从分布Q的随机生成器生成的，但最终表示的是分布p。这是一个很好的技巧，可以帮助我们在执行预测和创新算法时大有裨益。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625162337.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来我们来看看我们如何利用这些加权样本来实现创新和预测步骤。&lt;/p&gt;

&lt;h3 id=&quot;particle-filter-粒子滤波&quot;&gt;Particle Filter 粒子滤波&lt;/h3&gt;

&lt;p&gt;假设我们正在处理一个二维状态空间，这里的幻灯片实现了这个二维状态空间的平面。现在，幻灯片上的每一点代表一个状态向量。为了可视化，我们在这里显示了总共五个随机选择的状态向量。也就是说，这五个蓝点应该代表一个有五个元素的样本，这个样本代表了当前的状态分布。点的直径代表重要性权重w_i，直径越大，重要性权重就越大。所以，让我们假设这五个点是一个加权样本，代表了当前的状态分布。现在让我们想一个如何实现预测步骤的方法。&lt;/p&gt;

&lt;p&gt;由于每个样本点都是一个状态向量，我们可以直接对其应用状态转移函数，即使它是一个非常非线性的函数。如果我们这么做，我们会把每个样本点都转换到状态空间的一个新位置。当然，我们必须考虑到状态转移模型不是一个确定性模型，还有一些不确定性，一些随机效应，导致新状态不仅仅是旧状态的转换，还有一定数量的随机性被添加进来或者以某种方式影响了结果。在这种情况下，我们可以生成一些非常小的随机位移，然后把它加到每个状态向量的结果位置上。也就是说，对于每个蓝色的样本点，我们首先应用转换函数，这用黑色的实心箭头表示。然后，我们生成一些小的随机数，把它加到状态转移的终点上，所以最后样本点的新位置是随机向量的终点。随机向量用虚线箭头表示。总的来说，我们以某种方式修改了随机样本，&lt;strong&gt;得到了用绿色点表示的样本&lt;/strong&gt;。我们保持权重不变。&lt;/p&gt;

&lt;p&gt;现在，我们假设我们得到了一个观察值。为了简单起见，让我们假设这里的观测值正好是状态加上一些随机误差。所以我们可以&lt;strong&gt;用红色的十字来表示测量值&lt;/strong&gt;。现在我们能做什么呢？我们如何实现创新步骤呢？在创新步骤中，我们需要比较观测值和我们预期得到的观测值，然后得出结论。对于每个绿色的样本点（其实是状态空间中的向量），我们可以应用观测函数，这会给我们一个预期的观测值，如果绿色点是真正的状态向量的话。然后，我们可以直接比较这个预期的测量值和我们的真实测量值的匹配度如何。根据它们是否匹配，我们可以修改加权的随机样本。修改的最简单方法就是改变权重，也就是说，如果预期的测量值和感知的测量值非常匹配，就增加权重。如果感知的测量值和预期的测量值不匹配，就减少权重。这在图上用增加和减少点的直径来表示。现在，创新之后的&lt;strong&gt;随机样本集用紫色点表示&lt;/strong&gt;。正如我们可以看到的，那些靠近测量值的点（也就是说，这些状态向量非常支持测量值），权重i增加。对于那些远离测量值的点（也就是说，状态向量并不支持测量值），权重会减少。&lt;/p&gt;

&lt;p&gt;现在，我们可以继续下一个预测步骤了。我们&lt;strong&gt;从紫色的样本集&lt;/strong&gt;开始，再次对每个点应用状态转移函数。然后，我们在位置上添加一些&lt;strong&gt;随机向量&lt;/strong&gt;，以模拟状态转移中的随机性。我们得到的是&lt;strong&gt;用黄色表示的点集&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;之后，我们又可以执行一个创新步骤，我们做一个观察，这在幻灯片上用红色十字表示。对于每一个样本向量，我们都会计算它们对这次测量的支持程度。对于那些很好地支持这次测量的样本，我们会增加其权重，而对于那些不支持这次测量的样本，我们会降低其权重。结果以红色圈表示。&lt;/p&gt;

&lt;p&gt;就这样，我们可以继续进行下一个预测步骤，如此反复。这种技术被称为&lt;strong&gt;粒子滤波器，我们用来表示状态分布的点被称为粒子&lt;/strong&gt;。也就是说，一个随机样本点连同其权重被称为一个粒子。是的，这个滤波器被称为粒子滤波器，有时也被称为冷凝滤波器。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625163407.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张幻灯片展示了粒子滤波器的一般操作。它处理一组粒子，每一个粒子都由一个非负的重要性权重w_i和一个状态向量x_i组成，这个状态向量代表了关于当前状态分布的一部分知识。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625164412.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在预测步骤中，我们按照以下方式操作这个粒子集：我们保持所有权重不变，但是我们改变状态向量。为此，我们从给定的前一状态x_i的后继状态的条件分布中生成新的状态向量。这用字母f表示。最简单的情况下，这可能是一个确定性状态转移函数和一个从描述系统转移中不确定性的概率分布生成的附加随机变异的组合。&lt;/p&gt;

&lt;p&gt;下一步是创新步骤，我们假设我们进行了一组测量，基于这些测量，我们再次操作粒子集，但现在我们保持状态向量不变，只更新权重。我们选择新的权重与旧的权重和状态向量如何支持观察成比例。小h代表了一个依赖于状态向量的条件概率密度，它提供了我们期望得到的观测值的分布。&lt;strong&gt;这可以是像一个确定性观察函数加上一些概率密度函数，这个函数模型了在传感器过程中的不确定性。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在我们计算了这些权重之后，我们必须对它们进行归一化，使得所有权重的和等于1。&lt;/p&gt;

&lt;p&gt;现在我们有了新的粒子集，我们可以进行下一个循环了。带有’的粒子集现在成为下一个循环的起点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625164440.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example for Particle Filter&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们看一个非常简单的例子。我们假设一个二维状态空间，我们在这个图中看到。我们进一步假设，状态随着时间的推移从点到点变化，但仅仅在水平坐标轴上产生一个偏移量，并且测量值简单地等于观察值加上一些随机噪声。&lt;/p&gt;

&lt;p&gt;现在，让我们开始粒子滤波器，我们用一个盒区域的均匀分布初始化粒子集。在第一步&lt;strong&gt;预测步骤&lt;/strong&gt;中，我们通过对其应用一个恒定偏移量并向右移动，并添加一些额外的随机向量来预测每一个样本点。&lt;strong&gt;结果以紫色圆圈表示&lt;/strong&gt;。然后是&lt;strong&gt;创新步骤&lt;/strong&gt;，我们做一个测量，这在图上用&lt;strong&gt;绿色星号&lt;/strong&gt;表示。现在我们重新计算所有粒子的权重，&lt;strong&gt;结果是黄色或偏黄色的粒子集&lt;/strong&gt;。如我们所见，那些接近观察值的粒子，它们非常支持这次观察，它们的权重增加，而那些不太支持测量的粒子，它们的权重在减小。现在是下一个预测步骤，我们根据状态动态移动所有粒子，并添加一些随机噪声。最终，我们得到的是&lt;strong&gt;以蓝色样本集表示的结果&lt;/strong&gt;。&lt;strong&gt;再次应用创新步骤&lt;/strong&gt;，我们得到一个测量，&lt;strong&gt;以绿色星号表示&lt;/strong&gt;，并重新计算所有粒子的权重，这&lt;strong&gt;产生了青色粒子集&lt;/strong&gt;。那些接近测量值的粒子，它们的权重在增加，那些远离测量值的粒子，它们的权重在减小。然后是下一个预测步骤，我们根据系统动态移动所有粒子，并添加一些随机噪声。之后，我们得到一个测量，并重新计算所有粒子的权重。&lt;/p&gt;

&lt;p&gt;所以，这个程序工作得很好，但我们已经可以看到，有些粒子的权重在不断增长，&lt;strong&gt;也就是说，它们的权重变得越来越大，而其他粒子的权重变得越来越小，它们的权重在三次迭代之后已经非常接近于零，所以它们不再真正地对我们想要建模的分布有所贡献。如果我们继续这个过程更多步骤，我们会发现，最后只有少数粒子，可能是两三个，或者四个，甚至只有一个的权重明显不同于零，而其他所有粒子的权重都越来越接近于零，或者几乎等于零&lt;/strong&gt;。这种粒子云的退化是个问题，因为只有那些权重明显不同于零的粒子真正地对分布有所贡献，而那些权重几乎为零的粒子不再贡献，它们只是增加了计算负担，但并不能帮助我们得到一个好的状态估计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625164920.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;resampling-重采样&quot;&gt;resampling 重采样&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;我们如何克服退化粒子集的问题呢&lt;/strong&gt;？我们采用的技术来自于统计学，&lt;strong&gt;它被称为自举或重采样&lt;/strong&gt;。所以我们拿到粒子集，我们创建一个新的集合，叫做自举样本，然后我们用自举样本替换原始的粒子集。那是怎么做到的呢？&lt;/p&gt;

&lt;p&gt;为了说明，让我们假设我们有一个由五个粒子组成的粒子集，每一个粒子在这里都以不同的颜色表示，以便于我们后来再识别它们。&lt;/p&gt;

&lt;p&gt;每个粒子的权重在圆圈内给出，我们可以看到这个粒子集是不平衡的，有些粒子有大的权重，比如绿色的，有些粒子有小的权重，比如黄色的或紫色的。&lt;/p&gt;

&lt;p&gt;要创建自举样本，我们从该集合中&lt;strong&gt;随机选择粒子，并以选择某个粒子的概率等于该粒子的权重&lt;/strong&gt;。所以在这种情况下，选择&lt;strong&gt;绿色粒子的概率是40%，选择红色的概率是20%，选择黄色的概率是10%&lt;/strong&gt;，等等。我们可以在我们的自举样本中多次取同一个粒子，也就是说，这是一种有替代的采样。所以在这个例子中，让我们假设我们取了三次绿色的粒子，一次蓝色的粒子，一次紫色的粒子。你会看到，总的来说，粒子的数量保持不变。然而，有些粒子出现了几次，而其他粒子一次都没有出现在自举样本中，特别是那些有高权重的粒子出现了几次，而那些权重小的粒子，他们经常在自举样本中再也不出现。最后，&lt;strong&gt;我们将自举样本中所有粒子的权重重置为1/n&lt;/strong&gt;，&lt;strong&gt;其中n是粒子的数量&lt;/strong&gt;，这样我们最后得到的粒子都有相同的权重。底部的图片显示了结果，注意绿色的粒子出现了三次，所以我们在这里有三个相同的粒子的副本。当然，这有点难以显示，为此，你只看到一个，但你可以看到标注，确实，绿色的粒子在这里有三个副本。现在我们继续粒子滤波器，就像之前一样，我们可以开始预测步骤，然后创新步骤，然后我们会得到新的权重。现在，你可以看到，这个新的粒子集比原来的粒子集更平衡了。&lt;/p&gt;

&lt;p&gt;重采样是一个很有效的工具，可以避免粒子集的退化，但它也有一些缺点。重采样的一个主要缺点是，由于有放回的抽样，有些粒子在重采样过程中可能会被多次选中，而有些粒子可能一次也不会被选中，这可能导致一些重要的信息丢失。此外，如果我们太频繁地进行重采样，那么这个方法就可能导致过度拟合，这就是所谓的重采样退化。为了解决这个问题，通常的做法是使用某种准则来决定何时进行重采样，例如，当有效粒子数下降到总数的一定比例时。有效粒子数可以通过计算所有粒子权重的平方和的倒数来得到。&lt;/p&gt;

&lt;p&gt;这就是粒子滤波器的基本原理。在实际应用中，可能会使用更复杂的版本，其中包括不同类型的预测和更新步骤，以及更复杂的重采样策略。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625165325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们考虑用粒子来建模分布时，我们会遇到这样的退化粒子集，圆圈的直径表示权重，我们看到在边缘有非常非常小权重的微小粒子，而在中心有相当大权重的粒子。现在我们开始重新采样的过程，我们随机从集合中选择粒子，结果可能是这样的。红色的数字表示我们选择某个粒子的次数，例如，在中心我们发现粒子被选择了6次或4次或5次，而在边缘那些粒子只被选择了一次或甚至一次都没有。所以现在我们取那些选中的粒子，我们把他们的权重重置为1/n，然后情况就变成了这样。请注意，图片中间有几个粒子在同一个地方重复出现，所以我们只看到一个，尽管有几个粒子在同一个地方。为了更好地可视化，让我们给这些粒子加上一点随机噪声，这样我们就可以看到在中心确实比在边缘留下了更多的粒子。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625170118.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以让我们再看一下带有重采样的粒子滤波器的操作。我们从一个具有权重wi和状态向量xi的粒子集开始，第一步是预测步骤，我们已经知道这一步。下一步是创新步骤，这也是和我们之前做的一样。现在，我们不再把在创新步骤中获得的这个粒子集作为下一个预测步骤的起点，&lt;strong&gt;我们在两者之间做一个重采样步骤。这意味着我们通过替换采样创建一个新的粒子集&lt;/strong&gt;，这个幕后的M字母在这个幻灯片上表示一个多项概率分布，这意味着一个概率分布，描述了我们有n个可能的粒子可以选择，选择每个粒子的概率与重要性权重成正比，我们选择n个新粒子，这意味着粒子集的大小保持不变。&lt;/p&gt;

&lt;p&gt;重采样的粒子集现在成为下一个预测步骤的起点，就像这样我们继续。所以，粒子滤波器的重采样包括三个步骤：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625170303.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;让我们&lt;strong&gt;比较一下我们在这一章中得到的过滤器&lt;/strong&gt;，&lt;strong&gt;卡尔曼滤波器，扩展卡尔曼滤波器，无迹卡尔曼滤波器和粒子滤波器&lt;/strong&gt;。卡尔曼滤波器，扩展卡尔曼滤波器和无迹卡尔曼滤波器都是在连续状态变量上工作的，这创造了数据变量不能被这些滤波器包含在内。粒子滤波器更通用，它可以处理连续随机变量，离散随机变量，也可以处理这些类型随机变量的混合。也就是说，状态向量可能由一些连续随机变量和一些离散随机变量组成。在观测空间中，我们有同样的情况，所以卡尔曼滤波器，扩展卡尔曼滤波器和无迹卡尔曼滤波器只能处理连续的观测变量，所以测量值是实数。粒子滤波器再次很通用，所以它可以处理连续和离散的观测，它也可以处理两者的组合。我们可以在卡尔曼滤波器中使用什么模型？当然，我们只能使用线性高斯模型。对于扩展卡尔曼滤波器和无迹卡尔曼滤波器，我们可以放宽这些条件，我们坚持高斯模型，但是转换函数和观测函数可能是非线性的，至少稍微非线性。粒子滤波器并不限制分布的种类和转换函数的种类，它可以处理任何模型。&lt;/p&gt;

&lt;p&gt;我们需要执行哪些操作来执行卡尔曼滤波器或其他滤波器？在卡尔曼滤波器中，我们只需要线性操作，乘法矩阵，加上向量和矩阵，最复杂的操作是计算一个矩阵的逆。对于扩展卡尔曼滤波器，情况也一样，此外，我们还要计算导数，也就是状态转换函数和测量函数的雅可比。在无迹卡尔曼滤波器中，我们需要生成Sigma点，然后对Sigma点进行操作。在粒子滤波器中，我们需要的是采样和重采样，所以只是一些随机化操作。&lt;/p&gt;

&lt;p&gt;这些我们需要的操作在计算上都相当cheap，至少对于卡尔曼滤波器来说，只要状态空间不是太大。当然，反转一个500x500的矩阵并不容易，但是对于相当小的状态空间，卡尔曼滤波器的操作并不计算昂贵。对于扩展卡尔曼滤波器，情况几乎相同，只是导数的计算可能需要一些额外的工作量。对于无迹卡尔曼滤波器，计算的计算工作量仍然很小，我们需要在Sigma点上应用状态转换函数，Sigma点的数量与状态轴的数量线性减小，这意味着状态变量的数量。对于粒子滤波器，我们得到了每个粒子非常简单和便宜的操作，然而，因为我们通常有数百个，数千个甚至数百万个粒子，所以粒子滤波器在计算上要昂贵得多。所以，更大的计算开销让我们可以处理更复杂的模型。我们得到的结果的准确性如何？当然，这只适用于满足各自滤波器条件的情况。如果我们可以应用一个卡尔曼滤波器，并且模型真的是一个高斯线性模型，那么卡尔曼滤波器的结果将是高度准确的。对于扩展卡尔曼滤波器和无迹卡尔曼滤波器，只要转换和测量函数不是太离线性，情况也是一样的。对于粒子滤波器，准确性高度依赖于粒子数量。对于小的粒子集，准确性较低。对于非常大的粒子集，可能有数百万或数十亿的粒子，准确性与卡尔曼滤波器一样高。然而，在实践中，你通常不能承担为数百万或数十亿粒子做所有的计算，因此，在实践中的准确性通常较低。我们将在第六章看到一个粒子滤波器的例子，它用于自我定位。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230625170511.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：这一章讲述了在三维空间中跟踪对象。我们从回归作为跟踪对象的技术开始，主要关注线性运动模型，这是一种不需要太多先验信息就能成功的简单技术，所以如果可能的话，尝试使用回归模型。然后我们转向马尔可夫过渡模型，即隐藏马尔可夫，我们描述了系统状态，我们提到了马尔可夫假设的随机独立性，这是非常重要的，因为它使得在这种模型中进行有效计算成为可能。最后，我们推导出了一个通用的滤波器模板，其中包含了预测和创新步骤，用来从一系列观测中估计这样一个隐藏马尔可夫模型的状态。&lt;/p&gt;

&lt;p&gt;基于隐藏马尔可夫模型的滤波器主要分为两类：卡尔曼滤波器家族和粒子滤波器。卡尔曼滤波器，包括扩展卡尔曼滤波器和无迹卡尔曼滤波器，适用于线性高斯模型或至少接近线性高斯模型的情况。如果我们不能满足这些限制条件，那么我们就要转向粒子滤波器，它更加通用，可以处理任何形式的模型。然而，代价是在计算方面要更加消耗资源。&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/05-Tracking-Moving-Objects/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/05-Tracking-Moving-Objects/</guid>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-4-optical-flow-and-image-based-tracking--光流和基于图像的跟踪&quot;&gt;Chapter 4: Optical Flow and Image Based Tracking &lt;br /&gt; 光流和基于图像的跟踪&lt;/h1&gt;
&lt;p&gt;欢迎来到《汽车视觉》讲座中关于光流和基于图像的跟踪的章节。&lt;/p&gt;

&lt;p&gt;首先，让我们看一下文献。这里有几篇来自教科书和原创论文的章节，涉及到今天讨论的主题。前三个条目是教科书的一部分，介绍了光流估计的主题。第四篇出版物是一篇原创论文，描述了Hon和Chun的方法。如果你有兴趣阅读原始论文，最后一篇论文涉及内核化相关滤波器，这在本章后半部分讨论图像中的物体跟踪时已经介绍过。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;B. Jähne, Digitale Bildverarbeitung, Springer, 2005, Chapter 14&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;E.R. Davies, Machine Vision. Theory. Algorithms. Practicalities. Elsevier, 2005,Section 21.6 ff&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;R. Jain, R. Kasturi, B. G. Schunck, Machine Vision. McGraw Hill, 1995, Section 14.1-14.4&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;B. K. P. Horn, B. G. Schunck, Determining Optical Flow. Artificial Intelligence 17, 1981, pg. 185-203&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;J. F. Henriques, R. Caseiro, P. Martins, J. Batista, High-Speed Tracking with Kernelized Correlation Filters, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 37, no. 3, pp. 583-596, 2015&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-sequences-图像序列&quot;&gt;Image Sequences 图像序列&lt;/h2&gt;

&lt;p&gt;到目前为止，我们&lt;strong&gt;已经研究了单幅灰度图像或双目摄像头设置中的成对灰度图像&lt;/strong&gt;。现在，我们想把这种分析&lt;em&gt;扩展到&lt;/em&gt;&lt;strong&gt;随着时间推移记录的灰度图像序列&lt;/strong&gt;。为此，我们用第三个变量T来扩展灰度函数，它代表记录的时间。在我们的案例中，我们将T解释为一个整数，用来计算到现在为止记录的图像数量。&lt;/p&gt;

&lt;p&gt;到目前为止我们有：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;examined single images $g(u, v)$&lt;/li&gt;
  &lt;li&gt;examined stereo images $\left(g_l(u, v), g_r(u, v)\right)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;图像序列：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;examine a sequence of images $g(u, v, t)$&lt;/li&gt;
  &lt;li&gt;观测图像随时间的变化&lt;/li&gt;
  &lt;li&gt;自我运动(ego motion)引起的变化&lt;/li&gt;
  &lt;li&gt;观察物体运动引起的变化&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;optical-flow-光流&quot;&gt;Optical Flow 光流&lt;/h2&gt;

&lt;p&gt;光流是由相机和观察对象之间的相对运动引起的图像中任何点的明显移动&lt;/p&gt;

&lt;p&gt;我们感兴趣的是观察图像序列中发生的变化，这些变化可能&lt;strong&gt;是由相机的自我运动、图像中观察到的物体的运动或两者的组合引起&lt;/strong&gt;的。&lt;/p&gt;

&lt;p&gt;这就引出了光流的第一个定义： &lt;strong&gt;光流是图像中任何一点的明显移动，由相机和被观察物体之间的相对运动引起&lt;/strong&gt;。重要的是要看到，光流是图像空间中的一个属性。它是图像坐标中的一个矢量，它连接了前一幅图像中某一点的位置和后一幅图像中同一点的位置。它不是一个物体的三维运动，而是图像空间中的二维运动。&lt;/p&gt;

&lt;p&gt;这里我们有一个非常简单的例子，就是两幅图像一个接一个地记录下来，我们可以很容易地观察到一些光流。我们可以看到情况是如何变化的，某些点是如何在两幅图像之间移动的，这种移动就是光流。我们可以区分两种不同的光流概念。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/8f91a500-9003-4cd8-81a4-46248963f96d.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一个概念叫做&lt;strong&gt;密集流&lt;/strong&gt;，我们的目标是为图像中的每一个点计算一个流向量，或者至少计算尽可能多的点，从而形成一个完整的流场或流向量场。&lt;/p&gt;

&lt;p&gt;第二个概念是&lt;strong&gt;稀疏流&lt;/strong&gt;，我们只对获得特定兴趣点的光流向量感兴趣，例如图像中突出特征点的一个子集。这建议使用特征点方法，我们分析每张图像，检测特征点，然后比较第一张图像中的哪些特征点也能在随后的图像中找到。这种方法使我们能够为特征点创建稀疏的流向量。&lt;/p&gt;

&lt;p&gt;然而，这并不足以实现密集流，因为图像中的许多点不是特征点，我们用这种方法不会得到这些点的流向量。&lt;/p&gt;

&lt;p&gt;– 密集流：我们确定图像中每个点的流矢量
– 稀疏流：我们仅为（一小部分）显着点（例如特征点）确定流向量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Typical Optical Flow Fields 典型光流场&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们研究一下在某些情况下我们可以期待的典型流场。让我们假设我们有一个平面世界，在这个世界里，一辆车正笔直地向前行驶，我们观察到地面在一条水平线以下。在这些条件下得到的光流向量显示在左上方的图像中。每个流向量都用黑线标出，红色菱形表示第一幅图像中的相应点。&lt;/p&gt;

&lt;p&gt;我们可以观察到，流动向量正在向地平线上的一个虚拟点靠拢，流动向量的长度根据与摄像机的距离而变化。点越远，流动矢量越小。在天空中，我们无法确定任何流动矢量，因为那些点实际上位于很远的地方，导致流动等于零。&lt;/p&gt;

&lt;p&gt;第二张图片描述了一个类似的情况，但有一个俯仰运动。如果我们想象坐在一辆汽车里，有人把车头往下推，然后松开，造成俯仰运动，流场看起来与直行驾驶的情况类似。然而，在这种情况下，我们在地平线上仍然有不同于零的流向，而且流向的整体方向也不同。&lt;/p&gt;

&lt;p&gt;第三张图片显示了滚动运动，当车辆沿其纵轴倾斜时，就会出现这种情况，就像摩托车在弯道上行驶一样。流场表现为滚动运动。当然，这种滚动运动也可以与直线行驶的运动相结合，导致不同的整体流场，如第四张图片所描述的，车辆向右行驶通过一个曲线。&lt;/p&gt;

&lt;p&gt;道路上的预期流&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203326.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;光照是恒定的。&lt;/li&gt;
  &lt;li&gt;目标点没有被遮挡。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些是我们在这些情况下可能观察到的典型光流场。只是为了让您对其外观有一个概念。现在让我们讨论如何计算光流。一种方法是了解场景中所有物体的真实运动和三维场景结构，然后可以计算光流。然而，这不是我们的目的。我们的目标是直接从图像序列中提取光流。&lt;/p&gt;

&lt;p&gt;为了做到这一点，我们做出了一些假设。首先，我们假设图像序列是在恒定照明下记录的，这意味着每个点的亮度随时间不变。第二个假设是我们要观察的点不会在视频序列中的任何图像中被遮挡。如果被遮挡，我们就无法计算光流。这个假设是相当明显的。&lt;/p&gt;

&lt;p&gt;基于这些假设，我们为光流建立了一个条件。我们引入光流向量ΔUΔV，描述了某个点的光流，表示为U B。&lt;/p&gt;

&lt;p&gt;由于我们假设该点的照明在时间上不变，我们可以得出结论，先前图像中该点的灰度值（在时间T）必须等于稍后图像中位置为U + ΔU，V + ΔV，T + ΔT的像素的灰度值。这个必要条件要求ΔUΔV是位置U，V处点的光流。然而，这还不足够，因为可能有许多点满足这个等式。&lt;/p&gt;

&lt;p&gt;从这个必要条件出发，我们想推导出如何计算ΔU和ΔV。我们从等式的两边减去U，V，T处的灰度G，然后用一阶泰勒多项式替换右边的第一部分。这得到了一个名为“&lt;strong&gt;运动约束方程&lt;/strong&gt;”的方程。这个方程提供了一个条件，必须满足ΔUΔV才能成为某个像素位置的光流。&lt;/p&gt;

&lt;p&gt;重要的是要注意，运动约束方程中需要的所有偏导数都是在用于计算光流的第一个图像对的某个位置处计算的。&lt;/p&gt;

&lt;p&gt;光流的必要条件：&lt;/p&gt;

\[g(u, v, t)=g(u+\Delta u, v+\Delta v, t+\Delta t)\]

&lt;ul&gt;
  &lt;li&gt;必要但不充分。&lt;/li&gt;
  &lt;li&gt;不够清晰&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203515.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运动约束方程：&lt;/strong&gt;&lt;/p&gt;

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

&lt;p&gt;– 偏导数从何而来？&lt;/p&gt;

&lt;p&gt;使用导数滤波器掩模（例如Sobel）进行滤波会产生$\frac{\partial g}{\partial u}, \frac{\partial g}{\partial v}$&lt;/p&gt;

&lt;p&gt;灰度值差异产生 $\frac{\partial g}{\partial t} \approx g(u, v, t+1)-g(u, v, t)$&lt;/p&gt;

&lt;p&gt;那么，我们如何计算这些偏导数呢？关于U和V的偏导数是我们在本课程的第一章中已经推导出来的。我们可以使用滤波器掩模，如Sobel滤波器掩模，从灰度图像中计算这些偏导数。所以这不是什么新东西，可以很容易地完成。关于时间方向的灰度值函数的偏导数也很容易计算。我们可以通过比较后续图像中的灰度值与当前图像中的灰度值（都在所关注的位置上进行评估）来近似计算它。这个近似给出了这个偏导数的近似值。因此，我们只需要灰度值信息来计算这些偏导数。从一对图像中，我们获得了一个以运动约束方程形式的约束，其中有未知的Delta U和Delta V。因此，从一对图像中，我们得到一个约束。&lt;/p&gt;

&lt;p&gt;让我们看一下运动约束方程的简单示例。为此，我们将分析一个一维信号，即图像的一行，其中整个光流是向左或向右移动的，由一维向量Delta U表示。假设我们有一个用青色表示的灰度值函数，对于较小的U值有较小的值，对于较大的U值有较大的灰度值。我们要分析的是位于虚线所示位置U处的光流。我们假设在后续图像中，我们有相同类型的灰度值斜坡，但向右移动了一定的距离。后续图像的新灰度值函数由蓝色曲线表示。&lt;/p&gt;

&lt;p&gt;一维信号的图示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203815.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们正在寻找的光流代表了向右的移动，如这个水平向量所示。对于时间方向的偏导数测量了感兴趣位置U的灰度值函数的变化。在这种情况下，我们可以观察到灰度值已经减小，因此这个偏导数可以用指向下方的垂直箭头来表示，与坐标轴相反。因此，这个导数的值是负数。&lt;/p&gt;

&lt;p&gt;此外，我们知道，对于空间方向U，灰度级梯度可以被解释为感兴趣位置的灰度值函数的斜率。可以从灰度值函数的切线绘制的虚线红线来测量斜率，如此处所示。通过将这个虚线红线移动到垂直箭头的末端，我们可以观察到在灰度值遵循线性逼近的最佳情况下，我们得到一个三角形。这个三角形可以用来计算切线的斜率，该斜率大约等于垂直箭头长度与水平箭头长度的比值。由于垂直箭头向下指向，与坐标轴相反，我们需要添加一个负号来表示这个导数的负值。这给出了右侧所示的方程。如果我们将两边都乘以Delta U，我们就得到了一维情况下的运动约束方程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运动约束方程：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这种方法可以直接扩展到二维情况。然而，有一个重要的区别。在一维信号的情况下，我们可以很容易地通过解方程相对于Delta U来计算Delta U，并获得Delta U的估计值。在二维情况下，这是不可能的，因为一个方程不能为两个未知变量提供解。&lt;/p&gt;

&lt;p&gt;那么，我们该如何解决这个问题呢？关键是添加额外的方程，以获得两个未知变量Delta U和Delta V的多个方程。为此，我们假设光流在相邻点之间没有显著变化。我们假设右侧和左侧相邻像素的光流，以及上方、下方或对角线相邻像素的光流完全相同。通过为每个相邻像素计算一个运动约束方程，我们可以创建一个具有多个方程和两个未知数的线性方程组。&lt;/p&gt;

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

&lt;p&gt;– 问题：一个方程，两个未知变量
– 附加假设：光流在局部环境中是恒定的。&lt;/p&gt;

\[\begin{aligned}
-\frac{\partial g(u, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v, t)}{\partial v} \\
-\frac{\partial g(u-1, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u-1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u-1, v, t)}{\partial v} \\
-\frac{\partial g(u+1, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u+1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u+1, v, t)}{\partial v} \\
-\frac{\partial g(u, v-1, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v-1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v-1, t)}{\partial v} \\
-\frac{\partial g(u, v+1, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v+1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v+1, t)}{\partial v}
\end{aligned}\]

&lt;h3 id=&quot;lucas-kanade-method-卢卡斯-卡纳德方法&quot;&gt;Lucas-Kanade Method 卢卡斯-卡纳德方法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;在计算机视觉中，卢卡斯-卡纳德方法是一种广泛使用的&lt;strong&gt;光流估计的差分方法&lt;/strong&gt;，这个方法是由Bruce D. Lucas和Takeo Kanade发明的。&lt;strong&gt;它假设光流在像素点的邻域是一个常数，然后使用最小平方法对邻域中的所有像素点求解基本的光流方程&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;通过结合几个邻近像素点的信息，卢卡斯-卡纳德方法(简称为L-K方法)&lt;strong&gt;通常能够消除光流方程里的多义性&lt;/strong&gt;。而且，与逐点计算的方法相比，&lt;strong&gt;L-K方法对图像噪声不敏感&lt;/strong&gt;。不过，由于这是一种局部方法，所以在图像的均匀区域内部，&lt;strong&gt;L-K方法无法提供光流信息&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果我们有确切的两个方程和两个未知数，我们可以希望从这些方程中获得唯一解。如果我们有多于两个方程，由于随机性引起的方程之间的冲突，很可能我们找不到任何解。然而，我们可以通过说明我们不需要找到Delta U和Delta V以使运动约束方程完全相等来克服这个问题。相反，我们希望找到尽可能多地满足方程的Delta U和Delta V，这可以通过最小化这些方程的残差平方和来实现。残差表示运动约束方程的左右两侧之间的差异。&lt;strong&gt;这种方法被称为计算某一点的光流的Lucas-Kanade方法&lt;/strong&gt;。这种方法的思想是在感兴趣点周围的某个区域内最小化残差平方和，例如最近的3x3像素的正方形区域。&lt;/p&gt;

&lt;p&gt;可以通过最小化二次误差来估计光流&lt;/p&gt;

\[\begin{aligned}
\operatorname{minimize}_{\Delta u, \Delta v} \sum_{(i, j) \in\{-1,0,1\}^2}\left(\frac{\partial g(u+i, v+j, t)}{\partial t}\right. &amp;amp; +\Delta u \cdot \frac{\partial g(u+i, v+j, t)}{\partial u} \left.+\Delta v \cdot \frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

&lt;p&gt;解决这个优化问题后，我们获得了Delta U和Delta V。解决方案涉及计算要最小化的函数相对于两个未知变量Delta U和Delta V的偏导数。然后将这些导数置零，并解出所得到的方程组，得到一个2x2矩阵&lt;/p&gt;

&lt;p&gt;左边乘以未知变量的向量Delta U和Delta V（表示光流向量），等于右边具有两个条目的向量。矩阵和右边的向量可以从灰度值梯度信息计算得出，因此不需要额外的信息。如果左侧的矩阵具有满秩，我们将得到该方程组的唯一解。&lt;/p&gt;

&lt;p&gt;在推导后并置零:&lt;/p&gt;

\[\begin{aligned}
\left(\begin{array}{ll}
G_{u u} &amp;amp; G_{u v} \\
G_{u v} &amp;amp; G_{v v}
\end{array}\right)\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \quad \text { with } G_{u u} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
G_{u v} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t) \partial g(u+i, v+j, t)}{\partial v}\right) \\
G_{v v} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2 \\
G_{u t} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial t}\right) \\
G_{v t} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v} \frac{\partial g(u+i, v+j, t)}{\partial t}\right)
\end{aligned}\]

&lt;p&gt;这里提供了Lucas-Kanade方法如何计算光流向量的示例。在左侧，我们看到输入图像，它看起来非常模糊。事实上，模糊性实际上有助于Lucas-Kanade方法找到一些光流向量。在右侧，我们看到了每个像素的计算光流，根据下方提供的彩色轮进行了颜色编码。光流为0的向量将由白色像素表示。彩色轮显示了向量指向的方向，以及它的长度。高饱和度的颜色对应于较长的向量，而较低饱和度的颜色表示较短的向量。U值（红色、绿色或蓝色）确定向量指向的方向。从可视化结果中，我们可以观察到获得了一些光流向量，但并不是对所有点都获得了光流向量。此外，并非所有计算出的光流向量都是合理的，例如左下角的绿色向量。&lt;/p&gt;

&lt;p&gt;总的来说，Lucas-Kanade方法提供了一种通过制定和求解使用运动约束方程和最小化残差平方和的线性方程组来估计光流的方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204331.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204345.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;编码：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和度（saturation）= 向量长度&lt;/li&gt;
  &lt;li&gt;色调（hue）= 方向&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;线性近似的极限&quot;&gt;线性近似的极限&lt;/h3&gt;

&lt;p&gt;在所示的示例中，我们有一个一维灰度值图像，具有较大的移动，导致较长的光流向量。原始的灰度值函数由蓝色曲线表示，而后续图像的灰度值函数则显示为红色。&lt;/p&gt;

&lt;p&gt;为了使用Lucas-Kanade方法计算光流，我们首先确定虚线橙色线所示位置的灰度值函数的斜率。我们计算随时间的灰度值变化（红色垂直箭头），并将切线线移到垂直箭头的顶部，得到移动的橙色线。连接原始位置和移动的橙色线的水平向量表示由Lucas-Kanade计算得到的光流向量。&lt;/p&gt;

&lt;p&gt;然而，在这种情况下，光流向量显著低估了实际光流。为了解决这个问题，我们比较一下如果我们将原始灰度值函数向右移动光流量的话，灰度值函数会是什么样子。我们得到了黑色曲线，它与蓝色曲线或后续图像中的真实灰度值相差很大。&lt;/p&gt;

&lt;p&gt;虽然存在很大差异，我们可以继续使用Lucas-Kanade方法计算光流，但基于黑色灰度值函数而不是原始的蓝色正弦曲线。我们迭代这个过程，计算灰度值差异并移动切线，以获得额外的光流估计。这些估计与先前计算得到的光流向量连接起来。&lt;/p&gt;

&lt;p&gt;通过迭代执行Lucas-Kanade方法，我们可以获得比仅执行一次时更好的光流向量。这种迭代方法类似于使用牛顿法寻找函数零点。&lt;/p&gt;

&lt;p&gt;线性近似不足以进行较大的偏移&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204456.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;– 也可以使用迭代计算（牛顿法）确定光流&lt;/p&gt;

&lt;p&gt;图中展示了迭代的Lucas-Kanade方法的结果，其中光流向量与实际光流相比较之前的尝试更接近。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204518.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204527.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;编码：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和度（saturation）= 向量长度&lt;/li&gt;
  &lt;li&gt;色调（hue）= 方向&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aperture-problem-光圈问题&quot;&gt;Aperture Problem 光圈问题&lt;/h3&gt;

&lt;p&gt;除了可以使用迭代的Lucas Granada方法解决的问题外，还存在另一个问题，称为光圈问题（aperture problem），它会给Lucas Granada方法带来麻烦。让我们进行一个实验，假设有一个场景，我们只能通过百叶窗中的一个小孔来看到，这意味着整个场景可以被视为相机的镜头，百叶窗则可以被视为相机内部的百叶窗。因此，我们只能看到世界的一个小区域，在我们的实验中，我们感知到的这个小区域有一些白色背景和一些黑色物体，这些物体最初只出现在孔的左边界上。现在这个物体进行了一次移动，我们来看一下。&lt;/p&gt;

&lt;p&gt;最后，物体以某种方式移动了，问题是我们观察到了哪种运动？显然，物体似乎是从左向右移动的，但这是完整的事实吗？我们能够唯一确定这个运动吗？&lt;/p&gt;

&lt;p&gt;为了回答这个问题，让我们看一下百叶窗的背面，看看实际发生了什么。&lt;/p&gt;

&lt;p&gt;在这里，我们可以看到我们实验的初始情况。现在我们开始这个运动，我们可以看到这个运动不仅仅是从左到右，而是沿着对角线方向的运动，因此还涉及到垂直运动，这是我们在示例中无法看到的。这个例子表明，我们可以感知到运动的部分，但无法完全感知到整个运动，在某些情况下。让我们稍微改变一下我们的例子，在这个例子中，我们改变了我们看到的物体的形状，现在我们再次进行运动，我们清楚地看到这是一个沿对角线方向的运动。因此，虽然场景只稍微改变，但完整的运动变得明显起来，那么这两个例子之间的区别是什么？在第一个例子中，我们只能观察到一个灰度值的边缘，而在第二个例子中，我们可以观察到一个灰度值的角落，这就产生了重要的区别。如果我们能观察到一个角落，我们就能确定完整的运动，如果我们只能观察到一个边缘，我们只能观察到运动的部分。&lt;/p&gt;

&lt;p&gt;我们看到什么样的运动？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/03832927-14d5-495f-b065-cff87f9ea7ab.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/0963d66a-dabc-413f-a168-328f524f8e54.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/8ced9aa5-60e4-415e-ae86-fe9f085c179e.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么什么情况下可以解决Lucas-Kanade方法呢？
如果我们观察公式，我们可以看到涉及一个2x2矩阵，其中包含一些偏导数。当矩阵G具有满秩时，我们可以得到线性方程组的唯一解。
如果它的秩只有1，我们可能得到一组解，也就是说我们没有唯一解；
如果这个矩阵的秩为零，那么所有可能的向量或光流向量都满足这个矩阵，这意味着所有向量都能解决这个方程，我们就无法得到Lucas-Kanade的唯一解。
重要的性质是矩阵G具有满秩，因此它是可逆的。
如果满足条件，我们就能得到唯一解。这适用于当这个矩阵的两个特征值都大于零且远大于零时。&lt;/p&gt;

&lt;p&gt;需要强调的是，这种矩阵始终具有两个实特征值，并且它们都是非负的，但重要的是它们不等于零，也不接近零，而是远离零。如果这两个特征值都满足条件，那么矩阵G是可逆的，并且这种反转也对相机图像中的随机影响具有稳定性。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \underbrace{\left(\begin{array}{ll}
G_{u u} &amp;amp; G_{u v} \\
G_{u v} &amp;amp; G_{v v}
\end{array}\right)}_{=: G}\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \\
&amp;amp; G_{u u}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
&amp;amp; G_{u v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial v}\right) \\
&amp;amp; G_{v v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;矩阵 G 是可逆的&lt;/li&gt;
  &lt;li&gt;G 的特征值都近似相等且 &amp;gt; 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么什么情况下会发生这种情况呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;如果我们观察均匀区域，我们会发现矩阵G的元素几乎都等于零，如果它们都等于零，特征值将是0和0，这意味着我们无法得到唯一解，这是一个糟糕的情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另一个糟糕的情况是灰度边缘，无论是水平还是垂直的边缘，在这种情况下，矩阵G有两个特征值，其中一个是零或接近零，另一个与零不同，对于所有灰度边缘（包括对角线边缘等），都是如此。
这也是我们无法得到Lucas-Kanade方法唯一解的情况。然而，正如我们所见，该方法仍然能够揭示关于运动的一些信息，但不是全部信息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在灰度角点的情况下，我们通常会得到两个不为零的特征值，因此这是一个好的情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;同样地，如果我们处理孤立点，我们会得到与零不同的特征值，所以这也是一个好的情况。这个思想类似于Stephen Harris角点检测器，并且在位移计算中也可以找到。基本思想仍然是相同的。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211225.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;variational-approach-变分法&quot;&gt;Variational Approach 变分法&lt;/h3&gt;

&lt;p&gt;由于我们面临着获取满秩矩阵G的问题，我们可能会问，我们计算矩阵G时应该考虑多大的环境范围。
我们只应该考虑像素感兴趣的直接邻居，还是应该考虑间接邻居？
我们应该考虑多少像素？我们可以一般性地增加环境的面积，也可以减小它。
那么最好的做法是什么呢？如果我们选择一个非常小的环境，很明显，我们很可能遇到我们刚刚看到的问题，也就是所谓的光圈问题。在这种情况下，矩阵G的秩不满，我们无法得到唯一解，因为环境中没有足够的纹理、结构，这使我们无法观察到完整的运动。&lt;/p&gt;

&lt;p&gt;因此，我们可能会提出这样的问题：为什么不使用较大的环境来计算这个大写字母G呢？
然而，如果我们选择一个非常大的环境，我们可能会遇到其他问题。
当然，环境越大，我们需要进行所有计算的计算时间就越长。
更重要的是，如果我们选择了大的环境，我们可能会将不同物体的运动混淆在一起，因为在大的环境中，很可能我们不只观察到一个单独的物体，而是可能观察到几个不同的物体，它们以不同的方式运动。
因此，我们计算出的是几个物体不同运动方式的混合。&lt;/p&gt;

&lt;p&gt;因此，这两种选择都不是最佳的，我们可能需要在这两个思想之间做出一些平衡。&lt;/p&gt;

&lt;p&gt;这些方法的优点是我们可以获得几乎所有图像像素的光流向量。然而，缺点是需要大量计算来解决这些大规模优化问题，因此无法实时运行，只适用于批量处理记录的图像。这些方法更适合于批量处理记录的图像。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211701.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;霍恩和肖克最初的方法奠定了变分方法的基础。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;变分方法：假设光流在相邻像素中相似。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在变分方法中，基本思想是根据环境的特性进行自适应选择。如果处于均匀区域，可能需要选择较大的环境；如果处于纹理丰富的区域，可能更倾向于选择较小的环境。这是一种基本的思路，如何表达这个思想并使其更加普适呢？&lt;/p&gt;

&lt;p&gt;早在上世纪80年代，Horn和Schunck提出了一套基于变分方法的光流计算方法，后来的一系列方法都是基于这个思路。这些方法的基本思想是，不是单独估计每个点或单个点的光流向量，而是并行估计所有像素点的光流向量，并建立一个大规模的优化问题，将相邻像素的光流向量之间建立关系。通过这种方式，避免了对环境的特定选择，使其更加灵活。&lt;/p&gt;

&lt;p&gt;具体来说，假设我们有一幅灰度图像，包含一组像素点。对于每个像素点，我们可以推导出运动约束方程，该方程建立了像素点的灰度值和光流向量之间的关系。我们假设相邻像素的光流向量是相似的，它们可能是相等的，或者至少在像素之间变化不大。我们通过一个条件来表达这种相似性，即希望相邻像素的光流向量之间的差异接近于零。&lt;/p&gt;

&lt;p&gt;现在，我们有了一组从运动约束方程得出的条件，以及确定相邻光流向量相似性的条件。我们可以基于这些条件建立一个大规模的优化问题，然后使用数值方法来解决这个优化问题，以并行地找到所有像素点的光流向量。这里不详细介绍具体的方法，只是介绍了这个基本思路。&lt;/p&gt;

&lt;p&gt;这些方法的优点是可以为几乎所有像素点计算光流向量，缺点是需要大量计算来解决这些大规模的优化问题，因此无法实时工作，只适用于批量处理记录的图像或视频。&lt;/p&gt;

&lt;p&gt;如果想了解更详细的信息，请参考提供的参考文献，其中介绍了变分方法在光流计算中的基本原理和扩展。当然，Horn和Schunck的方法已经不再是最新技术，现在有许多对这种方法进行了改进并获得更好结果的扩展方法。不过，让我们先看一下Horn和Schunck方法的结果，以了解这些变分方法的工作原理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212309.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，当今已经有很多对这种方法的扩展，比基本的霍恩和肖克方法表现更好。
不过，让我们看一下霍恩和肖克的结果，以了解这些变分方法是如何工作的。
我们从之前使用卢卡斯-卡纳达方法的示例开始，然后应用霍恩和肖克的方法，经过长时间的计算后，我们得到下面的结果。&lt;/p&gt;

&lt;p&gt;我们可以看到，现在光流向量的估计比之前要好得多，尽管仍然存在一些估计错误和箭头状的伪影，但整体估计效果更好。我们还可以看到，平均光流向量的长度比卢卡斯-卡纳达方法更大，并且相邻像素更可能具有相似的光流向量，因为这是变分方法中引入的内容。&lt;/p&gt;

&lt;p&gt;基于变分方法的解决方案：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;变分优化问题，类似于随机场&lt;/li&gt;
  &lt;li&gt;数值迭代计算&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;无法实时运行&lt;/strong&gt;！&lt;/li&gt;
  &lt;li&gt;有关详细信息，请参考提供的参考资料&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212943.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;optical-flow-and-stereo-vision-光流和立体视觉&quot;&gt;Optical Flow and Stereo Vision 光流和立体视觉&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;光流计算 ≈ 立体视觉的对应问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总结一下光流计算，我们已经了解了一些光流计算方法。
在之前的章节中，我们介绍了双目视觉，在双目视觉中，我们也面临着类似的问题，即我们想计算两幅图像中某个点的像素位置之间的关系，因此我们有了对应问题。&lt;/p&gt;

&lt;p&gt;虽然光流计算与双目重建不同，但我们仍然可以认为这两个问题之间存在密切的联系。
在光流问题中，我们比较图像序列中的图像，而在双目视觉中，我们比较立体图像对。
在光流计算中，我们希望获得两个对应点之间的矢量，而在双目视觉中，我们希望计算视差，也可以将其解释为矢量。&lt;/p&gt;

&lt;p&gt;因此，我们确定了一些可能的方法。&lt;/p&gt;

&lt;p&gt;例如，可以使用&lt;em&gt;运动约束方程进行光流计算，但如果需要的话，也可以用于双目重建&lt;/em&gt;。
&lt;strong&gt;变分方法&lt;/strong&gt;主要用于光流计算，但也有非常类似的变分方法用于立体重建。
&lt;strong&gt;极线几何&lt;/strong&gt;是在双目视觉背景下引入的概念，但也可以用于光流计算。
&lt;strong&gt;块匹配&lt;/strong&gt;也是用于双目重建的方法，但也可以用于光流计算。
当然，特征点方法也可用于两个问题，至少可以用于获取稀疏光流或稀疏视差。&lt;/p&gt;

&lt;p&gt;可能的方法（适用于两者）包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;运动约束方程&lt;/li&gt;
  &lt;li&gt;变分方法&lt;/li&gt;
  &lt;li&gt;极线几何&lt;/li&gt;
  &lt;li&gt;块匹配/相关过程&lt;/li&gt;
  &lt;li&gt;特征点方法&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;稀疏流&quot;&gt;稀疏流&lt;/h3&gt;

&lt;p&gt;为了说明特征点方法的有用性，这里有一个标准图像序列的示例。我使用SURF特征点为两幅图像创建了特征点，并连接那些相互匹配的特征点对。结果如下图所示，每条黄线表示一个光流矢量，我们可以看到大多数光流矢量是有意义的。当然，右上角存在一些特征点连接不合理的伪影，导致了一些奇怪的光流，我们并不期望这种情况发生。当然，汽车部分也产生了一些奇怪的光流，这也是我们所预期的。然而，总体结果还是相当不错的。当然，这只是对于光流的稀疏估计，我们并没有获得每个像素的光流，但至少对于那些获得光流的像素，结果还是相当好的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614213941.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;image-based-tracking-基于图像的跟踪&quot;&gt;Image Based Tracking 基于图像的跟踪&lt;/h3&gt;

&lt;p&gt;在许多应用中，不需要计算每个像素的光流矢量，而是只对跟踪物体感兴趣，也就是确定属于某个特定物体的像素的光流。我们希望为整个物体获取一个单一的光流矢量。我们假设我们使用某种物体检测器，在第一帧中提供了一个感兴趣区域（ROI）。基于此，我们希望在整个视频序列中跟踪这个区域。我们假设我们不知道当前检测到的是什么物体，可能是汽车、人或动物等，我们只是想能够在整个视频中跟踪这个物体。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214319.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里有一个例子，仅包含了一系列图像中的四个图像。我们可以看到几个物体。假设在第一幅图像中，物&lt;em&gt;体检测器给出了三个感兴趣区域，用红色、绿色和蓝色矩形表示&lt;/em&gt;。我们的任务是在随后的图像中再次找到这些物体，并确定相应的感兴趣区域。
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214155.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;解决这个问题的基本思路如下&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214514.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从第一幅图像中，我们获取了对感兴趣物体的一些信息，即我们对物体的外观有一些概念。我们可以将这个外观作为该物体的模板，即我们只需将图像中的这个矩形区域作为模板。&lt;/p&gt;

&lt;p&gt;然后在下一幅图像中，我们可以搜索相同的模板出现的位置。我们将该区域在整个图像上进行移动，对于每个位置，我们检查模板是否与图像中所见的内容匹配，并确定相似度的度量。在这种情况下，我们可能发现在这里显示的第一个区域的左侧区域不匹配，因此模板与该区域的内容的相似度非常低，而在右侧的另一个模板中，模板与图像内容的相似度相对较高。我们可以将其视为一种块匹配，再次比较图像的感兴趣区域的灰度值，并尝试找到最佳匹配。一旦我们找到了最佳匹配，我们就知道这个物体在第二幅图像中最有可能再次出现的位置。&lt;/p&gt;

&lt;p&gt;现在，我们可以利用这第二幅图像，因为我们知道同一物体在第二幅图像中的位置，我们可以得到显示相同物体（或至少可能是相同物体）的第二个感兴趣区域。现在，我们可以使用第一幅图像和第二幅图像的两个感兴趣区域，并以最佳方式调整模板，使其适应两者。&lt;/p&gt;

&lt;p&gt;这样就得到了一个适应的模板。有了这个适应的模板，我们可以进入第三幅图像，并根据最佳匹配搜索第三幅图像中最合适的区域。基于这个最佳匹配，我们可以再次调整模板以适应新找到的感兴趣区域的外观。&lt;/p&gt;

&lt;p&gt;通过这样的步骤，我们可以逐步变得越来越好，以确定代表这种物体的良好模板。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于图像的跟踪：超越块匹配 Beyond Block Matching&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因此，创建模板并将其与图像块进行比较的方法既可以视为一种块匹配，也可以以不同的方式处理，并将其解释为分类任务。也就是说，我们想要搜索特定类别的物体，这些分类器通常使用一些示例图像进行训练。&lt;/p&gt;

&lt;p&gt;在我们的情况下，我们从一个正例图像开始，即来自图像序列中的第一幅图像的感兴趣区域，然后我们选择一些其他图像块作为负例。一旦我们在第二幅图像中找到了感兴趣区域，我们可以将第二幅图像中的感兴趣区域视为第二个训练示例，用于训练专门针对相关对象类别的分类器，通过这种方式我们可以不断进行下去。&lt;/p&gt;

&lt;p&gt;因此，我们对模板匹配使用可训练的分类器。参加过机器视觉或相关模式识别讲座的人可能已经对我们可以使用哪些分类器有一些了解，例如人工神经网络、支持向量机、决策树等等。在我们这里，我们将坚持支持向量机的思想，但不使用纯粹的支持向量机，而是经过改进的某种机器。&lt;/p&gt;

&lt;h3 id=&quot;example-kernelized-correlation-filter-kcf-核化相关滤波器-kcf&quot;&gt;Example: Kernelized Correlation Filter (KCF) 核化相关滤波器 (KCF)&lt;/h3&gt;

&lt;p&gt;这导致了一种被称为核化相关滤波器的方法。相关滤波器让我们想起了块匹配方法，而核化则提醒我们支持向量机的思想，因为这些方法的基本思想是将一种块匹配与核化相结合。&lt;/p&gt;

&lt;p&gt;在这种情况下，训练示例的创建如下所示：
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614215729.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设我们在最初的图像中的感兴趣区域显示了这个骑自行车的补丁，然后我们将这个补丁复制并填充整个平面。此外，我们创建了一种类似原始补丁大小的标签图像，这个标签图像的值介于0和1之间。中心点的值为1，在边界处的值为0，两者之间的值从1递减。然后我们创建一组训练示例，第一个示例是从原始图像补丁和相应的标签创建的，标签的值是标签图像中心处的值。然后，我们围绕原始图像补丁转动这个红色矩形，并以相同的方式转动用于确定相应训练示例标签的标签图像中的点。当然，标签不仅仅是0和1，这是纯粹分类任务的预期，而是介于0和1之间的实数。因此，这些标签在某种程度上告诉我们一个正确示例的级别，我们就是这样创建训练示例的。对于你所看到的红色矩形的每个位置，我们创建一个训练示例。之后，我们可能会在灰度图像或彩色图像上计算一些之前计算的特征，并将其应用于这些灰度图或者彩色图。&lt;/p&gt;

&lt;p&gt;之后，我们可能会在灰度图像或彩色图像上计算一些特征，并将其应用于这些训练示例，而不是直接使用颜色或灰度值。之前参加过机器视觉讲座的人会了解到一些特征，例如HOG特征或LBP特征，这些特征也可以用来创建训练示例，而不是直接使用原始图像数据。&lt;/p&gt;

&lt;p&gt;然后，我们应用一个分类器，它类似于支持向量机，但不完全是支持向量机。在我们的情况下，可以使用快速傅里叶变换以高效地进行训练，因此这种训练只需现代计算机上的10到20毫秒，可以实时进行。这样，我们就训练出了一个分类器，现在我们可以在下一幅图像中搜索适当的最佳匹配。在这种的情况下，也可以使用快速傅里叶变换来实现这一点，从而获得非常快速的响应时间。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Example: Tracking with Occlusions 使用遮挡进行跟踪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是的，我们在获取新图像时逐步更新模板。在这里，我们可以看到核化相关滤波方法的一个例子，它通过一种额外的技术扩展以处理遮挡。这是我们团队中Weitian的工作成果。让我们开始视频，我们可以看到这种方法跟踪了一个骑自行车的人，即使自行车被汽车遮挡，它仍然能够跟踪。这里的思路是分析物体的哪些部分仍然可见，然后在这个可见区域上初始化第二个核化相关滤波器，可见区域显示为绿色。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/bb28588d-b509-4bcd-bfd6-94c43a518c5d.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Example: Tracking in Fog 雾中跟踪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们看另一个示例视频，在右下方的图像中，你可以看到初始情况，绿色矩形定义了一开始提供的感兴趣区域，很难确定我们实际上正在跟踪的是什么。如果你看左上方的图像，也显示相同的图片，我们可以看到有些东西，但很难说那是什么，即使我们放大并查看右上方的图像，我们几乎无法确定我们真正看到了什么，只有一些与周围的雾有些不同的深灰色区域。然而，让我们启动这个核化相关滤波器来跟踪物体。&lt;/p&gt;

&lt;p&gt;现在我们可以看到物体的真正是什么，即一辆汽车。然而，从第一幅图像来看，几乎不可能确定这确实是一辆车，因此在第一幅图像中，车辆检测器无法确定这是一辆车，但我们仍然能够跟踪它，这真的很有趣。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/d96751c9-e29a-4f87-baf7-87295e60fa47.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;总结一下光流计算和基于图像的跟踪这一章节。我们开始讨论光流，介绍了光流的基本概念，推导了运动约束方程，并基于此引入了Lucas-Kanade方法。然后，我们更详细地分析了Lucas-Kanade方法，推导了光圈问题，并介绍了变分流计算方法的一些基本思想。&lt;/p&gt;

&lt;p&gt;对于基于图像的跟踪，我们引入了模板匹配的思想和核化相关滤波器作为一种有用且实时可行的方法来实现这种模板匹配思想，用于真实图像序列。&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/04-Optic-Flow-and-Image-Based-Tracking/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/04-Optic-Flow-and-Image-Based-Tracking/</guid>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Binocular Vision / Stereo Vision 双目视觉/立体视觉</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-2-binocular-vision--双目视觉&quot;&gt;chapter 2 Binocular Vision &lt;br /&gt; 双目视觉&lt;/h1&gt;

&lt;p&gt;欢迎来到《汽车视觉》第二章，今天我们将讨论双目视觉系统，也称为立体视觉。这是一些提供有关双目视觉系统章节的教科书列表。如果你需要超出本讲座范围的背景信息，请参考这些书籍以获取更多信息。让我们通过介绍对极几何概念来开始我们对双目视觉的讨论。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;R. Hartley, A. Zisserman, Multiple View Geometry in computer vision. Cambridge
University Press, 2006&lt;/li&gt;
  &lt;li&gt;E. R. Davies, Machine Vision. Theory. Algorithms. Practicalities. Elsevier, 2005, ch.
21.6 ff&lt;/li&gt;
  &lt;li&gt;D. A. Forsyth, J. Ponce, Computer Vision. A Modern Approach. Prentice Hall, 2003,
ch. 10&lt;/li&gt;
  &lt;li&gt;R. Szilinsik, Computer Vision: Algorithms and Applications, 2010, ch. 10&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;epipolar-geometry-对极几何&quot;&gt;Epipolar Geometry 对极几何&lt;/h2&gt;

&lt;h3 id=&quot;binocular-vision--stereo-vision-双目视觉立体视觉&quot;&gt;Binocular Vision / Stereo Vision 双目视觉/立体视觉&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615142533.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;双目视觉或立体视觉系统由两个相机组成。每个相机将三维世界映射到二维图像上。当使用两个不同的相机从两个不同的视点观察同一场景时，我们会获得两幅图像。这意味着我们有一个从三维世界到二维（两倍）世界的映射，或者换句话说，从三维到四维世界的映射。这种映射使我们能够确定一个点相对于相机的距离，这是使用单个相机无法实现的。我们将这个距离称为点的深度。此外，我们将双目相机系统中两个相机之间的距离称为立体设置或立体摄像机的基线。&lt;/p&gt;

&lt;p&gt;一旦我们确定了所有点的三维位置，我们就可以创建环境的三维模型。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;场景是用两个摄像头拍摄的&lt;/li&gt;
  &lt;li&gt;$\mathbb{R}^3 \rightarrow \mathbb{R}^2 \times \mathbb{R}^2$&lt;/li&gt;
  &lt;li&gt;3d 重建：确定到物体的距离（深度）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/68d8081b-56f5-4e5f-b9d8-b50989567816.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;让我们从以下的图示开始分析：&lt;/p&gt;

&lt;p&gt;我们有一个以焦点和图像平面为模型的相机。在现实中，相机的图像平面位于焦点后方。然而，为了简化分析，让我们引入一个位于相机前方的虚拟图像平面。由于针孔相机模型仅使用相机的焦点作为投影中心来实现透视映射，我们将在虚拟图像平面上观察到与在真实图像平面上相同的图像。然而，左右和上下是翻转的。此外，我们假设虚拟图像平面与相机之间的距离为1。&lt;/p&gt;

&lt;p&gt;如果我们观察一个三维点P，我们可以通过连接这个点P与相机的焦点来构建一个视线。该视线与图像平面的交点将给出该点的图像点，我们在这个图示中将其表示为ql。&lt;/p&gt;

&lt;p&gt;这里所示的点Fl和图像平面描述了左侧相机。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615143811.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们引入立体摄像机设置中的右侧相机，它也由其焦点和虚拟右图像平面定义。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615143923.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们添加了第三条连接两个焦点的线，实际上就是基线。我们观察到这个基线也与图像平面在两个点相交，我们将其表示为eL和eR，并将它们称为相机系统的epipolar”。请注意，图像平面本身是一个无限延伸的平面。我们在相机中感知到的图像只是该平面内的一个小区域。因此，即使epipolar”在图像之外，它仍然存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615144259.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;点FL、FR和P构成了一个三角形，这个三角形定义了一个平面，我们称之为极线平面（epipolar plane）。极线平面与虚拟图像平面在一条线上相交，这条线被称为相机设置的极线（epipolar line）。&lt;/p&gt;

&lt;p&gt;在位于两个相机前方的极线平面上的所有点都会被映射到两个相机的图像平面上的极线上。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;现在，我们可以基于这个模型进行计算&lt;/strong&gt;，区分左侧相机和右侧相机的相关坐标系。我们引入大写索引’L’和’R’分别表示左侧和右侧相机的坐标系。在进行计算时，始终小心并检查我们当前所处的坐标系，因为混淆不同的坐标系可能会导致问题。&lt;/p&gt;

&lt;p&gt;让我们首先建立起点P在左侧相机坐标系统中的三维位置描述向量PL与点P在左侧相机图像平面中的图像点位置描述向量ql之间的关系。从图示中，我们可以很容易地看出这两个向量只是彼此的缩放版本，&lt;strong&gt;缩放因子由1/zLL（1除以zLL）给出&lt;/strong&gt;。这是因为&lt;em&gt;虚拟图像平面与焦点之间的深度为1&lt;/em&gt;，而zLL是点P在左侧相机坐标系中的深度。因此，zLL只是向量PLL的第三个分量。&lt;/p&gt;

&lt;p&gt;类似地，我们可以对右侧相机坐标系和向量PR应用相同的推理过程。&lt;/p&gt;

&lt;p&gt;此外，我们观察到点FL、FR和P构成了极线平面，而向量PL、PR和B是极线平面的一部分。这意味着如果我们计算这些向量中任意两个的叉乘，我们将得到一个垂直于该平面的向量。此外，如果我们将这样一个垂直向量与平面上的其中一个向量进行点积运算，结果将为零。我们可以执行这个计算，例如，首先将基线向量B与向量PL进行叉乘，然后计算与向量PR的点积。当然，我们必须确保所有这些计算都在同一个坐标系中进行，特别是左侧相机的坐标系。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;左侧相机坐标系统： $\vec{q}_l^L=\frac{1}{z_l^L} \vec{p}_l^L$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;右侧相机坐标系统： $\vec{q}_r^R=\frac{1}{z_r^R} \vec{p}_r^R$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;假设向量位于一个平面上： $\left(\vec{p}_r^L\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在我们之前的计算中，我们使用了向量PR，但是将其表示为左侧相机的坐标系，这有点不寻常。因此，让我们看看如何将其转换为在右侧相机坐标系中表示的向量。由于两个相机坐标系都是右手坐标系、正交坐标系，并且使用相同的长度单位，我们可以通过将这些点与幻灯片上表示的旋转矩阵（用大写字母D表示）相乘，并通过一定的偏移来将它们从一个坐标系转换到另一个坐标系。在这种情况下，偏移量是基线向量B。现在，对于在左侧相机坐标系中表示的向量PR，它实际上是连接FR和P的向量。这个向量可以被重写为从FR到FL，然后从FL到P的组合。换句话说，它是从FL到P的向量减去从FL到FR的向量。这两个向量表示了左侧相机坐标系中两个点的位置。现在，我们可以使用这个替换，应用上述的坐标变换规则，并将这些向量替换为在右侧相机坐标系中表示的相应向量。&lt;/p&gt;

&lt;p&gt;在此之后，我们观察到项BL出现了两次，一次为正，一次为负，因此该项消失了。此外，我们可以将旋转矩阵D提取出来。括号中剩下的项实际上就是连接FR和P的向量，表示在右侧摄像机坐标系中。这实际上就是PRR。&lt;/p&gt;

&lt;p&gt;结合我们之前的结果，我们可以得出以下结论：
&lt;strong&gt;旋转矩阵D乘以括号中的PRR转置，再乘以BL和PLL的叉乘，必须等于零。&lt;/strong&gt; *(下面式子最后一行)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;坐标变换：$\vec{x}^L=D \vec{x}^R+\vec{b}^L$&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}
&amp;amp; \vec{p}_r^L={\overrightarrow{F_r P}}^L={\overrightarrow{F_l P}}^L-{\overrightarrow{F_l F_r}}^L \\
&amp;amp; =D \cdot{\overrightarrow{F_l}}^R+\vec{b}^L-\left(D \cdot{\overrightarrow{F_l F_r}}^R+\vec{b}^L\right) \\
&amp;amp; =D \cdot\left({\overrightarrow{F_l P}}^R-{\overrightarrow{F_l F_r}}^R\right) \\
&amp;amp; =D \cdot \vec{F}_r R=D \vec{p}_r^R \\
&amp;amp; \left(\vec{p}_r^L\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0 \quad \Rightarrow \quad\left(D \vec{p}_r^R\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0 \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615144259.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在，我们将这个结果与先前关于矢量ql和pl之间关系的结果相结合。我们已经得出这两个向量是通过一个缩放因子相关联的。现在，我们将这个关系代入以下方程中，将PRR替换为QRR，将PLL替换为QLL。
由于zRR和zLL（点在两个坐标系中的深度）始终是正数，我们可以将整个方程除以这两个深度值。我们得到下面的等式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;结合：&lt;/li&gt;
&lt;/ul&gt;

\[\begin{array}{r}
z_r^R\left(\vec{q}_r^R\right)^T D^T\left(\vec{b}^L \times z_l^L \vec{q}_l^L\right)=0 \\
\left(\vec{q}_r^R\right)^T D^T\left(\vec{b}^L \times \vec{q}_l^L\right)=0
\end{array}\]

&lt;p&gt;最后一步是将叉乘BL叉乘QLL重新写成矩阵-向量乘法的形式。通过一些变换，我们可以将其重写为矩阵为3x3的矩阵乘以一个三维向量，如下所示。让我们将其表示为BL叉乘。你可以在纸上试一下验证这个等式。&lt;/p&gt;

\[\vec{b}^L \times \vec{q}_l^L=\left(\begin{array}{ccc}
0 &amp;amp; -b_z^L &amp;amp; b_y^L \\
b_z^L &amp;amp; 0 &amp;amp; -b_x^L \\
-b_y^L &amp;amp; b_x^L &amp;amp; 0
\end{array}\right) \vec{q}_l^L=\left[\vec{b}^L\right]^L \times \cdot \vec{q}_l^L\]

&lt;p&gt;现在我们可以简化我们感兴趣的方程，最终结果为：QR的转置乘以E乘以QLL等于零，其中E，也被称为本质矩阵  essential matrix，就是转置的旋转矩阵乘以矩阵BL叉乘。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \text { with: } E=D^T\left[\vec{b}^L\right] \\
&amp;amp; \qquad\left(\vec{q}_r^R\right)^T E \vec{q}_l^L=0
\end{aligned}\]

&lt;p&gt;很容易看出，本质矩阵只包含有关相机设置的内部参数的信息，也就是关于两个相机之间的相对位置的信息。&lt;/p&gt;

\[\left(\vec{q}_r^R\right)^T E \vec{q}_l^L=0\]

&lt;p&gt;为什么这个结果如此重要呢？如果我们知道$\vec{q}_l^L$，也就是我们知道了&lt;strong&gt;左相机图像中的某个点&lt;/strong&gt;，那么根据这个方程，我们可以确定右图像中的对极线。
因为右图像上的所有点都必须满足这个方程：$\left(\vec{x}^R\right)$的转置乘以E乘以$\vec{q}_l^L$必须等于零。所以这其实就是右相机图像平面上一条直线的定义。&lt;/p&gt;

\[\left(\vec{x}^R\right)^T E \vec{q}_l^L=0\]

&lt;p&gt;类似地，如果我们知道右相机图像中的一个点，我们可以确定左相机图像中相应的对极线。&lt;/p&gt;

&lt;p&gt;我们还可以确定&lt;strong&gt;立体摄像机系统的对极点&lt;/strong&gt;，因为对极点是所有对极线共有的点。这意味着对于右相机的对极点，我们得到ERR的转置乘以本质矩阵乘以QLL必须对所有可能的QLL值都相等。类似地，我们也可以得到左相机对极点的结果。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \left(\vec{e}_r^R\right)^T E \vec{q}_l^L=0 \text { for all } \vec{q}_l^L \\
&amp;amp; \left(\vec{q}_r^R\right)^T E \vec{e}_l^L=0 \text { for all } \vec{q}_r^R
\end{aligned}\]

&lt;p&gt;因此，如果我们想从立体摄像机系统中重建三维点，我们可以利用这一点。假设我们已经获得了立体摄像机系统的左图像和右图像，并且我们在左图像中找到了一个有趣的点QL。问题是，对应的右图像中的点在哪里？它可能在任何地方。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615152840.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，如果我们知道了点QL对应的对极线，我们就可以限制搜索范围，因为我们知道对应的点只能位于对极线上。这意味着知道对极线可以帮助我们将搜索空间限制在一维结构上，即一条一维线上。如果我们知道一对对极线，我们还可以确定对极平面。&lt;/p&gt;

&lt;h2 id=&quot;fundamental-matrix&quot;&gt;Fundamental Matrix&lt;/h2&gt;

&lt;p&gt;在许多情况下，使用本质矩阵并不方便，因为如果我们想要使用图像坐标进行操作，通常希望使用图像坐标系统中的u和v坐标，而不是相机坐标系统中的坐标。为此，我们可以引入另一个矩阵，称为基础矩阵F，它实际上与本质矩阵相同，但使用图像坐标系统中的坐标。它可以通过将本质矩阵从左侧和右侧乘以两个相机的内部参数矩阵来导出，如方程中所示。&lt;/p&gt;

&lt;p&gt;现在，我们之前针对本质矩阵导出的方程同样适用于基础矩阵。对于一对对应的图像坐标UL、VL和UR、VR，我们得到UR、VR、1乘以基础矩阵乘以UL、VL、1必须等于零。&lt;/p&gt;

&lt;p&gt;基础矩阵可以从已标定的相机配置中导出，因为我们&lt;em&gt;知道内部相机参数和外部参数&lt;/em&gt;，可以从中导出本质矩阵和基础矩阵。即使我们不知道这些内部和外部参数，如果我们有一定数量的左右相机图像上的对应点，仍然可以导出基础矩阵。如果我&lt;strong&gt;们至少知道八个点，我们可以使用所谓的八点算法估计基础矩阵F，但无法确定一个未知的比例因子&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在有基本矩阵 F 的情况下，首选图像坐标：
    &lt;ul&gt;
      &lt;li&gt;具有内在相机参数的矩阵 Al, Ar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[F=A_r^{-T} E A_l^{-1}\]

&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;在一对对应的图像坐标的情况下：&lt;/li&gt;
&lt;/ul&gt;

\[\left(u_r, v_r, 1\right) F\left(\begin{array}{c}
u_l \\
v_l \\
1
\end{array}\right)=0\]

&lt;ul&gt;
  &lt;li&gt;基本矩阵的形状可以通过一组≥8个对应的图像点（8点算法）直到一个未知的比例因子来计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;例子&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们来看一些例子。这里，我们看到两个图像显示的是同一个场景，但&lt;strong&gt;在左图中，视角稍微向左&lt;/strong&gt;，而&lt;strong&gt;在右图中，视角稍微向右&lt;/strong&gt;。我们看到一些蓝色的线，它们是极线，以及一些用小绿点标记的点集。在这些情况下，极线大致是水平的，并且极点远离图像之外。&lt;/p&gt;

&lt;p&gt;– horizontal panning motion 水平平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615153747.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张图片展示了类似的情况，但现在视角位置重叠。极线是垂直的。&lt;/p&gt;

&lt;p&gt;– vertical panning motion 垂直平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615153935.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;– horizontal and vertical panning motion  水平和垂直平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615154100.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个情况，其中两个摄像机的视角在水平和垂直方向上发生了移动，因此极线有些倾斜，至少部分倾斜。最后，让我们来看一下摄像机不是向左、向右、向上或向下移动，而是向前或向后移动，离场景越来越近或越来越远的情况。在这种设置中，四个极点都位于图像内部，正如我们在所有极线的交点处所看到的，这些交点就是立体设置的极点。
– motion parallel to optical axis 平行于光轴的运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615154216.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;此外，还有一个非常特殊的极线几何情况，即具有相同图像平面、相同内部参数的相机，且相机完全平行且方向相同。这种情况如图所示，两个摄像机只是平行于摄像机坐标系的x轴向左或向右移动。在这种情况下，极线是平行的且完全水平的。我们需要在另一个图像的同一行上搜索对应的点。极点位于无限远处。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615155041.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这样的设置中，我们称之为矫正相机设置，计算特定点的深度相对容易。首先，我们需要确定该点的视差，即图像坐标中对应点的 u 坐标之差。因此，视差（表示为 Ddisparity）等于 UL 减去 UR。这总是一个非负数。基于视差，我们可以轻松计算出点 P 的三维位置。它由基线（两个焦点之间的距离）乘以 alpha prime（相机设置的有效焦距）除以视差，再乘以向量 [XL, YL, 1] 给出。该向量表示左侧相机的焦点和相机坐标系中的图像点的位置。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;视差（以像素为单位）：$d=u_l-u_r$&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

\[P^L=\frac{b}{x_l^L-x_r^R}\left(\begin{array}{c}
x_l^L \\
y_l^L \\
1
\end{array}\right)=\frac{b \alpha^{\prime}}{u_l-u_r}\left(\begin{array}{c}
x_l^L \\
y_l^L \\
1
\end{array}\right)\]

&lt;p&gt;&lt;strong&gt;Derivation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615155538.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disparity 视差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们可以看到校正或矫正立体设置的视觉效果。在顶部，您可以看到立体摄像机的左图像和右图像，在底部，您可以看到两个图像一个接一个地显示。我们可以观察到，当图像发生变化时，所有的点都向左和向右移动，然而它们不上下移动。我们还可以进一步观察到，远离我们的点，例如背景中的房屋，移动得不多，即视差较小，而前景中的点，例如行人，移动得很多，这些点的视差很大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150252.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rectification 矫正&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实际上，几乎不可能构建一个完全矫正的相机系统，因为我们在安装相机时所需的精度在机械上很难实现。那么，如果我们无法构建矫正相机，我们如何使用矫正相机呢？答案很简单，我们可以从实际的立体设置中创建虚拟矫正相机。这个原理在下面的图片中展示。我们从原始相机设置的图像开始。这个设置并不差，所以相机的对准尽可能好，但不完美。然后，我们进行一些转换，称为图像的矫正，然后稍微修改图像，使其完全矫正。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150522.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它是如何实现的？起点是我们有立体设置的两个相机，具有不同的相机参数Al和AR，以及不同的坐标系。我们的目标是定义两个新的虚拟相机，一个左虚拟相机和一个右虚拟相机，两者应该具有相同的焦距，以及相同的内部参数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150731.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;两个虚拟摄像机的对齐方式应该是完全一致的，这意味着它们的相机坐标系应该完全对齐。它们的相机坐标系的x轴应该与连接两个焦点的基线平行，并且焦点应该与原始摄像机的焦点相同。也就是说，左侧虚拟摄像机的焦点应与真实左侧摄像机的焦点相同，虚拟右侧摄像机的焦点应与真实右侧摄像机的焦点相同。&lt;/p&gt;

&lt;p&gt;我们可以将这个过程可视化如下：我们从一个真实相机开始，你可以看到相机坐标系彼此不对齐。然后我们将它们旋转，使它们的x坐标与基线平行，而它们的y和z坐标也互相平行。然后我们忘记原始坐标系，只使用这个虚拟双目相机设置。我们如何计算这个呢？&lt;/p&gt;

&lt;p&gt;首先，我们需要根据相机参数定义一个共同的内部矩阵a’，这个矩阵类似于原始内部相机矩阵Al和Ar。&lt;/p&gt;

&lt;p&gt;其次，我们要找到一个共同的相机坐标系，使得x轴平行于基线。在定义这个坐标系时，我们有一定的自由度，因为我们可以始终围绕x轴旋转，并得到不同可能的矫正相机坐标系的选择。
实际上，我们在实践中使用尽可能与原始两个相机坐标系相似的坐标系。一旦我们定义了这些新的坐标系，我们确定所需的旋转矩阵，用于将原始坐标转换为新的坐标。
然后，我们将原始相机图像转换为虚拟相机的图像，也就是创建了新的虚拟矫正相机图像。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这可以按照以下方式完成&lt;/strong&gt;：从透视投影中，我们知道如果我们知道点p在原始相机设置和左相机的坐标系中的3D点位置，通过将Al与p相乘，我们得到图像坐标。左侧的结果是深度pz乘以该点的图像坐标。我们可以对新的虚拟左相机系统进行类似的计算。对于新的虚拟相机坐标系，我们有P’×a’ = pz’×u’×b’，其中带有撇号的变量是与新的虚拟相机坐标系相关的变量，这个新坐标系中的点的深度和坐标都可能发生变化。&lt;/p&gt;

&lt;p&gt;知道两个坐标系之间有一个已知的变换，仅由一个旋转矩阵定义，我们可以将点P’转换为DL乘以p。&lt;/p&gt;

&lt;p&gt;现在我们可以合并这两个方程，并通过从上面的方程推导出的相应方程替换点P，最终我们得到了你在这里看到的术语。通过将整个方程除以Pz，我们得到一个简化的项目P’ / Pz，这只是一个缩放因子，我们可以通过这个方程的第三行确定缩放因子。一旦我们知道了缩放因子，我们就可以确定U’和V’。如果我们想根据实际图像中的位置确定虚拟图像中的点的位置，这意味着我们可以创建一个描述实际图像中的点如何映射到虚拟矫正图像中的点的映射。我们可以对左右两个虚拟相机都这样做，并最终得到结果。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; p_z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=A_l \cdot \vec{p} \\
&amp;amp; p_z^{\prime} \cdot\left(\begin{array}{l}
u^{\prime} \\
v^{\prime} \\
1
\end{array}\right)=A^{\prime} \cdot \vec{p}^{\prime}=A^{\prime} \cdot D_l \cdot \vec{p}=A^{\prime} \cdot D_l \cdot A_l^{-1} \cdot p_z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right) \\
&amp;amp; \frac{p_z^{\prime}}{p_z}\left(\begin{array}{l}
u^{\prime} \\
v^{\prime} \\
1
\end{array}\right)=A^{\prime} D_l A_l^{-1} \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)
\end{aligned}\]

&lt;p&gt;最后，让我们分析从我们可以确定该点的视差的准确性来看，深度计算的灵敏度如何。&lt;/p&gt;

&lt;p&gt;我们已经推导出深度Pz取决于视差D的公式，其中包括项基线B乘以有效焦距Alpha Prime除以视差D。如果我们假设我们只能确定视差到某个位置，那么我们假设在计算这个视差时会产生一定的误差Epsilon。让我们考虑一下这个误差和视差计算对计算深度的影响有多大。为此，我们使用泰勒展开。对于视差D + Epsilon，我们可以近似为视差D - Epsilon的点的深度，其中深度对视差的一阶导数为B乘以Alpha Prime除以D的平方。这可以表示为D-Epsilon / B乘以Alpha Prime乘以Z平方的术语，这意味着在深度估计中获得的误差与点的距离的平方成正比。也就是说，点离得越远，我们在深度估计中得到的误差就越大。&lt;/p&gt;

&lt;p&gt;该图显示了这种误差增长的典型示例。现在我们清楚地看到在水平轴上是点的真实距离，而在垂直轴上是如果我们对视差进行了半个像素的小猜测或小测量所得到的误差。我们很容易看到误差的正确二次增长。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616152729.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;correspondence-problem-对应问题&quot;&gt;Correspondence Problem 对应问题&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616152832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在让我们来讨论对应问题。到目前为止，我们假设我们知道左图像中的哪些点和右图像中的哪些点表示三维世界中的同一点，但实际上这是未知的，我们需要计算它。我们来看一对经过矫正的立体图像。&lt;/p&gt;

&lt;p&gt;在左图像中，一个点用橙色圆圈标出，它是建筑物的左上角。对于这个点，找到右图像中的对应点相对容易，因为这个点非常显著，我们可以比较容易地确定它。&lt;/p&gt;

&lt;p&gt;对于第二个点，它位于一个窗户的垂直边缘上，情况稍微复杂一些。在右图像中，我们可以找到同样的垂直边缘，但是如果没有任何额外的信息，我们不会确切地知道这个边缘上的哪个点是对应点。幸运的是，在这种情况下，我们知道我们正在处理的是矫正的相机图像，这意味着我们知道我们必须在同一行中搜索，因为这是对应的极线。如果我们利用这个额外的知识，我们可以轻松找到对应点。&lt;/p&gt;

&lt;p&gt;在第三种情况下，我们处理的是轨道上的一个点。同样，我们可以使用相同的技巧并利用极线，但不幸的是，在这条极线上有两个非常相似的点，两个轨道上的点都有可能是对应点。如果我们分析整个图像并理解整个图像，我们将能够轻松区分左侧的轨道和右侧的轨道。但如果我们只看局部区域并比较右图像中的哪个区域与左图像中的哪个区域相似，可能会遇到问题，因为在这种情况下，错误的对应点看起来比正确的对应点更相似。&lt;/p&gt;

&lt;p&gt;最后，最糟糕的情况发生在雪地中的这个点。我们知道我们必须在极线上搜索，但不幸的是，图像中没有足够的结构来确定对应点的位置，我们只能说它必定在这个区域，但无法确定确切位置。&lt;/p&gt;

&lt;p&gt;为了确定对应点，我们可以利用几个特性，特别是在矫正的图像中。如果图像是由相同类型的相机拍摄，并且曝光时间选择相同，那么点的灰度值应该是相同的。它们应该具有相同的局部环境，看起来非常相似。它们必须位于同一对极线上。这些点的邻域也应该大部分时间保持不变，这意味着如果我们在左图像中有两个点，一个在另一个点的左边，那么相应的右图像中的点的顺序也应该如此。正如我所说，有一些例外情况，不满足这些条件，但这些例外情况相当罕见。最后，在左图像中，U坐标大于右图像中的U坐标，因此视差始终是非负的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对应的点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;具有相同的灰度值&lt;/li&gt;
  &lt;li&gt;具有相同的局部环境&lt;/li&gt;
  &lt;li&gt;位于同一对极线上&lt;/li&gt;
  &lt;li&gt;邻域被保留（大部分情况下）&lt;/li&gt;
  &lt;li&gt;在左图像中的u坐标大于在右图像中的u坐标（矫正后的图像）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;block-matching-块匹配&quot;&gt;Block Matching 块匹配&lt;/h3&gt;

&lt;p&gt;我们如何确定对应点呢？方法是比较两个点的局部环境，这就得到了一种称为块匹配的方法，因为我们比较的是灰度值的块。在这种情况下，我选择了左图像中的一个图像块，如顶部所示，并提供了三个可能的右图像中的候选点，它们可能是对应点。&lt;/p&gt;

&lt;p&gt;现在我们可以比较这些图像块，看灰度值结构的相似程度，例如通过一个灰度值差异度量，我们可以得到左&lt;strong&gt;边的图像块的差异为74.9，中间的图像块的差异为43.8，右边的图像块的差异为3.2&lt;/strong&gt;。在这种情况下，&lt;strong&gt;我们只是计算了逐像素的绝对灰度值差异，然后取平均值&lt;/strong&gt;。当然，我们还&lt;em&gt;可以选择其他灰度值差异度量的方法&lt;/em&gt;，例如如果我们喜欢，我们可以选择平方差异而不是计算绝对差异。在这种情况下，我们将得到这些值。最后，我们会选择最相似的图像块，也就是具有最小差异的图像块，并将其选为最有可能的对应点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616153711.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;数学上，我们会检查以左图像中感兴趣像素 UL、VL 为中心的一定区域，并分析通过该区域中的所有像素的灰度值结构，使用两个运行索引 i 和 j。&lt;/p&gt;

&lt;p&gt;对于右图像中的潜在对应点，我们也会考虑相同区域内的所有像素，并逐像素比较灰度值，取绝对差异并对所有像素求和。如果需要，我们可以通过将结果除以该区域中的像素数量来取平均值。这将得到灰度值绝对差异的总和。对于平方差异，计算方式非常类似，只是在差异的计算中取差值的平方。另一个选项是使用相关性，如此处所示。该相关性是从统计学上确定的，具有一些不同的特性。前两种度量方式，如果图像非常相似，它们会很小；相关性在两个图像相似时很大；它们在两个图像完全相同时达到最大值 1；而当它们非常不相似时，相关性为 -1。&lt;/p&gt;

&lt;p&gt;相关性具有一些优势，因为它对消除具有不变性。如果两个图像块通常稍微亮或暗一些，相关性对这些变化不敏感，例如由于相机的曝光时间不同。然而，灰度值绝对差异和平方差异是不具有这种不变性的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;左图中像素 (ul,vl) 周围的局部环境：&lt;/li&gt;
&lt;/ul&gt;

\[g_l\left(u_l+i, v_l+j\right), \quad-n \leq i, j \leq n\]

&lt;ul&gt;
  &lt;li&gt;左右分割段的区别：
    &lt;ul&gt;
      &lt;li&gt;对灰度值绝对差求和：&lt;br /&gt;
\(\sum_{i=-n}^n \sum_{j=-n}^n\left|g_l\left(u_l+i, v_l+j\right)-g_r\left(u_r+i, v_r+j\right)\right|\)&lt;br /&gt;&lt;/li&gt;
      &lt;li&gt;对灰度值平方误差求和：&lt;br /&gt;
\(\sum_{i=-n}^n \sum_{j=-n}^n\left(g_l\left(u_l+i, v_l+j\right)-g_r\left(u_r+i, v_r+j\right)\right)^2\)&lt;br /&gt;&lt;/li&gt;
      &lt;li&gt;相关性:&lt;br /&gt;
\(\frac{\frac{1}{(2 n+1)^2} \sum_{i=-n}^n \sum_{j=-n}^n\left(g_l\left(u_l+i, v_l+j\right)-\bar{g}_l\right) \cdot\left(g_r\left(u_r+i, v_r+j\right)-\bar{g}_r\right)}{\sqrt{V\left(g_l\right) V\left(g_r\right)}}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;让我们以一个例子来说明。
上方是我在左图像中选择的图像块，下方是右图像。
我们可以将此图像块与右图像中的所有可能像素进行比较，不考虑首先考虑极线几何关系。然后，对于每个像素，我们得到一个特定的误差项，如此处所示。颜色表示了右图像中相应像素周围区域的差异程度，&lt;strong&gt;蓝色表示差异小，非常相似&lt;/strong&gt;，&lt;strong&gt;红色表示差异大，非常不同&lt;/strong&gt;。&lt;em&gt;如果我们寻找最小值，我们实际上会找到一个位置，如右图像中用红色矩形标示的位置，这是实际的对应点。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616154845.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在实际应用中，我们对图像的所有像素进行这个过程，并当然使用了极线来限制搜索范围，只搜索相应的极线，以避免过多的计算。&lt;/p&gt;

&lt;p&gt;我们这样做会得到视差图像，你可以在右侧看到示例。这个视差图像显示了每个像素的视差值，视差值使用颜色编码，&lt;strong&gt;绿色表示小的视差，红色表示大的视差，对于黑色区域，我们无法确定视差&lt;/strong&gt;，因为点周围的环境结构不足，没有足够的纹理来确定对应点，正如我们在这里看到的，尤其是在非常均匀的雪地区域，无法确定对应点。但对于铁轨、架空线缆、背景建筑或铁路车辆等场景，我们可以确定对应点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616155152.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里是另一个例子，展示了一位前博士生安德烈亚斯·盖格（Andreas Geiger）开发的块匹配方法，他添加了一些额外的技术来得到一些密集的视差图，如你在这里所见。可能有趣的是，在第二列的视差图中有一些黑色区域，看起来像是物体的阴影。例如，对于行人的背后，我们看到一个黑色的区域，无法计算出视差。在这种情况下，该区域的结构足够丰富以计算视差，但行人本身遮挡了其后面的一些区域。这些遮挡区域在左右相机中是不同的，因此对于在一个相机中被遮挡而在另一个相机中没有遮挡的点，我们显然无法计算出视差值，因此在这些区域中，我们得到这些视差阴影。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616155406.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关于块匹配的一些说明&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;它是一种具有许多&lt;strong&gt;优点&lt;/strong&gt;的方法，非常通用，可以用于很多应用，双目重建是其中一个可能的应用，但不是唯一的应用。光流计算，我们在第四章中讨论过的内容，是另一个应用。我们可以利用极线几何来限制搜索范围，但如果我们无法访问极线几何，我们也可以在整个图像上执行块匹配。&lt;/p&gt;

&lt;p&gt;在使用块匹配时，存在一些&lt;strong&gt;不足&lt;/strong&gt;之处。完整的搜索可能需要大量计算资源，尤其是对于大图像而言，因为它涉及对大量图像块进行比较。此外，只有当图像块中的灰度结构足够丰富时，才能明确地确定对应点。如果图像块的结构较差，存在找不到准确对应点的风险。&lt;/p&gt;

&lt;p&gt;另一个考虑因素是我们在块匹配中比较的区域大小。如果区域太小，图像块中的灰度结构将较差，增加了错误匹配的风险。然而，如果区域太大，计算时间会增加，并且区域可能包含属于不同对象且具有不同深度的像素，这会增加错误结果的可能性。&lt;/p&gt;

&lt;p&gt;在实践中，&lt;strong&gt;块匹配通常应用于预先校准的图像上&lt;/strong&gt;，这样它们就不会受到整体照明条件的影响。为了避免由于左右图像的亮度差异（由于曝光时间不同或其他原因）而导致块匹配失败，许多研究人员&lt;strong&gt;首先对图像进行Sobel或Laplace运算，以获得一阶或二阶滤波图像，然后在梯度图像上应用块匹配。通过使用导数计算（如梯度），消除了整体亮度水平的影响，使整个过程对消除不变。&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/02-BinocularVision/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/02-BinocularVision/</guid>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第二部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习&quot;&gt;深度学习&lt;/h1&gt;

&lt;h2 id=&quot;语义分割和目标检测-semantic-segmentation-and-object-detection&quot;&gt;语义分割和目标检测 (Semantic Segmentation and Object Detection)&lt;/h2&gt;

&lt;h3 id=&quot;场景标注-scene-labeling&quot;&gt;场景标注 Scene Labeling&lt;/h3&gt;

&lt;p&gt;分割图像&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类每个像素&lt;/li&gt;
  &lt;li&gt;自动编码器/解码器结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111358.png&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;h3 id=&quot;实例标签-instance-labeling&quot;&gt;实例标签 Instance Labeling&lt;/h3&gt;

&lt;p&gt;语义标签不提供对象边界！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111731.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;想法：将方向标记为对象中心&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112000.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;C:\Users\Wenbo Li\AppData\Roaming\Typora\typora-user-images\image-20220310112145711.png&quot; alt=&quot;image-20220310112145711&quot; /&gt;&lt;/p&gt;

&lt;center&gt;video provided by Nick Schneider, Daimler AG  &lt;/center&gt;

&lt;h3 id=&quot;区域生成网络region-proposal-networks&quot;&gt;区域生成网络Region Proposal Networks&lt;/h3&gt;

&lt;p&gt;Region Proposal Network，直接翻译是“&lt;strong&gt;区域生成网络&lt;/strong&gt;”，通俗讲是“筛选出可能会有目标的框”。其本质是基于滑窗的无类别object检测器，输入是任意尺度的图像，输出是一系列矩形候选区域。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112344.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112421.png&quot; style=&quot;zoom: 68%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112445.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们在哪里可以找到哪些对象？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将图像划分为单元&lt;/li&gt;
  &lt;li&gt;在每个单元中应用区域生成网络&lt;/li&gt;
  &lt;li&gt;改变划分的单元大小以处理更大/更小的对象&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;深度学习技术&quot;&gt;深度学习技术&lt;/h3&gt;

&lt;p&gt;没有比更多数据更重要的数据了！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的严格验证&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的正则化&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;– 提前停止&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 权重衰减/L2 正则化&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– dropout&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 随机梯度下降&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 多任务学习&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 使用预训练网络&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 损失函数&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重用 （他人的）实践知识&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的网络结构&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的培训过程&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;训练期间的典型错误进展&quot;&gt;训练期间的典型错误进展&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113429.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么早期停止作为正则化技术起作用？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提前停止更倾向小权重&lt;/li&gt;
  &lt;li&gt;小权重意味着几乎没有非线性&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;小权重正则化&quot;&gt;小权重正则化&lt;/h4&gt;

&lt;p&gt;假设感知器的绝对权重较小&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113609.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113743.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;小权重促进感知器的线性行为&lt;/p&gt;

&lt;p&gt;假设具有线性激活的全连接网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113904.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→感知器的线性行为降低了非线性表达性&lt;/p&gt;

&lt;p&gt;→正则化&lt;/p&gt;

&lt;h3 id=&quot;权重衰减l2-正则化-weight-decay--l2-regularisation&quot;&gt;权重衰减/L2-正则化 Weight Decay / L2-Regularisation&lt;/h3&gt;

&lt;p&gt;通过正则化规则扩大训练目标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过在训练期间随机关闭感知器进行正则化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114520.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dropout 迫使神经网络以分布式方式存储相关信息&lt;/p&gt;

&lt;p&gt;dropout 减少过拟合&lt;/p&gt;

&lt;h3 id=&quot;梯度下降的修正&quot;&gt;梯度下降的修正&lt;/h3&gt;

&lt;h4 id=&quot;随机梯度下降&quot;&gt;&lt;strong&gt;随机梯度下降&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114745.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;加速&lt;/li&gt;
  &lt;li&gt;减少一点过拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;动量梯度下降&quot;&gt;&lt;strong&gt;动量梯度下降&lt;/strong&gt;&lt;/h4&gt;

\[\begin{aligned}
\Delta \vec{w} &amp;amp; \leftarrow \alpha \cdot \Delta \vec{w}-\varepsilon \cdot \frac{\partial}{\partial \vec{w}} \sum_{j \in S} \operatorname{err}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right), \vec{t}^{(j)}\right) \\
\vec{w} \leftarrow \vec{w}+\Delta \vec{w}
\end{aligned}\]

&lt;p&gt;用一个α&amp;gt;0参数来控制后续步骤的一致性&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在平坦区域加速&lt;/li&gt;
  &lt;li&gt;减少曲折&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;多任务学习-multi-task-learning&quot;&gt;多任务学习 Multi Task Learning&lt;/h3&gt;

&lt;p&gt;想法：在单个网络示例中学习多个相关任务：&lt;/p&gt;

&lt;p&gt;场景标记+实例标记+深度估计&lt;/p&gt;

&lt;p&gt;scene labeling + instance labeling + depth estimation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115128.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;强制网络在隐藏层中开发共同特征&lt;/li&gt;
  &lt;li&gt;减少对单个任务的过度拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;预训练特征网络的使用&quot;&gt;&lt;strong&gt;预训练特征网络的使用&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;想法：重用预训练的网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115236.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用大型训练集训练其他任务&lt;/li&gt;
  &lt;li&gt;丢弃其他任务的分类层&lt;/li&gt;
  &lt;li&gt;为新任务创建新的分类层&lt;/li&gt;
  &lt;li&gt;训练新分类层的权重，同时保留特征层&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;输出层和损失函数-output-layers-and-loss-functions&quot;&gt;输出层和损失函数 Output Layers and Loss Functions&lt;/h3&gt;

&lt;p&gt;损失函数将网络输出与期望的输出进行比较&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115431.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（回归任务）：期望的输出应该是实数&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用线性激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用平方误差，即&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[\operatorname{err}(\vec{y}, \vec{t})=\|\vec{y}-\vec{t}\|^{2}\]

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（分类任务）：期望的输出应该是类别标签&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用softmax激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用交叉熵误差 cross entropy error&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115748.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;不平衡训练集的变体&quot;&gt;不平衡训练集的变体&lt;/h3&gt;

&lt;p&gt;对于严重不平衡的训练集（即每个类的示例数量不相等），训练可能会失败&lt;/p&gt;

&lt;p&gt;引入加权因子来补偿不平衡&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120231.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;来自深度学习工具箱的其他技术&quot;&gt;来自深度学习工具箱的其他技术&lt;/h2&gt;

&lt;h3 id=&quot;生成对抗网络-gan-generative-adversarial-networks-gan&quot;&gt;生成对抗网络 (GAN) Generative Adversarial Networks (GAN)&lt;/h3&gt;

&lt;p&gt;我们可以使用深度网络生成逼真的图像吗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120527.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120601.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;生成网络应该学会生成逼真的图像&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;鉴别性网络应该学习如何区分图像是真实的还是生成的。&lt;/li&gt;
  &lt;li&gt;训练：两个网络都是零和游戏中的竞争对手&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;应用领域： • 图像渲染 • 域适应 • 为分类器生成（附加）训练数据&lt;/p&gt;

&lt;h3 id=&quot;序列处理sequence-processing&quot;&gt;序列处理Sequence Processing&lt;/h3&gt;

&lt;p&gt;我们如何处理序列，例如 视频序列？&lt;/p&gt;

&lt;p&gt;(1) 多通道输入层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120707.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有在以下情况下才有可能&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2)图像单独处理+拼接层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(3) 图像的单独处理+附加层（深度集）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120924.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;图像的顺序并不重要&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(4)递归网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121006.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121023.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;学习算法：通过时间进行反向传播&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;问题：梯度消失&lt;/li&gt;
  &lt;li&gt;解决方案：用适当的处理单元（GRU、LSTM）取代网络C中的感知器。
适当的处理单元(GRU, LSTM)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;循环单元-grulstm-recurrent-units-grulstm&quot;&gt;循环单元 (GRU+LSTM) Recurrent Units (GRU+LSTM)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;实现简单状态机的专用单元&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;状态从不通过双曲切线的逻辑函数→来传递
没有消失的梯度&lt;/li&gt;
  &lt;li&gt;内部结构有几个控制信息流的闸门&lt;/li&gt;
  &lt;li&gt;使用感知器机制打开/关闭闸门&lt;/li&gt;
  &lt;li&gt;LSTM：更早（1997年），更复杂（需要5个感知器）。&lt;/li&gt;
  &lt;li&gt;GRU：较新（2014年），门数较少，参数较少（需要3个感知器）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;门控循环单元-gru&quot;&gt;门控循环单元 (GRU)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121136.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;长短期记忆单元-lstm&quot;&gt;长短期记忆单元 (LSTM)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121153.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.1/</guid>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第一部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习-deep-learning&quot;&gt;深度学习 Deep Learning&lt;/h1&gt;

&lt;h2 id=&quot;多层感知器multi-layer-perceptrons--mlp&quot;&gt;多层感知器Multi-Layer Perceptrons  （MLP）&lt;/h2&gt;

&lt;p&gt;MLP 是高度参数化的非线性函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094040.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;示例：图像分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$\vec{x}$   特征向量，例如 图像中所有灰度值的向量&lt;/p&gt;

&lt;p&gt;$\vec{y}$  1-of-q-vector 为 q 个可能类别中的每一个建模概率，例如 笑脸是快乐/悲伤/沮丧&lt;/p&gt;

&lt;p&gt;感知器, 感知机&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094519.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094543.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;许多感知器的分层排列：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094857.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;网络结构创建了一组高度非线性的函数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;许多权重&lt;/li&gt;
  &lt;li&gt;深层架构：通常 &amp;gt;5 个隐藏层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们如何确定 MLP 的权重？&lt;/p&gt;

&lt;p&gt;– 基本思想：最小化训练样例的误差&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095152.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解决&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p} \operatorname{err}\left(f_{M L P} ^ {\vec{w} }\left(\vec{x}^ {(j)}\right), \vec{t}^ {(j)}\right)\]

&lt;p&gt;用于适当的误差测量（损失函数）&lt;/p&gt;

&lt;p&gt;for appropriate error measure (loss function)&lt;/p&gt;

&lt;p&gt;算法：梯度下降（反向传播）&lt;/p&gt;

&lt;h2 id=&quot;梯度下降反向传播gradient-descent-backpropagation&quot;&gt;梯度下降（反向传播）Gradient Descent (Backpropagation)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;

\[\underset{\vec{w}} {\operatorname{minimize}} g(\vec{w}) \text { with } g(\vec{w}):=\sum_{j=1}^{p} \operatorname{err}\left(f_{M L P}^{\vec{w} }\left(\vec{x}^{(j)}\right), \bar{t}^{(j)}\right)\]

&lt;p&gt;&lt;strong&gt;算法&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用小数字随机初始化权重 $\vec{w}$&lt;/li&gt;
  &lt;li&gt;计算梯度 $\frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;以小的学习率$\varepsilon&amp;gt;0$更新权重 $\varepsilon&amp;gt;0\vec{w} \leftarrow \vec{w}-\varepsilon \frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;转到 第2步 直到达到停止标准&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095811.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;改进： – 稍后讨论&lt;/p&gt;

&lt;h2 id=&quot;训练-mlp传统方法training-mlps-traditional-methods&quot;&gt;训练 MLP（传统方法）Training MLPs (traditional methods)&lt;/h2&gt;

&lt;p&gt;传统训练方法的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重太多，训练样例太少&lt;/li&gt;
  &lt;li&gt;太慢&lt;/li&gt;
  &lt;li&gt;数值问题，局部最小值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;👉过拟合、欠拟合、泛化不足&lt;/p&gt;

&lt;p&gt;克服问题的传统技术：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;正则化（例如提前停止、权重衰减、贝叶斯学习）&lt;/li&gt;
  &lt;li&gt;模式预处理、特征提取、降维&lt;/li&gt;
  &lt;li&gt;选择更小的 MLP、更少的层、更少的隐藏神经元、网络修剪&lt;/li&gt;
  &lt;li&gt;用其他方法替换神经网络 （例如 SVM、boosting 等）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;深度学习&quot;&gt;深度学习&lt;/h2&gt;

&lt;p&gt;深度学习有什么不同的？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更大的训练集（数百万而不是数百）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更强大的计算机，多核 CPU 和 GPU 上的并行实现&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特殊网络结构&lt;/p&gt;

    &lt;p&gt;自编码器&lt;/p&gt;

    &lt;p&gt;卷积网络&lt;/p&gt;

    &lt;p&gt;循环网络/LSTM&lt;/p&gt;

    &lt;p&gt;(深度信念网络/受限玻尔兹曼机)&lt;/p&gt;

    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;权重共享 weight sharing&lt;/li&gt;
  &lt;li&gt;逐层学习 layer-wise learning&lt;/li&gt;
  &lt;li&gt;Dropout&lt;/li&gt;
  &lt;li&gt;有用特征的学习 learning of useful features&lt;/li&gt;
  &lt;li&gt;从无标签的例子中学习 learning from unlabeled examples&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;特征学习&quot;&gt;特征学习&lt;/h3&gt;

&lt;p&gt;观察：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;许多像素并没有提供太多的信息&lt;/li&gt;
  &lt;li&gt;相邻的像素是高度相关的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：笑脸&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102320.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们如何将相关信息与无关信息分开？&lt;/p&gt;

&lt;h3 id=&quot;自动编码器-autoencoder&quot;&gt;自动编码器 Autoencoder&lt;/h3&gt;

&lt;p&gt;👉具有这种结构的 MLP&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102549.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学习识别功能：&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right)-\vec{x}^{(j)}\right)^{2}\]

&lt;p&gt;隐蔽层必须分析压缩图像内容的神经主成分的种类&lt;/p&gt;

&lt;h3 id=&quot;堆叠自动编码器-stacked-autoencoders&quot;&gt;堆叠自动编码器 Stacked Autoencoders&lt;/h3&gt;

&lt;p&gt;多层自动编码器的增量训练&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;训练具有单个隐藏层的自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103140.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103247.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过附加隐藏层扩展自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103315.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103412.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;类似地重复过程以添加更多隐藏层&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;👉信息压缩逐层增加非线性、多层主成分分析&lt;/p&gt;

&lt;h3 id=&quot;用于分类的堆叠自动编码器&quot;&gt;用于分类的堆叠自动编码器&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;训练堆叠自动编码器&lt;/li&gt;
  &lt;li&gt;用全连接分类器网络替换解码器网络&lt;/li&gt;
  &lt;li&gt;训练分类器网络&lt;/li&gt;
  &lt;li&gt;训练编码器和分类器网络的所有权重进行几次迭代&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103608.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;堆叠式自动编码器可以使用未标记的示例进行训练&lt;/li&gt;
  &lt;li&gt;增量训练获得更好的结果&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;局部感受野local-receptive-fields&quot;&gt;局部感受野Local Receptive Fields&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%84%9F%E5%8F%97%E9%87%8E/8989338&quot;&gt;感受野是什么&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28492837&quot;&gt;深度神经网络中的感受野(Receptive Field)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;评论里有句话：convNets(cnn)每一层输出的特征图(feature map)上的像素点在原始图像上映射的区域大小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103920.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部感受野迫使网络在本地处理信息。&lt;/p&gt;

&lt;p&gt;示例：图像的局部特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104631.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;权值共享--weight-sharing&quot;&gt;权值共享  Weight Sharing&lt;/h3&gt;

&lt;p&gt;权值共享就是说，给一张输入图片，用一个&lt;a href=&quot;https://baike.baidu.com/item/卷积核/3377590&quot;&gt;卷积核&lt;/a&gt;去扫这张图，卷积核里面的数就叫权重，这张图每个位置是被同样的卷积核扫的，所以&lt;a href=&quot;https://baike.baidu.com/item/权重/10245966&quot;&gt;权重&lt;/a&gt;是一样的，也就是共享。&lt;/p&gt;

&lt;p&gt;我们可以为所有像素生成相同的局部特征吗？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重共享：绑定不同感知器的权重&lt;/li&gt;
  &lt;li&gt;卷积层：绑定一层所有感知器的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104849.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;多通道特征层multi-channel-feature-layers&quot;&gt;多通道特征层Multi-Channel Feature Layers&lt;/h3&gt;

&lt;p&gt;在每个隐藏层中，想为每个像素计算几个不同的特征 → &lt;u&gt;多通道层&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310105353.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积核是大小$h×w×k$的&lt;a href=&quot;https://baike.baidu.com/item/%E5%BC%A0%E9%87%8F/380114&quot;&gt;张量&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;最大池化max-pooling&quot;&gt;最大池化Max-Pooling&lt;/h3&gt;

&lt;p&gt;池化层旨在在空间上聚合信息&lt;/p&gt;

&lt;p&gt;池化（Pooling）是卷积神经网络中的一个重要的概念，它实际上是一种形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化（Max pooling）”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效的原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了过拟合。通常来说，CNN的卷积层之间都会周期性地插入池化层。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Max-Pooling：从局部感受野计算最大值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;池化通常与降低层的分辨率相结合&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110357.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;卷积网络convolutional-networks&quot;&gt;卷积网络Convolutional Networks&lt;/h3&gt;

&lt;p&gt;卷积神经网络（CNN）结合了&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;卷积层&lt;/li&gt;
  &lt;li&gt;池化层&lt;/li&gt;
  &lt;li&gt;全连接分类器网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;例如：Alexnet是2012年Imagenet竞赛的冠军模型，准确率达到了57.1%, top-5识别率达到80.2%。&lt;/p&gt;

&lt;p&gt;AlexNet包含5个卷积层和3个&lt;a href=&quot;https://so.csdn.net/so/search?q=全连接层&amp;amp;spm=1001.2101.3001.7020&quot;&gt;全连接层&lt;/a&gt;，模型示意图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从层到层… – 特征在几何上变得越来越复杂 – 特征变得越来越独立于位置 – 特征变得越来越独立于图案大小 – 特征变得越来越具体&lt;/p&gt;

&lt;h3 id=&quot;resnet层-resnet-layers&quot;&gt;ResNet层 ResNet Layers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.0/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.0/</guid>
        
        <category>机器视觉</category>
        
        
      </item>
    
  </channel>
</rss>
