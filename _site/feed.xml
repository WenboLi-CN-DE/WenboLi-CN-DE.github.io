<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>高傲的电工李</title>
    <description>欢迎来到我的个人博客</description>
    <link>https://wenboli-cn-de.github.io/</link>
    <atom:link href="https://wenboli-cn-de.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 21 Jun 2023 14:36:57 +0200</pubDate>
    <lastBuildDate>Wed, 21 Jun 2023 14:36:57 +0200</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>机器学习 Machine Learning - Neural Networks 神经网络</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;neural-networks-神经网络&quot;&gt;Neural Networks 神经网络&lt;/h1&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

We will learn today…

- What a (deep) neural network is&lt;br /&gt;
-  How do we train it?&lt;br /&gt;
-  … which requires a calculus refresher ☺&lt;br /&gt;
-  Why is everybody talking about it?&lt;br /&gt;
-  Various ways to accelerate gradient descent&lt;br /&gt;
-  Practical tips and tricks for training NNs
  
    &lt;/div&gt;

    &lt;div style=&quot;width: 50%;&quot;&gt;

我们今天将学习以下内容：&lt;br /&gt;
&lt;br /&gt;
- 什么是（深度）神经网络&lt;br /&gt;
- 如何训练神经网络？&lt;br /&gt;
- 这需要温习一下微积分 ☺&lt;br /&gt;
- 为什么大家都在谈论它？&lt;br /&gt;
- 加速梯度下降的各种方法&lt;br /&gt;
- 训练神经网络的实际技巧和诀窍&lt;br /&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

Today‘s Agenda!&lt;br /&gt;
&lt;br /&gt;
-  What is a Neuron?&lt;br /&gt;
-  Architectures and Activation Functions&lt;br /&gt;
-  Loss-functions&lt;br /&gt;
-  Backpropagation and the Chain Rule&lt;br /&gt;
-  Computation graphs&lt;br /&gt;
&lt;br /&gt;
Advanced Topics:
- Accelerating gradient descent
- Regularization in Neural Networks
- Practical considerations
  
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

今天的议程如下：&lt;br /&gt;
&lt;br /&gt;
- 什么是神经元？&lt;br /&gt;
- 架构和激活函数&lt;br /&gt;
- 损失函数&lt;br /&gt;
- 反向传播和链式法则&lt;br /&gt;
- 计算图&lt;br /&gt;
&lt;br /&gt;
深入话题:&lt;br /&gt;
- 加速梯度下降&lt;br /&gt;
- 神经网络中的正则化&lt;br /&gt;
- 实际考虑因素&lt;br /&gt;
  
    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;biological-inspiration-the-brain-生物学灵感大脑&quot;&gt;Biological Inspiration: The brain 生物学灵感：大脑&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;A neuron is the basic computational unit of the brain:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;神经元是大脑的基本计算单元：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144017.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our brain has ~ 1011 neurons&lt;/li&gt;
  &lt;li&gt;Each neuron is connected to ~ 104 other neurons (via synapses)&lt;/li&gt;
  &lt;li&gt;Synapses have different connectivity&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Approx. model: Input impulses are weighted by synapse strength and added up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;我们的大脑有大约10^11个神经元。&lt;/li&gt;
  &lt;li&gt;每个神经元通过大约10^4个突触连接到其他神经元。&lt;/li&gt;
  &lt;li&gt;突触具有不同的连接方式。&lt;/li&gt;
  &lt;li&gt;近似模型：输入脉冲通过突触的强度加权并相加。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Neurons receive input signals and accumulate voltage. After some threshold they will fire spiking responses (highly non-linear response).&lt;/p&gt;

&lt;p&gt;神经元接收输入信号并积累电压。 在达到某个阈值后，它们将激发尖峰响应（高度非线性响应）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144249.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;artificial-neurons-人工神经元&quot;&gt;Artificial Neurons 人工神经元&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;For neural nets, we use a much simpler unit (neuron, perceptron):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于神经网络，我们使用更简单的单元（神经元、感知器）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

3 ingredients:
- Weighting of the input
- Summation
- Non-linear activation function
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;
    
三个要素：
- 输入的加权
- 总和计算
- 非线性激活函数
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Example we already know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logistic regression 逻辑回归&lt;/li&gt;
&lt;/ul&gt;

\[y=\sigma\left(\mathbf{w}^T \mathbf{x}+b\right)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;feedforward-neural-networks-前馈神经网络&quot;&gt;Feedforward Neural Networks 前馈神经网络&lt;/h3&gt;

&lt;p&gt;Building a network:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We can connect lots of units
together into a directed acyclic
graph.&lt;/li&gt;
  &lt;li&gt;This gives a feed-forward
neural network. That’s in
contrast to recurrent neural
networks, which can have
cycles.&lt;/li&gt;
  &lt;li&gt;Typically, units are grouped
together into layers.&lt;/li&gt;
  &lt;li&gt;Each layer connects N input units to M output units.&lt;/li&gt;
  &lt;li&gt;In the simplest case, all input units are connected to all output units. We call this a fully
connected layer.&lt;/li&gt;
  &lt;li&gt;Note: the inputs and outputs for a layer are distinct from the inputs and outputs to the network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;构建一个网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们可以将很多单元连接在一起形成一个有向无环图。&lt;/li&gt;
  &lt;li&gt;这就得到了一个前馈神经网络。与循环神经网络形成对比，后者可以有循环。&lt;/li&gt;
  &lt;li&gt;通常，单元被分组成层。&lt;/li&gt;
  &lt;li&gt;每一层将N个输入单元连接到M个输出单元。&lt;/li&gt;
  &lt;li&gt;在最简单的情况下，所有输入单元都连接到所有输出单元。我们称之为全连接层。&lt;/li&gt;
  &lt;li&gt;注意：层的输入和输出与网络的输入和输出是不同的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I.e., each layer has a M x N weight matrix W&lt;/li&gt;
  &lt;li&gt;Equation in matrix form: $\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;Output units are a function of input units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Feedforward neural networks are also often called multi-layer perceptrons (MLPs)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;每一层具有一个大小为M x N的权重矩阵W。&lt;/li&gt;
  &lt;li&gt;以矩阵形式的方程为：$\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;输出单元是输入单元的函数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;前馈神经网络通常也被称为多层感知器（MLP）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145355.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;activation-funcitons-激活函数&quot;&gt;Activation funcitons 激活函数&lt;/h3&gt;

&lt;p&gt;Different activation functions for introducing non-linearities:
引入非线性的不同激活函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145629.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[\sigma(x)=\frac{1}{1+\exp (-x)}\]

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[0,1]&lt;/li&gt;
  &lt;li&gt;从历史上来看它们非常流行，因为它们可以很好地解释为神经元的饱和“发射率”
    &lt;blockquote&gt;
      &lt;p&gt;常用的激活函数（如Sigmoid函数）在输入值较大或较小的情况下会饱和，即输出值接近0或1，并具有类似于神经元发射的特性。因此，这些激活函数的输出值可以被解释为神经元的饱和“发射率”。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和的神经元会使得梯度消失&lt;/li&gt;
  &lt;li&gt;Sigmoid函数的输出不以零为中心（对于初始化很重要）&lt;/li&gt;
  &lt;li&gt;exp()计算耗费资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150009.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[-1,1]&lt;br /&gt;
✓ 以零为中心（很好）&lt;br /&gt;
× 当饱和时仍然会消失梯度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;修正线性单元（Rectified Linear Unit，ReLU）&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和（在正区间内）&lt;br /&gt;
✓ 计算效率非常高&lt;br /&gt;
✓ 在实践中比sigmoid/tanh函数收敛速度快得多（例如，快6倍）&lt;/p&gt;

&lt;p&gt;× 输出不以零为中心&lt;br /&gt;
× 对于x &amp;lt; 0没有梯度&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152248.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0.1 x, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和&lt;br /&gt;
✓ 计算效率高&lt;br /&gt;
✓ 在实践中收敛速度比sigmoid/tanh函数快很多！（例如，6倍）&lt;br /&gt;
✓ 不会“消失”&lt;/p&gt;

&lt;p&gt;Parametric Rectifier (PReLu):&lt;br /&gt;
参数整流器 (PReLu)：&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (\alpha x, x)$&lt;/p&gt;

&lt;p&gt;Also learn alpha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;指数线性单元&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[f(x)= \begin{cases}x &amp;amp; \text { if } x&amp;gt;0 \\ \alpha(\exp (x)-1) &amp;amp; \text { if } x \leq 0\end{cases}\]

&lt;p&gt;其中，alpha是一个预定义的常数，通常取一个较小的正数。&lt;/p&gt;

&lt;p&gt;✓ 具有ReLU的所有优点&lt;br /&gt;
✓ 输出接近零均值&lt;br /&gt;
× 计算过程中需要使用exp()函数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In practice:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用ReLU。在学习率和初始化时要小心。
    &lt;blockquote&gt;
      &lt;p&gt;对于学习率（learning rate），选择一个合适的值非常重要。过大的学习率可能导致训练不稳定或发散，而过小的学习率可能导致收敛速度过慢。&lt;/p&gt;

      &lt;p&gt;对于初始化（initialization），权重和偏置的初始值也需要谨慎选择。使用不合适的初始化方法可能导致梯度消失或梯度爆炸等问题，影响网络的训练效果。对于使用ReLU的网络，一种常见的初始化方法是使用较小的随机值，如从均匀分布或正态分布中采样得到的值。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;尝试使用Leaky ReLU / ELU。&lt;/li&gt;
  &lt;li&gt;尝试使用tanh函数，但不要期望太多。&lt;/li&gt;
  &lt;li&gt;不要使用sigmoid函数。
    &lt;ul&gt;
      &lt;li&gt;sigmoid函数仅在分类问题的输出激活中使用。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Formalisation:&lt;/p&gt;

&lt;p&gt;每层计算一个函数，因此网络计算函数的组合：&lt;/p&gt;

\[\begin{aligned}
\mathbf{h}^{(1)} &amp;amp; =f^{(1)}(\mathbf{x}) \\
\mathbf{h}^{(2)} &amp;amp; =f^{(2)}\left(\mathbf{h}^{(1)}\right) \\
\vdots &amp;amp;
\end{aligned}\]

&lt;p&gt;或者更简单地：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \mathbf{y}=f^{(L)}\left(\mathbf{h}^{(L-1)}\right) \\
&amp;amp; \mathbf{y}=f^L \circ f^{L-1} \circ \ldots f^{(1)}(\mathbf{x})
\end{aligned}\]

&lt;p&gt;神经网络提供模块化：我们可以将每一层的计算实现为一个黑盒子&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614154844.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-xor-异或&quot;&gt;Example: XOR 异或&lt;/h4&gt;

&lt;p&gt;设计一个实现 XOR 的网络：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161308.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单个单元无法计算!&lt;/li&gt;
  &lt;li&gt;经典的例子，为什么我们需要多层次&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;XOR in terms of elemental operations:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;XOR(a,b) = (a OR b) AND NOT (a AND b)&lt;/p&gt;

&lt;p&gt;设计一个实现XOR的网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;激活函数的硬阈值，x1和x2是二进制的&lt;/li&gt;
  &lt;li&gt;h1 计算 x1 OR x2&lt;/li&gt;
  &lt;li&gt;h2 计算 x1 AND x2&lt;/li&gt;
  &lt;li&gt;y 计算 h1 AND NOT h2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-architectures深层架构&quot;&gt;Deep Architectures深层架构&lt;/h3&gt;

&lt;p&gt;为什么我们需要深入？&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;任何线性层序列都可以用单个线性层等效地表示&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{y}=\underbrace{\mathbf{W}^{(3)} \mathbf{W}^{(2)} \mathbf{W}^{(1)}}_{\tilde{\mathbf{W}}} \mathbf{x}\]

&lt;p&gt;即，我们需要非线性，以利用多个层次&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;具有非线性激活函数的FF-NN是通用函数近似器：
    &lt;ul&gt;
      &lt;li&gt;给定一个潜在的无限量的单元，它们可以任意地逼近任何函数&lt;/li&gt;
      &lt;li&gt;通用函数逼近定理： 单层就足以实现 “普适性”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;那么，单层是否足够？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;尽管通用函数逼近定理表示单层理论上足够，但实际上我们需要指数级（与输入维度成正比）的神经元数量才能实现这一点。
    &lt;ul&gt;
      &lt;li&gt;如果可以学习任何函数，那么结果很可能会过拟合。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;相反，多层网络可以用更少的神经元实现类似的效果。
    &lt;ul&gt;
      &lt;li&gt;紧凑的表示方式比”通用表示”更有效。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-损失函数&quot;&gt;Loss-functions 损失函数&lt;/h2&gt;

&lt;p&gt;训练神经网络的目标函数：&lt;/p&gt;

&lt;p&gt;通用的机器学习方法：逐样本损失 + 正则化惩罚&lt;/p&gt;

\[\boldsymbol{\theta}^*=\underset{\text { parameters } \boldsymbol{\theta}}{\arg \min } \sum_{i=1}^N l\left(\boldsymbol{x}_i, \boldsymbol{\theta}\right)+\lambda \text { penalty }(\boldsymbol{\theta})\]

&lt;p&gt;对于不同的任务，损失函数和输出激活函数的选择有所不同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;回归任务（Regression）：通常使用均方误差（Mean Squared Error）作为损失函数，输出激活函数可以是线性函数或恒等函数。&lt;/li&gt;
  &lt;li&gt;二分类任务（Binary Classification）：常见的损失函数包括二元交叉熵（Binary Cross-Entropy）或对数损失（Log Loss），输出激活函数通常选择sigmoid函数。&lt;/li&gt;
  &lt;li&gt;多类别分类任务（Multi-class Classification）：常用的损失函数是多类别交叉熵（Categorical Cross-Entropy），输出激活函数则通常选择softmax函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Regression 回归&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\boldsymbol{b}^{(L)}
$$

&lt;b&gt;Loss：&lt;/b&gt;

squared error 方差

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\frac{1}{2}\left(\mathbf{f}\left(\mathbf{x}_i\right)-\mathbf{y}_i\right)^2
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

linear Gaussian

$$
p(\mathbf{y} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}, \mathbf{\Sigma}\right)
$$

&lt;br /&gt;

negative log-likelihood 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\log \mathcal{N}\left(\mathbf{y}_i \mid \boldsymbol{\mu}\left(\mathbf{x}_i\right), \boldsymbol{\Sigma}\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Binary classification 二元分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
f=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

hinge-loss 铰链损失

$$
l\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\max \left(0,1-y_i f\left(\boldsymbol{x}_i\right)\right)
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
f=\sigma\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
\begin{aligned}
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)= &amp;amp; -c_i \log f\left(\mathbf{x}_i\right)-\left(1-c_i\right) \log \left(1-f\left(\mathbf{x}_i\right)\right)
\end{aligned}
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中$y_i$是 -1/+1 labels, $c_i$ 是0/1 labels。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-class classification 多类别分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

Multi-class SVM loss 多类 SVM 损失&lt;br /&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
 Not covered
&lt;/div&gt;

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
\mathbf{f}=\operatorname{softmax}\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\sum_{k=1}^K \boldsymbol{h}_{c_i, k} \log y_k\left(\mathbf{x}_i\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中 $\boldsymbol{h}_{c_i, k}$ 是 one hot coding&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;One-hot encoding是一种常用的数据预处理技术，用于将离散特征表示为二进制向量的形式。它常用于机器学习和深度学习任务中，特别是当特征数据中包含分类变量时。&lt;/p&gt;

  &lt;p&gt;在One-hot encoding中，如果一个特征具有n个不同的类别，那么它将被表示为一个长度为n的二进制向量，其中只有一个位置为1，其他位置都为0。被设置为1的位置对应于该特征所属的类别。&lt;/p&gt;

  &lt;p&gt;这样的编码方式有助于解决以下问题：&lt;/p&gt;

  &lt;p&gt;解决分类变量的数值化问题：分类变量通常无法直接用于机器学习算法，因为算法通常期望输入是数值型数据。One-hot encoding可以将分类变量转换为数值型数据，使其适用于算法的处理。&lt;/p&gt;

  &lt;p&gt;避免特征之间的顺序关系：One-hot encoding将每个类别都独立地表示为一个二进制向量，不考虑类别之间的顺序关系。这在一些情况下是有益的，例如避免算法错误地学习到类别之间的顺序或大小关系。&lt;/p&gt;

  &lt;p&gt;需要注意的是，当原始特征具有大量类别时，One-hot encoding会导致特征空间的维度增加，可能会导致稀疏矩阵和计算资源的浪费。在处理高维稀疏数据时，可能需要考虑其他的特征编码方法。&lt;/p&gt;

  &lt;p&gt;在实践中，可以使用多种编程语言和库来执行One-hot encoding，例如Python中的scikit-learn、pandas和TensorFlow等。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Feature Learning 特征学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;神经网络可以被看作是一种学习特征的方式&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;最后一层是标准的线性回归/分类层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络学习特征$\psi(\mathbf{x})$使得线性回归/分类可以解决它&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165612.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165623.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</guid>
        
        <category>专业</category>
        
        <category>机器学习</category>
        
        
      </item>
    
      <item>
        <title>工程力学-动力学/Technische Mechanik IV – Dynamik - Integration der Eulerschen Gleichungen 欧拉方程的积分</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;integration-der-eulerschen-gleichungen-欧拉方程的积分&quot;&gt;Integration der Eulerschen Gleichungen 欧拉方程的积分&lt;/h1&gt;

&lt;p&gt;EULERSCHE Kreiselgleichungen 欧拉陀螺仪方程&lt;/p&gt;

&lt;p&gt;Eulersche Gleichungen beschreiben allgemeine Bewegung eines starren Körpers mit einem fixen Punkt.欧拉方程描述了具有固定点的刚体的一般运动。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162403.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Das Problem der analytischen Lösung dieser Gleichungen hat Wissenschaftler weit über 100 Jahre intensiv beschäftigt. Am Ende hat sich herausgestellt, dass es nur drei Fälle gibt, in denen diese Gleichungen vollständig lösbar sind. (Natürlich numerische Näherungslösung ist immer möglich). Die Nichtintegrierbarkeit dieser Gleichungen wurde ähnlich wir beim Dreikörperproblem auf die fundamentale Arbeiten vom französischen Mathematiker Henry Poincare Ende des XIX Jahrhundert zurückgeführt. Die drei Fälle der Integrierbarkeit werden nach ihren Erfinder genannt&lt;/p&gt;

&lt;p&gt;100 多年来，这些方程的解析解问题一直困扰着科学家们。 最后发现只有三种情况可以完全求解这些方程。  （当然，数值近似总是可能的）。 与三体问题类似，这些方程的不可积性问题可以追溯到19世纪末法国数学家亨利庞加莱的基础工作。 可积性的三种情况以其发明者的名字命名&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162341.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Der einfachste Falls wurde von Euler untersucht und beschäftigt sich mit einem Körper in der Situation, wo das resultierende Moment aller äußerer Kräfte verschwindet (gleich null ist). Dieser Fall wird realisiert, wenn ein schwerer Kreisel sich im homogenen Schwerekraft (z.B. der Erde befindet) und in seinem Schwerpunkt fixiert wird, d.h. der Aufhänge punkt befindet sich im Schwerpunkt des Körpers. In diesem Fall vereinfachen sich die Bewegungsgleichungen:&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-kreisel-der-eulersche-fall-陀螺仪&quot;&gt;Kräftefreier Kreisel (Der Eulersche Fall) 陀螺仪&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163321.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种最简单的情况是由欧拉研究的，涉及到一个物体在所有外力产生的力矩之和为零的情况。这种情况在一个重质量陀螺仪位于均匀重力场（例如地球）并且被固定在其质心的情况下实现，也就是悬挂点位于物体的质心。在这种情况下，运动方程变得更简化：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;Zunächst wird der einfachste Fall eines symmetrischen Körpers behandelt. In diesem Fall
können die Gleichungen in elementaren Funktionen integriert werden:&lt;/p&gt;

&lt;p&gt;首先，处理对称体的最简单情况。 在这种情况下，方程可以集成为初等函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; J_{11}=J_{22}=A ; \quad J_{33}=C \\
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0
\end{aligned}\]

&lt;h2 id=&quot;kräftefreier-symmetrischer-kreisel-kinetik-没有外力作用具有对称性的陀螺&quot;&gt;Kräftefreier symmetrischer Kreisel. Kinetik 没有外力作用、具有对称性的陀螺&lt;/h2&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0 \quad \dot{\omega}_3=0 \rightarrow \quad \omega_3=\omega_{30}=\text { konst } \\
&amp;amp; \left\{\begin{array}{l}
\dot{\omega}_1+\omega_2 \omega_{30} \frac{C-A}{A}=0 \\
\dot{\omega}_2-\omega_1 \omega_{30} \frac{C-A}{A}=0
\end{array} \rightarrow \quad \ddot{\omega}_2=\dot{\omega}_1 \omega_{30} \frac{C-A}{A}=-\omega_1\left(\omega_{30} \frac{C-A}{A}\right)^2\right. \\
&amp;amp; \ddot{\omega}_2+\left(\omega_{30} \frac{C-A}{A}\right)^2 \omega_2=0 \quad \rightarrow \quad \omega_2=\omega_0 \sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\frac{A}{C-A} \frac{1}{\omega_{30}} \dot{\omega}_2=\frac{A}{C-A} \frac{1}{\omega_{30}} \omega_0 \omega_{30} \frac{C-A}{A} \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\omega_0 \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Damit sind die Komponenten der Winkelgeschwindigkeit vollständig bestimmt.
Es bleiben die kinematischen Gleichungen zur Bestimmung der Eulerschen Winkel als
Funktionen der Zeit.&lt;br /&gt;
角速度的分量因此被完全确定。 用于确定作为时间函数的欧拉角的运动学方程仍然存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Geometrische Interpretation: Innerhalb des Körpers umläuft der Vektor der Winkelgeschwindigkeit einen Kreis. Die Umlaufgeschwindigkeit hängt von den Anfangsbedingungen und der Verhältnis der Massenträgheits-momente des Körpers ab.&lt;br /&gt;几何解释：在物体内部，角速度的矢量绕着一个圆旋转。旋转速度取决于初始条件和物体的转动惯量之比。&lt;/p&gt;

\[\Omega_{\text {Umlauf }}=\omega_{30} \frac{C-A}{A}\]

&lt;p&gt;Ermittlung &lt;strong&gt;kinematischer Größen&lt;/strong&gt; wird möglich, wenn wir beachten, dass die Zeitableitung des Drehmomentes im raumfesten Bezugssystem in Abwesenheit des äußeren Momentes gleich null ist.&lt;br /&gt;当我们注意到在没有外部力矩的情况下，相对于固定空间参考系的力矩的时间导数为零时，我们就可以确定&lt;strong&gt;运动学量&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“kinematische Größen” 指的是描述物体运动的量，而不考虑所受到的力或力矩的影响。它们通常包括位置、速度、加速度和角度等物理量。运动学是研究物体运动的分支，主要关注物体的运动状态和其随时间的变化，而不涉及导致这些变化的具体力量或力矩。因此，kinematische Größen 是用来描述物体运动的量，从而提供关于物体位置、速度和加速度等方面的信息。&lt;/p&gt;
&lt;/blockquote&gt;

\[\frac{ {\quad}^I d \vec{L}^{(s)}}{d t}=\overrightarrow{0} \quad \rightarrow \quad \vec{L}^{(s)}=\text { konst }\]

&lt;p&gt;Dies bedeutet, dass der Drall-Vektor in seiner Richtung und betrag konstant bleibt. Wählen wir die raumfesten Koordinaten so, dass der Basisvektor entlang des Drall i3 -Vektors gerichtet ist:&lt;br /&gt;这意味着扭曲矢量的方向和大小保持不变。 让我们选择空间固定坐标，使基本向量沿着扭曲 i3 向量定向：&lt;/p&gt;

\[\vec{L}^{(S)}=L\vec{i}_{\text{3}}\]

&lt;p&gt;Anderseits gilt (vgl. Vorlesung 2, Folie 10):
另一方面（参见第 2 讲，幻灯片 10）：&lt;/p&gt;

\[\vec{L}^{(S)}=\vec{\vec{J}}^{(S)}\cdot{}^I\vec{\omega}^K=A\omega_1\vec{e}_1+A\omega_2\vec{e}_2+C\omega_3\vec{e}_3\]

&lt;p&gt;Aus der Definition der Euler-Winkeln folgt dann: &lt;br /&gt;根据欧拉角的定义，可以得出：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;C\omega_3=L\cos\theta \\
&amp;amp;A\omega_1 =L\sin\theta\sin\varphi  \\
&amp;amp;A\omega_2 =L\sin\theta\cos\varphi 
\end{aligned}\]

&lt;p&gt;Hinweis: Drehung um $\psi$ verändert den Drall-Vektor nicht.&lt;br /&gt;注意：关于$\psi$的旋转不会改变扭曲向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Daraus folgt sofort:&lt;/p&gt;

\[\begin{aligned}
&amp;amp; C \omega_3=L \cos \theta \rightarrow \quad \cos \theta=\frac{C \omega_3}{L}=\frac{C \omega_{30}}{L}=\text { konst } \\
&amp;amp; \theta=\theta_0=\arccos \left(\frac{C \omega_{30}}{L}\right) \\
&amp;amp; \left.\begin{array}{l}
A \omega_1=L \sin \theta \sin \varphi \\
A \omega_2=L \sin \theta \cos \varphi
\end{array}\right\} \\
&amp;amp; \rightarrow \tan \varphi=\frac{\omega_1}{\omega_2}=\frac{\cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}{\sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}=\cot \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \varphi=\frac{\pi}{2}-\omega_{30} \frac{C-A}{A} t+\alpha_0 ; \quad \dot{\varphi}=-\omega_{30} \frac{C-A}{A}=\text { konst } \\
&amp;amp; \dot{\psi} \cos \theta+\dot{\varphi}=\omega_{30} \quad \rightarrow \quad \dot{\psi} \frac{C \omega_{30}}{L}-\omega_{30} \frac{C-A}{A}=\omega_{30} \\
&amp;amp; \dot{\psi} \frac{C}{L}-\frac{C-A}{A}=1 \quad \rightarrow \quad \dot{\psi}=\frac{L}{A}=\text { konst } \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Nutationskegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;自旋轴&lt;/strong&gt;相对于固定空间的进动轴所形成的圆锥。这个圆锥的顶点位于陀螺体的自旋轴上，而圆锥的轴线则与进动轴重合。由于陀螺体的自旋轴会绕着进动轴进行进动，所以形成了这个进动圆锥。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 意味着这个进动圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着进动圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Nutationskegel” 指的是固定在空间中的进动圆锥，用于描述陀螺体或旋转物体的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Spurkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;迹点（运动轨迹上的点）&lt;/strong&gt;相对于固定空间的运动形成的圆锥。这个圆锥的顶点位于迹点所在的位置，而圆锥的轴线则与迹点在空间中的运动方向相对应。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 表示这个迹圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着迹圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Spurkegel” 指的是固定在空间中的迹圆锥，用于描述陀螺体或旋转物体迹点的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Polkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;极轴&lt;/strong&gt;所形成的圆锥。这个圆锥的顶点位于极轴所在的位置，而圆锥的轴线则与极轴重合。&lt;/p&gt;

  &lt;p&gt;“Körperfester” 表示这个极锥是相对于陀螺体自身来定义和测量的，而不是相对于外部空间。这意味着极锥的方向和位置随着陀螺体的运动而变化，取决于陀螺体自身的姿态和旋转状态。&lt;/p&gt;

  &lt;p&gt;因此，”Körperfester Polkegel” 指的是固定在陀螺体自身的极锥，用于描述陀螺体的旋转特性和姿态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;geometrische-interpretation-几何解释&quot;&gt;Geometrische Interpretation 几何解释&lt;/h3&gt;

&lt;p&gt;Der Körper dreht sich mit konstanter Geschwindigkeit $\dot{\varphi}$ um seine Hauptachse $\overrightarrow{e_{3}}$.&lt;/p&gt;

&lt;p&gt;Diese Achse selbst dreht sich mit konstanter Geschwindigkeit $\vec{i}_3$ um die raumfeste Achse, d.h. um den Drall-Vektor $\dot{\psi}$.&lt;/p&gt;

&lt;p&gt;Diese Bewegung wird als reguläre freie Präzession bezeichnet.&lt;/p&gt;

&lt;p&gt;物体以恒定速度 $\dot{\varphi}$ 绕其主轴 $\overrightarrow{e_{3}}$ 自转。&lt;/p&gt;

&lt;p&gt;这个轴本身以恒定速度 $\vec{i}_3$ 绕固定轴旋转，即绕着进动矢量 $\dot{\psi}$。&lt;/p&gt;

&lt;p&gt;这种运动被称为规则的自由进动。&lt;/p&gt;

\[\left.\begin{array}{l}
\dot{\psi}=\frac{L}{A} \\
\cos \theta=\frac{C \omega_{30}}{L} \\
\dot{\varphi}=-\omega_{30} \frac{C-A}{A}
\end{array}\right\}\]

\[\begin{gathered}
L=A \dot{\psi} \\
\rightarrow \quad \omega_{30}=\frac{L}{C} \cos \theta=\frac{A}{C} \dot{\psi} \cos \theta \\
\dot{\varphi}+\frac{C-A}{A} \dot{\psi} \cos \theta=0
\end{gathered}\]

&lt;p&gt;Die letzte Gleichung enthält keine Anfangsbedingungen und stellt den kinematischen Zusammenhang (vgl. Kepplersche Gesetze) dar.&lt;br /&gt;
Die Bewegung kann wie Abrollen des körperfesten Polkegels (von außen) auf dem raumfesten Spurkegel interpretiert werden. Punkte des Körpers bewegen sich auf &lt;strong&gt;Epizykloiden&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后一个方程不包含任何初始条件并表示运动学关系（参见开普勒定律）。
&lt;br /&gt;
该运动可以解释为固定体极锥（从外部）在固定空间轨道锥上的滚动。物体的点在&lt;strong&gt;外摆线&lt;/strong&gt;上移动&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613195029.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Auch hier kann die Bewegung wie Abrollen des körperfesten Polkegels (von innen) auf dem raumfesten Spurkegels interpretiert werden. Punkte des Körpers bewegen sich auf Perizykloiden&lt;br /&gt;
这里的运动也可以解释为刚体固定的极锥（从内部）在固定的迹锥上滚动。物体上的点沿着柏拉克罗侧线运动。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这句话描述了一种运动的解释，其中涉及到刚体固定的极锥和固定的迹锥之间的关系。具体而言，它提到了刚体固定的极锥从内部滚动在固定的迹锥上的过程。在这个过程中，物体上的点按照柏拉克罗侧线的路径进行运动。&lt;/p&gt;

  &lt;p&gt;“Perizykloiden”（柏拉克罗侧线）是一个几何学术语，指的是由一个固定圆与一个在其上滚动的小圆所形成的曲线。在这种描述中，物体上的点运动的路径类似于柏拉克罗侧线。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204331.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-unsymmetrischer-kreisel非对称陀螺仪&quot;&gt;Kräftefreier unsymmetrischer Kreisel.非对称陀螺仪。&lt;/h2&gt;

&lt;h3 id=&quot;der-fall-von-euler---poinsot&quot;&gt;Der Fall von Euler - Poinsot&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Euler-Poinsot陀螺，也称为Euler-Poinsot陀螺体或Euler陀螺，是一种具有特殊运动特性的刚体模型，它展示了一种被称为Euler-Poinsot情形的旋转现象。&lt;/p&gt;

  &lt;p&gt;在Euler-Poinsot情形下，刚体围绕其一个主惯性轴（也称为长轴）旋转，同时绕另外两个互相垂直的瞬时旋转轴（也称为短轴）进行进动。这种运动形式是非常特殊和复杂的，因为它涉及到刚体的自旋和进动的相互耦合。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot陀螺的运动过程中，其自旋和进动的角速度以及角动量都会发生变化。这种陀螺的稳定性和运动特性使其成为研究刚体动力学和旋转物体行为的重要示例。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot情形得名于法国数学家与物理学家Leonhard Euler和Louis Poinsot，他们在18世纪分别独立地研究和描述了这种陀螺的运动。这种情形为刚体动力学领域提供了重要的理论基础，并在许多相关学科中被广泛应用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204539.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jetzt wir der allgemeiner Fall mit drei unterschiedlichen Hauptmassenträgheitsmomenten untersucht (triaxiales Trägheitsellipsoid):&lt;/p&gt;

&lt;p&gt;现在检查具有三个不同主要质量惯性矩的一般情况（三轴惯性椭球）：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

&lt;p&gt;Zwei Integrale des Systems sind einfach zu erkennen. Das erste Integral druck die Erhaltung
der Energie des Systems aus. In diesem Fall ist das nur die kinetische Energie des Körpers.&lt;/p&gt;

&lt;p&gt;系统的两个积分很容易辨认出来。第一个积分表示系统能量的守恒。在这种情况下，它只表示物体的动能。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}-\omega_1 \omega_2 \omega_3\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}\right)=0 \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2
\end{aligned}\]

&lt;p&gt;Das zweite Integral druckt die Erhaltung des Drehimpulses aus:&lt;/p&gt;

&lt;p&gt;第二个积分表示角动量守恒：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3 J_{11}\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1 J_{22}\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1 J_{33}\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3\left(J_{11} J_{22}-J_{11} J_{33}+J_{22} J_{33}-J_{22} J_{11}+J_{33} J_{11}-J_{33} J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2\right)=0 \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \quad A \text { und } \Omega \text { sind Integrationskonstanten. }
\end{aligned}\]

&lt;p&gt;Integrationskonstanten – 积分常数&lt;/p&gt;

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：&lt;/p&gt;

\[J_{11}&amp;lt;J_{22}&amp;lt;J_{33}\]

&lt;p&gt;Aus der Definition der Parameter wird ersichtlich:&lt;/p&gt;

&lt;p&gt;参数的定义显示：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; A=\frac{A^2 \Omega^2}{A \Omega^2}=\frac{\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2}{\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}} \quad \rightarrow \quad J_{11} \leq A \leq J_{33} \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{11} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_2^2 J_{22}\left(J_{22}-J_{11}\right)+\omega_3^2 J_{33}\left(J_{33}-J_{11}\right)=A \Omega^2\left(A-J_{11}\right) \\
&amp;amp; \omega_3^2=\frac{A\left(A-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \Omega^2-\omega_2^2}_{\lambda_3^2})=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：
Analog bekommt man&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{33} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_1^2 J_{11}\left(J_{33}-J_{11}\right)+\omega_2^2 J_{22}\left(J_{33}-J_{22}\right)=A \Omega^2\left(J_{33}-A\right) \\
&amp;amp; \omega_1^2=\frac{A\left(J_{33}-A\right)}{J_{11}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(J_{33}-A\right)}{J_{22}\left(J_{33}-J_{22}\right)} \Omega^2}_{\lambda_1^2}-\omega_2^2)=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Diese Ausdrucke können wir in die letzte übriggebliebene Gleichung einsetzen:
我们可以将这些表达式代入最后剩下的等式：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \left.\begin{array}{l}
\omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right) \\
\omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{array}\right\} \\
&amp;amp; \omega_3 \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \omega_3 \omega_1= \pm \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2 J_{22}= \pm \omega_3 \omega_1\left(J_{33}-J_{11}\right) \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp;
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \frac{d \omega_2}{\sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Es wird beispielhaft der Fall $J_{22}&amp;lt;A&amp;lt;J_{33}$ untersucht. Es werden eine neue Variable und zwei neue Parameter eingeführt:&lt;/p&gt;

&lt;p&gt;在研究 $J_{22}&amp;lt;A&amp;lt;J_{33}$ 的示例情况时，引入了一个新的变量和两个新的参数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2=\lambda_1 u \\
&amp;amp; k^2=\frac{\lambda_1^2}{\lambda_3^2}=\frac{\left(J_{22}-J_{11}\right)\left(J_{33}-A\right)}{\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}&amp;lt;1 \\
&amp;amp; \frac{\lambda_1 d u}{\lambda_1 \lambda_3 \sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp; n=\lambda_3 \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}}=\Omega \sqrt{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \\
&amp;amp; =\Omega \sqrt{\frac{A\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}{J_{11} J_{22} J_{33}}}
\end{aligned}\]

&lt;p&gt;Damit kommen wir zur folgenden Lösung&lt;/p&gt;

&lt;p&gt;这给我们带来了以下解决方案&lt;/p&gt;

\[\pm n\left(t-t_0\right)=\int_0^U \frac{d u}{\sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}\]

&lt;p&gt;Weitere Transformation führt sofort zum elliptischen Integral:&lt;/p&gt;

&lt;p&gt;进一步变换立即得到椭圆积分：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; u=\sin \Phi \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{\cos \vartheta d \vartheta}{\sqrt{1-\sin ^2 \vartheta} \sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}=w(\Phi, k)
\end{aligned}\]

&lt;p&gt;Das ist das unvollständige elliptische Integral 1. Art. Sein Reziprok
führt auf elliptische Funktionen von Jakobi.&lt;/p&gt;

&lt;p&gt;这是第一类不完全椭圆积分，它的倒数导出Jakobi的椭圆函数。&lt;/p&gt;

&lt;p&gt;Definition (Legendre-Normalform) 定义（勒让德范式）&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reziprok davon wird als elliptische Amplitude bezeichnet&lt;/p&gt;

&lt;p&gt;这个的倒数称为椭圆振幅&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \rightarrow \quad \Phi(w)=a m(w)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205828.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ausgehend von dieser Funktion werden die elliptischen Funktionen
von Jacobi eingeführt:&lt;/p&gt;

&lt;p&gt;基于此函数，引入雅可比的椭圆函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \operatorname{sn}(w)=\sin \Phi=\sin (a m(w)) \\
&amp;amp; c n(w)=\cos \Phi=\cos (a m(w)) \\
&amp;amp; d n(w)=\sqrt{1-k^2 \sin ^2 \Phi}=\sqrt{1-k^2 \operatorname{sn}^2(w)}
\end{aligned}\]

&lt;p&gt;Sie werden als &lt;strong&gt;sinus amplitudinis&lt;/strong&gt;, &lt;strong&gt;cosinus amplitudinis&lt;/strong&gt; und  &lt;strong&gt;delta amplitudinis&lt;/strong&gt; bezeichnet.&lt;/p&gt;

&lt;p&gt;Diese Funktionen sind periodisch mit der Periode, die vom Parameter k abhängig ist. Die Abhängigkeit hängt mit dem kompletten elliptischen Integral zusammen:&lt;/p&gt;

&lt;p&gt;它们被称为&lt;strong&gt;正弦波&lt;/strong&gt;、&lt;strong&gt;余弦波&lt;/strong&gt;和&lt;strong&gt;三角波&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这些函数是周期性的，周期取决于参数 k。 依赖关系与完全椭圆积分有关：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; K(k)=\int_0^{\frac{\pi}{2}} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; d n(w+2 K)=d n(w) \\
&amp;amp; \operatorname{sn}(w+4 K)=\operatorname{sn}(w) \\
&amp;amp; c n(w+4 K)=c n(w) \\
&amp;amp; s n^2(w)+c n^2(w)=1
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210148.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210206.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210222.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210241.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mithilfe dieser Funktionen können wir die Komponenten der Winkelgeschwindigkeit sofort bestimmen:&lt;/p&gt;

&lt;p&gt;使用这些函数，我们可以立即确定角速度的分量：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2= \pm \lambda_1 \operatorname{sn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \sqrt{\lambda_1^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \lambda_1 \operatorname{cn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \sqrt{\lambda_3^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 \sqrt{1-k^2 s^2\left(n\left(t-t_0\right)\right)} \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 d n\left(n\left(t-t_0\right)\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Kinematische Teilaufgabe führt sofort zu einer weiteren Quadratur.
运动学子任务立即导致另一个正交。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; L \sin \varphi \sin \theta=J_{11} \omega_1 \\
&amp;amp; L \cos \varphi \sin \theta=J_{22} \omega_2 \\
&amp;amp; L \cos \theta=J_{33} \omega_3 \\
&amp;amp; \theta=\arccos \left(\frac{J_{33} \omega_3}{L}\right) \\
&amp;amp; \tan \varphi=\frac{J_{11} \omega_1}{J_{22} \omega_2} \rightarrow \quad \varphi=\arctan \left(\frac{J_{11} \omega_1}{J_{22} \omega_2}\right)
\end{aligned}\]

&lt;p&gt;Für Winkel $\varphi$ bleibt eine Differentialgleichung 1. Ordnung, die bei Bedarf integriert werden kann:&lt;/p&gt;

&lt;p&gt;角度 $\varphi$ 的一阶微分方程仍然存在，必要时可以对其进行积分：&lt;/p&gt;

\[\dot{\psi} \cos \theta+\dot{\varphi}=\omega_3 \quad \rightarrow \quad \dot{\psi}=\frac{\omega_3-\dot{\varphi}}{\cos \theta}=L \frac{J_{11} \omega_1^2+J_{11} \omega_2^2}{J_{11}^2 \omega_1^2+J_{22}^2 \omega_2^2}\]

&lt;p&gt;Der zweite Fall $J_{11}&amp;lt;A&amp;lt;J_{22}$ kann analog untersucht werden.&lt;/p&gt;

&lt;p&gt;第二种情况$J_{11}&amp;lt;A&amp;lt;J_{22}$可以类推.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Qualitativer Charakter der Bewegung:&lt;/p&gt;

&lt;p&gt;Ein rotationssymmetrischer Körper bewegt sich so, dass der Nutationswinkel konstant bleibt. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse bleiben auch konstant.&lt;/p&gt;

&lt;p&gt;Bei einem nicht rotationssymmetrischen Körper (einem dreiachsigen Ellipsoid) wird das alles gestört. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse werden zeitvariabel. Auch der Nutationswinkel wird zeitveränderlich, aber alle kinematischen Größen der Bewegung können in geschlossener Form (aber nicht in elementaren Funktionen) bestimmt werden.&lt;/p&gt;

&lt;p&gt;运动的定性特征：&lt;/p&gt;

&lt;p&gt;对于一个具有旋转对称性的物体，其运动使得进动角保持恒定。进动和自转的速度也保持恒定。&lt;/p&gt;

&lt;p&gt;然而，对于一个非旋转对称的物体（如一个三轴椭球体），这些特性会受到扰动。进动和自转的速度将随时间变化。进动角度也会随时间变化。尽管如此，运动的所有运动学量可以以闭合形式（但不是基本函数）确定&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/TM4-03/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/TM4-03/</guid>
        
        <category>专业</category>
        
        <category>工程力学</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - SLAM</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-6-self-localization-and-mapping&quot;&gt;Chapter 6: Self-Localization and Mapping&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sebastian Thrun, Wolfram Burgard, Dieter Fox, Probabilistic Robotics. MIT Press,
2005, Chapter 7-13 (partly)&lt;/li&gt;
  &lt;li&gt;Hugh Durrant-Whyte, Tim Bailey, Simultaneous Localization and Mapping: Part I,
IEEE Robotics and Automation Magazine, 13(2), pg. 99-110, 2006&lt;/li&gt;
  &lt;li&gt;Tim Bailey, Hugh Durrant-Whyte, Simultaneous Localization and Mapping: Part II,
IEEE Robotics and Automation Magazine, 13(3), pg. 108-117, 2006&lt;/li&gt;
  &lt;li&gt;Bruno Siciliano, Khatib Oussama (Hrsg.), Springer Handbook of Robotics, Springer,
2008, Chapter 37&lt;/li&gt;
  &lt;li&gt;Joachim Hertzberg, Kai Lingemann, Andreas Nüchter, Mobile Roboter – Eine
Einführung aus Sicht der Informatik, Springer 2012, Chapters 5+6&lt;/li&gt;
  &lt;li&gt;Ingemar J. Cox, Blanche – an Experiment in Guidance and Navigation of an
Autonomous Robot Vehicle. IEEE Transactions on Robots and Automation, 7(2),
pg. 193-204, 1991&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Self Localization 自定位&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;self localization problem 自定位问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;environment is known (map) 环境是已知的&lt;/li&gt;
  &lt;li&gt;vehicle position and orientation are unkonown 车辆位置和方向未知&lt;/li&gt;
  &lt;li&gt;vehicle observes the (local) environment 车辆观察（本地）环境&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612161042.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;localization-with-landmarks-地标定位&quot;&gt;Localization with landmarks 地标定位&lt;/h2&gt;

&lt;h3 id=&quot;landmarks-地标&quot;&gt;landmarks 地标：&lt;/h3&gt;

&lt;p&gt;consistently identifiable points in the world. E.g. lighthouses, feature points in imaging&lt;/p&gt;

&lt;p&gt;一直可以被识别的点，例如灯塔、图像中的特征点&lt;/p&gt;

&lt;p&gt;#### what can we conclude from… 2d：我们可以从…中得出什么结论 ?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the distance to a given landmark?到一个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position on a circle&lt;/li&gt;
      &lt;li&gt;unknown orientatioin&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between two landmarks?到两个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;2 possible positons&lt;/li&gt;
      &lt;li&gt;unknown orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between three landmarks?到三个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position(some exceptions are possible)机器人位置（可能有一些例外）&lt;/li&gt;
      &lt;li&gt;orientationo unknown&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162130.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the angle, from which a landmark is being observed 地标的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;positon unknown&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162831.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the angle from which two landmarks are being observed? 两个地标之间的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;robot position on an arc or line segment 圆弧或线段上的机器人位置&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;approch: inscribed angle theorem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162950.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;linear-landmarks-线性地标&quot;&gt;linear landmarks 线性地标&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;例如： roadway lines, curbs, and walls 道路线、路缘和墙壁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612163335.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;what-can-we-conclude-from-我们可以从中得出什么结论-&quot;&gt;what can we conclude from… ：我们可以从…中得出什么结论 ?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;the orthogonal distance,in which a line is being observed 观测一条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;position on two parallel lines 两条平行线&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the orthogonal distance to two lines 两条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;4 points / 2 points&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612164044.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;one-shot-localization-一次性定位算法&quot;&gt;One-Shot Localization 一次性定位算法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;“One-Shot Localization” 是指在&lt;strong&gt;仅有一次观测&lt;/strong&gt;或信息的情况下进行定位或位置估计的过程。它是指通过&lt;strong&gt;一次观测或一次输入&lt;/strong&gt;，从未知位置或环境中准确地确定目标的位置或姿态。在传感器技术和机器人领域中，这个术语通常用于描述使用单个数据样本进行&lt;strong&gt;位置估计&lt;/strong&gt;的方法或算法。这种方法可能利用传感器数据、图像处理技术或其他信息源来实现目标的定位。与传统的迭代定位算法相比，One-Shot Localization 着重于通过单次观测尽可能准确地确定目标的位置，从而减少计算和时间成本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;给定：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a map with a set of landmarks&lt;/li&gt;
  &lt;li&gt;a set of boserved landmarks from seen from a vehicle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;任务：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;how do I have to shift and rotate the vehicle so that the observed landmarks match best the land marks in the map?&lt;/li&gt;
  &lt;li&gt;我如何移动和旋转车辆，以便观察到的地标与地图中的地标最匹配？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;数学方法：mathematically&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;which movement (translation + rotation) transforms &lt;em&gt;vehicle coordinates&lt;/em&gt; into &lt;em&gt;world coordinates&lt;/em&gt; such that observed &lt;strong&gt;landmark positions fit to map position&lt;/strong&gt;?&lt;/li&gt;
  &lt;li&gt;哪种运动（平移+旋转）将&lt;em&gt;车辆坐标&lt;/em&gt;转换为&lt;em&gt;世界坐标&lt;/em&gt;，以便观察到的&lt;strong&gt;地标位置适配到地图位置&lt;/strong&gt;？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165001.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;landmark positions in world coordinates (map) 世界坐标中的地标位置（地图）：&lt;/li&gt;
&lt;/ul&gt;

\[\vec{p_{1}},\cdots,\vec{p_{i}},...\]

&lt;ul&gt;
  &lt;li&gt;observed landmark positions in vehicle coordinates 在车辆坐标中观察到的地标位置:&lt;/li&gt;
&lt;/ul&gt;

\[\vec{q}_{1},\cdot\cdot\cdot,\vec{q}_{i},\cdot\cdot\cdot,\vec{q}_{N}\]

&lt;ul&gt;
  &lt;li&gt;optimization problem:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612182552.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最小化下面的式子：minimize&lt;/li&gt;
&lt;/ul&gt;

\[E(R,\bar{t})=\frac{1}{N}\sum_{i=1}^{N}||\vec{p_{i}}-(R\vec{q_{i}}+\vec{t})||^{2}\]

&lt;p&gt;with：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; E(R, \vec{t})=\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}+\bar{p}-\left(R\left(\vec{q}_i^{\prime}+\bar{q}\right)+\vec{t}\right)\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right)+(\bar{p}-R \bar{q}-\vec{t})\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+\frac{2}{N} \sum_{i=1}^N(\bar{p}-R \bar{q}-\vec{t})^T\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+2(\bar{p}-R \bar{q}-\vec{t})^T\left(\frac{1}{N} \sum_{i=1}^N \vec{p}_i^{\prime}-R \frac{1}{N} \sum_{i=1}^N \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\underbrace{\|\bar{p}-R \bar{q}-\vec{t}\|^2} \\
&amp;amp; =0 \quad \underbrace{N}_{=0} \\
&amp;amp; \Rightarrow \vec{t}=\bar{p}-R \bar{q} \\
&amp;amp; =\left\|\vec{p}_i^{\prime}\right\|^2+\left\|\vec{q}_i^{\prime}\right\|^2-2\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime} \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;最大化：&lt;/p&gt;

&lt;p&gt;$\sum_{i=1}^N\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不同的方法，例如 SVD：&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{i=1}^{N}\left(\vec{p}_{i}^{\prime}\right)^{T} R \vec{q}_{i}^{\prime}=\sum_{i=1}^{N} \operatorname{Tr}\left(R \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\right)=\operatorname{Tr}(R H) \quad \text { with } H=\sum_{i=1}^{N} \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;mathematical theorem (singular value decomposition, SVD):
for every real matrix H exist orthogonal matrices U,V, and a diagonal matrix D with nonnegative entries, such that:
数学定理（奇异值分解，SVD）：对于每个实数矩阵 H，存在正交矩阵 U、V 和具有非负项的对角矩阵 D，使得：$H=U D V^{T}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;solution：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612190302.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

\[(Derivation and proof: K.S.Arun, T.S.Hunang, S.D.Blostein, Least Squares Fitting of Two 3-D Point Sets,
IEEE Transactions on Pattern Analysis and Machine Intelligence 9(5), 1987)\]

&lt;ul&gt;
  &lt;li&gt;what to do if landmarks are not uniquely identifiable?如果地标不是唯一可识别的怎么办？
    &lt;ul&gt;
      &lt;li&gt;$\vec{q_{i}}\ \mathrm{\bf~might~rester~to~any~of}\ \ \vec{p_{1}},\ …,\vec{p_{i}},…$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;brute force solution: try all possible combinations 蛮力解决方案：尝试所有可能的组合
    &lt;ul&gt;
      &lt;li&gt;computationally too expensive 计算成本太高&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;iterative, greedy assignments: 迭代，贪婪的分配：
    &lt;ul&gt;
      &lt;li&gt;$\text { assign } \vec{q}_i \text { to closest landmark among } \vec{p}_1, \ldots, \vec{p}_i, \ldots$&lt;/li&gt;
      &lt;li&gt;reassign all observations incrementally 逐步重新分配所有观察结果&lt;/li&gt;
      &lt;li&gt;👉 ICP algorithm 迭代最近算法&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;icp-algorithm-三维点云配准&quot;&gt;ICP algorithm 三维点云配准&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;ICP（Iterative Closest Point）算法是一种迭代的点云配准算法，用于将两个或多个点云之间进行对齐和匹配。它是一种常用的三维点云配准算法，在计算机视觉、机器人和地图构建等领域得到广泛应用。&lt;/p&gt;

  &lt;p&gt;ICP算法的基本思想是通过迭代的方式，将待配准的目标点云与参考点云对齐，使它们在空间中尽可能重合。算法的核心是找到两个点云之间的最佳刚性变换（旋转和平移），使得它们的重叠部分最大化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612192547.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Iterative Closest Point (ICP)(Besl, McKay 1992)
    &lt;ul&gt;
      &lt;li&gt;calculates rotation $R$ and translation $\overrightarrow{t}$ in order to transform a set of points $Q$ onto another set of points $P$ 计算旋转矩阵 $R$ 和平移向量 $\overrightarrow{t}$，以将点集 $Q$ 变换到另一个点集 $P$&lt;/li&gt;
      &lt;li&gt;ICP always terminates ICP总是终止&lt;/li&gt;
      &lt;li&gt;ICP converges to local minimum of &lt;br /&gt; 收敛到局部最小值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[E(R,\vec{t})\longrightarrow\frac{1}{N}\sum_{i=1}^{N}\,||\vec{p}_{j}(i)-\left(R\vec{q}_{i}+\vec{t}\right)||^{2}\]

&lt;ul&gt;
  &lt;li&gt;简要证明
    &lt;ul&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 8 assuming fixed assignments between points 根据结构，在步骤8中，$E(R,\overrightarrow{t})$是最小化的，假设点之间有固定的分配。&lt;/li&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 4 assuming fixed translation and rotation 根据结构，在步骤4中，假设固定的平移和旋转，$E(R,\overrightarrow{t})$被最小化了&lt;/li&gt;
      &lt;li&gt;hence, $E(R,\overrightarrow{t})$ never increases&lt;/li&gt;
      &lt;li&gt;since number of possible assignments is finite, we cannot generate new
permutations in step 4 from a certain point on (pigeonhole/Dirichlet principle) 由于可能的分配数量是有限的，我们不能在第 4 步中从某个点生成新的排列（pigeonhole/Dirichlet principle）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;incremental-localization-增量本地化&quot;&gt;Incremental Localization 增量本地化&lt;/h2&gt;

&lt;h2 id=&quot;mapping-映射&quot;&gt;Mapping 映射&lt;/h2&gt;

&lt;h2 id=&quot;simultaneous-localization-and-mappingslam&quot;&gt;Simultaneous Localization and Mapping(SLAM)&lt;/h2&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/06-SLAM/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/06-SLAM/</guid>
        
        <category>专业</category>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-4-optical-flow-and-image-based-tracking--光流和基于图像的跟踪&quot;&gt;Chapter 4: Optical Flow and Image Based Tracking &lt;br /&gt; 光流和基于图像的跟踪&lt;/h1&gt;
&lt;p&gt;欢迎来到《汽车视觉》讲座中关于光流和基于图像的跟踪的章节。&lt;/p&gt;

&lt;p&gt;首先，让我们看一下文献。这里有几篇来自教科书和原创论文的章节，涉及到今天讨论的主题。前三个条目是教科书的一部分，介绍了光流估计的主题。第四篇出版物是一篇原创论文，描述了Hon和Chun的方法。如果你有兴趣阅读原始论文，最后一篇论文涉及内核化相关滤波器，这在本章后半部分讨论图像中的物体跟踪时已经介绍过。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;B. Jähne, Digitale Bildverarbeitung, Springer, 2005, Chapter 14&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;E.R. Davies, Machine Vision. Theory. Algorithms. Practicalities. Elsevier, 2005,Section 21.6 ff&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;R. Jain, R. Kasturi, B. G. Schunck, Machine Vision. McGraw Hill, 1995, Section 14.1-14.4&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;B. K. P. Horn, B. G. Schunck, Determining Optical Flow. Artificial Intelligence 17, 1981, pg. 185-203&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;J. F. Henriques, R. Caseiro, P. Martins, J. Batista, High-Speed Tracking with Kernelized Correlation Filters, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 37, no. 3, pp. 583-596, 2015&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-sequences-图像序列&quot;&gt;Image Sequences 图像序列&lt;/h2&gt;

&lt;p&gt;到目前为止，我们&lt;strong&gt;已经研究了单幅灰度图像或双目摄像头设置中的成对灰度图像&lt;/strong&gt;。现在，我们想把这种分析&lt;em&gt;扩展到&lt;/em&gt;&lt;strong&gt;随着时间推移记录的灰度图像序列&lt;/strong&gt;。为此，我们用第三个变量T来扩展灰度函数，它代表记录的时间。在我们的案例中，我们将T解释为一个整数，用来计算到现在为止记录的图像数量。&lt;/p&gt;

&lt;p&gt;到目前为止我们有：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;examined single images $g(u, v)$&lt;/li&gt;
  &lt;li&gt;examined stereo images $\left(g_l(u, v), g_r(u, v)\right)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;图像序列：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;examine a sequence of images $g(u, v, t)$&lt;/li&gt;
  &lt;li&gt;观测图像随时间的变化&lt;/li&gt;
  &lt;li&gt;自我运动(ego motion)引起的变化&lt;/li&gt;
  &lt;li&gt;观察物体运动引起的变化&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;optical-flow-光流&quot;&gt;Optical Flow 光流&lt;/h2&gt;

&lt;p&gt;光流是由相机和观察对象之间的相对运动引起的图像中任何点的明显移动&lt;/p&gt;

&lt;p&gt;我们感兴趣的是观察图像序列中发生的变化，这些变化可能&lt;strong&gt;是由相机的自我运动、图像中观察到的物体的运动或两者的组合引起&lt;/strong&gt;的。&lt;/p&gt;

&lt;p&gt;这就引出了光流的第一个定义： &lt;strong&gt;光流是图像中任何一点的明显移动，由相机和被观察物体之间的相对运动引起&lt;/strong&gt;。重要的是要看到，光流是图像空间中的一个属性。它是图像坐标中的一个矢量，它连接了前一幅图像中某一点的位置和后一幅图像中同一点的位置。它不是一个物体的三维运动，而是图像空间中的二维运动。&lt;/p&gt;

&lt;p&gt;这里我们有一个非常简单的例子，就是两幅图像一个接一个地记录下来，我们可以很容易地观察到一些光流。我们可以看到情况是如何变化的，某些点是如何在两幅图像之间移动的，这种移动就是光流。我们可以区分两种不同的光流概念。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/8f91a500-9003-4cd8-81a4-46248963f96d.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一个概念叫做&lt;strong&gt;密集流&lt;/strong&gt;，我们的目标是为图像中的每一个点计算一个流向量，或者至少计算尽可能多的点，从而形成一个完整的流场或流向量场。&lt;/p&gt;

&lt;p&gt;第二个概念是&lt;strong&gt;稀疏流&lt;/strong&gt;，我们只对获得特定兴趣点的光流向量感兴趣，例如图像中突出特征点的一个子集。这建议使用特征点方法，我们分析每张图像，检测特征点，然后比较第一张图像中的哪些特征点也能在随后的图像中找到。这种方法使我们能够为特征点创建稀疏的流向量。&lt;/p&gt;

&lt;p&gt;然而，这并不足以实现密集流，因为图像中的许多点不是特征点，我们用这种方法不会得到这些点的流向量。&lt;/p&gt;

&lt;p&gt;– 密集流：我们确定图像中每个点的流矢量
– 稀疏流：我们仅为（一小部分）显着点（例如特征点）确定流向量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Typical Optical Flow Fields 典型光流场&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们研究一下在某些情况下我们可以期待的典型流场。让我们假设我们有一个平面世界，在这个世界里，一辆车正笔直地向前行驶，我们观察到地面在一条水平线以下。在这些条件下得到的光流向量显示在左上方的图像中。每个流向量都用黑线标出，红色菱形表示第一幅图像中的相应点。&lt;/p&gt;

&lt;p&gt;我们可以观察到，流动向量正在向地平线上的一个虚拟点靠拢，流动向量的长度根据与摄像机的距离而变化。点越远，流动矢量越小。在天空中，我们无法确定任何流动矢量，因为那些点实际上位于很远的地方，导致流动等于零。&lt;/p&gt;

&lt;p&gt;第二张图片描述了一个类似的情况，但有一个俯仰运动。如果我们想象坐在一辆汽车里，有人把车头往下推，然后松开，造成俯仰运动，流场看起来与直行驾驶的情况类似。然而，在这种情况下，我们在地平线上仍然有不同于零的流向，而且流向的整体方向也不同。&lt;/p&gt;

&lt;p&gt;第三张图片显示了滚动运动，当车辆沿其纵轴倾斜时，就会出现这种情况，就像摩托车在弯道上行驶一样。流场表现为滚动运动。当然，这种滚动运动也可以与直线行驶的运动相结合，导致不同的整体流场，如第四张图片所描述的，车辆向右行驶通过一个曲线。&lt;/p&gt;

&lt;p&gt;道路上的预期流&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203326.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;光照是恒定的。&lt;/li&gt;
  &lt;li&gt;目标点没有被遮挡。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些是我们在这些情况下可能观察到的典型光流场。只是为了让您对其外观有一个概念。现在让我们讨论如何计算光流。一种方法是了解场景中所有物体的真实运动和三维场景结构，然后可以计算光流。然而，这不是我们的目的。我们的目标是直接从图像序列中提取光流。&lt;/p&gt;

&lt;p&gt;为了做到这一点，我们做出了一些假设。首先，我们假设图像序列是在恒定照明下记录的，这意味着每个点的亮度随时间不变。第二个假设是我们要观察的点不会在视频序列中的任何图像中被遮挡。如果被遮挡，我们就无法计算光流。这个假设是相当明显的。&lt;/p&gt;

&lt;p&gt;基于这些假设，我们为光流建立了一个条件。我们引入光流向量ΔUΔV，描述了某个点的光流，表示为U B。&lt;/p&gt;

&lt;p&gt;由于我们假设该点的照明在时间上不变，我们可以得出结论，先前图像中该点的灰度值（在时间T）必须等于稍后图像中位置为U + ΔU，V + ΔV，T + ΔT的像素的灰度值。这个必要条件要求ΔUΔV是位置U，V处点的光流。然而，这还不足够，因为可能有许多点满足这个等式。&lt;/p&gt;

&lt;p&gt;从这个必要条件出发，我们想推导出如何计算ΔU和ΔV。我们从等式的两边减去U，V，T处的灰度G，然后用一阶泰勒多项式替换右边的第一部分。这得到了一个名为“&lt;strong&gt;运动约束方程&lt;/strong&gt;”的方程。这个方程提供了一个条件，必须满足ΔUΔV才能成为某个像素位置的光流。&lt;/p&gt;

&lt;p&gt;重要的是要注意，运动约束方程中需要的所有偏导数都是在用于计算光流的第一个图像对的某个位置处计算的。&lt;/p&gt;

&lt;p&gt;光流的必要条件：&lt;/p&gt;

\[g(u, v, t)=g(u+\Delta u, v+\Delta v, t+\Delta t)\]

&lt;ul&gt;
  &lt;li&gt;必要但不充分。&lt;/li&gt;
  &lt;li&gt;不够清晰&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203515.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运动约束方程：&lt;/strong&gt;&lt;/p&gt;

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

&lt;p&gt;– 偏导数从何而来？&lt;/p&gt;

&lt;p&gt;使用导数滤波器掩模（例如Sobel）进行滤波会产生$\frac{\partial g}{\partial u}, \frac{\partial g}{\partial v}$&lt;/p&gt;

&lt;p&gt;灰度值差异产生 $\frac{\partial g}{\partial t} \approx g(u, v, t+1)-g(u, v, t)$&lt;/p&gt;

&lt;p&gt;那么，我们如何计算这些偏导数呢？关于U和V的偏导数是我们在本课程的第一章中已经推导出来的。我们可以使用滤波器掩模，如Sobel滤波器掩模，从灰度图像中计算这些偏导数。所以这不是什么新东西，可以很容易地完成。关于时间方向的灰度值函数的偏导数也很容易计算。我们可以通过比较后续图像中的灰度值与当前图像中的灰度值（都在所关注的位置上进行评估）来近似计算它。这个近似给出了这个偏导数的近似值。因此，我们只需要灰度值信息来计算这些偏导数。从一对图像中，我们获得了一个以运动约束方程形式的约束，其中有未知的Delta U和Delta V。因此，从一对图像中，我们得到一个约束。&lt;/p&gt;

&lt;p&gt;让我们看一下运动约束方程的简单示例。为此，我们将分析一个一维信号，即图像的一行，其中整个光流是向左或向右移动的，由一维向量Delta U表示。假设我们有一个用青色表示的灰度值函数，对于较小的U值有较小的值，对于较大的U值有较大的灰度值。我们要分析的是位于虚线所示位置U处的光流。我们假设在后续图像中，我们有相同类型的灰度值斜坡，但向右移动了一定的距离。后续图像的新灰度值函数由蓝色曲线表示。&lt;/p&gt;

&lt;p&gt;一维信号的图示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203815.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们正在寻找的光流代表了向右的移动，如这个水平向量所示。对于时间方向的偏导数测量了感兴趣位置U的灰度值函数的变化。在这种情况下，我们可以观察到灰度值已经减小，因此这个偏导数可以用指向下方的垂直箭头来表示，与坐标轴相反。因此，这个导数的值是负数。&lt;/p&gt;

&lt;p&gt;此外，我们知道，对于空间方向U，灰度级梯度可以被解释为感兴趣位置的灰度值函数的斜率。可以从灰度值函数的切线绘制的虚线红线来测量斜率，如此处所示。通过将这个虚线红线移动到垂直箭头的末端，我们可以观察到在灰度值遵循线性逼近的最佳情况下，我们得到一个三角形。这个三角形可以用来计算切线的斜率，该斜率大约等于垂直箭头长度与水平箭头长度的比值。由于垂直箭头向下指向，与坐标轴相反，我们需要添加一个负号来表示这个导数的负值。这给出了右侧所示的方程。如果我们将两边都乘以Delta U，我们就得到了一维情况下的运动约束方程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运动约束方程：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这种方法可以直接扩展到二维情况。然而，有一个重要的区别。在一维信号的情况下，我们可以很容易地通过解方程相对于Delta U来计算Delta U，并获得Delta U的估计值。在二维情况下，这是不可能的，因为一个方程不能为两个未知变量提供解。&lt;/p&gt;

&lt;p&gt;那么，我们该如何解决这个问题呢？关键是添加额外的方程，以获得两个未知变量Delta U和Delta V的多个方程。为此，我们假设光流在相邻点之间没有显著变化。我们假设右侧和左侧相邻像素的光流，以及上方、下方或对角线相邻像素的光流完全相同。通过为每个相邻像素计算一个运动约束方程，我们可以创建一个具有多个方程和两个未知数的线性方程组。&lt;/p&gt;

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

&lt;p&gt;– 问题：一个方程，两个未知变量
– 附加假设：光流在局部环境中是恒定的。&lt;/p&gt;

\[\begin{aligned}
-\frac{\partial g(u, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v, t)}{\partial v} \\
-\frac{\partial g(u-1, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u-1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u-1, v, t)}{\partial v} \\
-\frac{\partial g(u+1, v, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u+1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u+1, v, t)}{\partial v} \\
-\frac{\partial g(u, v-1, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v-1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v-1, t)}{\partial v} \\
-\frac{\partial g(u, v+1, t)}{\partial t} &amp;amp; \approx \Delta u \cdot \frac{\partial g(u, v+1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v+1, t)}{\partial v}
\end{aligned}\]

&lt;h3 id=&quot;lucas-kanade-method-卢卡斯-卡纳德方法&quot;&gt;Lucas-Kanade Method 卢卡斯-卡纳德方法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;在计算机视觉中，卢卡斯-卡纳德方法是一种广泛使用的&lt;strong&gt;光流估计的差分方法&lt;/strong&gt;，这个方法是由Bruce D. Lucas和Takeo Kanade发明的。&lt;strong&gt;它假设光流在像素点的邻域是一个常数，然后使用最小平方法对邻域中的所有像素点求解基本的光流方程&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;通过结合几个邻近像素点的信息，卢卡斯-卡纳德方法(简称为L-K方法)&lt;strong&gt;通常能够消除光流方程里的多义性&lt;/strong&gt;。而且，与逐点计算的方法相比，&lt;strong&gt;L-K方法对图像噪声不敏感&lt;/strong&gt;。不过，由于这是一种局部方法，所以在图像的均匀区域内部，&lt;strong&gt;L-K方法无法提供光流信息&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果我们有确切的两个方程和两个未知数，我们可以希望从这些方程中获得唯一解。如果我们有多于两个方程，由于随机性引起的方程之间的冲突，很可能我们找不到任何解。然而，我们可以通过说明我们不需要找到Delta U和Delta V以使运动约束方程完全相等来克服这个问题。相反，我们希望找到尽可能多地满足方程的Delta U和Delta V，这可以通过最小化这些方程的残差平方和来实现。残差表示运动约束方程的左右两侧之间的差异。&lt;strong&gt;这种方法被称为计算某一点的光流的Lucas-Kanade方法&lt;/strong&gt;。这种方法的思想是在感兴趣点周围的某个区域内最小化残差平方和，例如最近的3x3像素的正方形区域。&lt;/p&gt;

&lt;p&gt;可以通过最小化二次误差来估计光流&lt;/p&gt;

\[\begin{aligned}
\operatorname{minimize}_{\Delta u, \Delta v} \sum_{(i, j) \in\{-1,0,1\}^2}\left(\frac{\partial g(u+i, v+j, t)}{\partial t}\right. &amp;amp; +\Delta u \cdot \frac{\partial g(u+i, v+j, t)}{\partial u} \left.+\Delta v \cdot \frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

&lt;p&gt;解决这个优化问题后，我们获得了Delta U和Delta V。解决方案涉及计算要最小化的函数相对于两个未知变量Delta U和Delta V的偏导数。然后将这些导数置零，并解出所得到的方程组，得到一个2x2矩阵&lt;/p&gt;

&lt;p&gt;左边乘以未知变量的向量Delta U和Delta V（表示光流向量），等于右边具有两个条目的向量。矩阵和右边的向量可以从灰度值梯度信息计算得出，因此不需要额外的信息。如果左侧的矩阵具有满秩，我们将得到该方程组的唯一解。&lt;/p&gt;

&lt;p&gt;在推导后并置零:&lt;/p&gt;

\[\begin{aligned}
\left(\begin{array}{ll}
G_{u u} &amp;amp; G_{u v} \\
G_{u v} &amp;amp; G_{v v}
\end{array}\right)\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \quad \text { with } G_{u u} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
G_{u v} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t) \partial g(u+i, v+j, t)}{\partial v}\right) \\
G_{v v} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2 \\
G_{u t} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial t}\right) \\
G_{v t} &amp;amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v} \frac{\partial g(u+i, v+j, t)}{\partial t}\right)
\end{aligned}\]

&lt;p&gt;这里提供了Lucas-Kanade方法如何计算光流向量的示例。在左侧，我们看到输入图像，它看起来非常模糊。事实上，模糊性实际上有助于Lucas-Kanade方法找到一些光流向量。在右侧，我们看到了每个像素的计算光流，根据下方提供的彩色轮进行了颜色编码。光流为0的向量将由白色像素表示。彩色轮显示了向量指向的方向，以及它的长度。高饱和度的颜色对应于较长的向量，而较低饱和度的颜色表示较短的向量。U值（红色、绿色或蓝色）确定向量指向的方向。从可视化结果中，我们可以观察到获得了一些光流向量，但并不是对所有点都获得了光流向量。此外，并非所有计算出的光流向量都是合理的，例如左下角的绿色向量。&lt;/p&gt;

&lt;p&gt;总的来说，Lucas-Kanade方法提供了一种通过制定和求解使用运动约束方程和最小化残差平方和的线性方程组来估计光流的方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204331.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204345.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;编码：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和度（saturation）= 向量长度&lt;/li&gt;
  &lt;li&gt;色调（hue）= 方向&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;线性近似的极限&quot;&gt;线性近似的极限&lt;/h3&gt;

&lt;p&gt;在所示的示例中，我们有一个一维灰度值图像，具有较大的移动，导致较长的光流向量。原始的灰度值函数由蓝色曲线表示，而后续图像的灰度值函数则显示为红色。&lt;/p&gt;

&lt;p&gt;为了使用Lucas-Kanade方法计算光流，我们首先确定虚线橙色线所示位置的灰度值函数的斜率。我们计算随时间的灰度值变化（红色垂直箭头），并将切线线移到垂直箭头的顶部，得到移动的橙色线。连接原始位置和移动的橙色线的水平向量表示由Lucas-Kanade计算得到的光流向量。&lt;/p&gt;

&lt;p&gt;然而，在这种情况下，光流向量显著低估了实际光流。为了解决这个问题，我们比较一下如果我们将原始灰度值函数向右移动光流量的话，灰度值函数会是什么样子。我们得到了黑色曲线，它与蓝色曲线或后续图像中的真实灰度值相差很大。&lt;/p&gt;

&lt;p&gt;虽然存在很大差异，我们可以继续使用Lucas-Kanade方法计算光流，但基于黑色灰度值函数而不是原始的蓝色正弦曲线。我们迭代这个过程，计算灰度值差异并移动切线，以获得额外的光流估计。这些估计与先前计算得到的光流向量连接起来。&lt;/p&gt;

&lt;p&gt;通过迭代执行Lucas-Kanade方法，我们可以获得比仅执行一次时更好的光流向量。这种迭代方法类似于使用牛顿法寻找函数零点。&lt;/p&gt;

&lt;p&gt;线性近似不足以进行较大的偏移&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204456.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;– 也可以使用迭代计算（牛顿法）确定光流&lt;/p&gt;

&lt;p&gt;图中展示了迭代的Lucas-Kanade方法的结果，其中光流向量与实际光流相比较之前的尝试更接近。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204518.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204527.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;编码：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和度（saturation）= 向量长度&lt;/li&gt;
  &lt;li&gt;色调（hue）= 方向&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;aperture-problem-光圈问题&quot;&gt;Aperture Problem 光圈问题&lt;/h3&gt;

&lt;p&gt;除了可以使用迭代的Lucas Granada方法解决的问题外，还存在另一个问题，称为光圈问题（aperture problem），它会给Lucas Granada方法带来麻烦。让我们进行一个实验，假设有一个场景，我们只能通过百叶窗中的一个小孔来看到，这意味着整个场景可以被视为相机的镜头，百叶窗则可以被视为相机内部的百叶窗。因此，我们只能看到世界的一个小区域，在我们的实验中，我们感知到的这个小区域有一些白色背景和一些黑色物体，这些物体最初只出现在孔的左边界上。现在这个物体进行了一次移动，我们来看一下。&lt;/p&gt;

&lt;p&gt;最后，物体以某种方式移动了，问题是我们观察到了哪种运动？显然，物体似乎是从左向右移动的，但这是完整的事实吗？我们能够唯一确定这个运动吗？&lt;/p&gt;

&lt;p&gt;为了回答这个问题，让我们看一下百叶窗的背面，看看实际发生了什么。&lt;/p&gt;

&lt;p&gt;在这里，我们可以看到我们实验的初始情况。现在我们开始这个运动，我们可以看到这个运动不仅仅是从左到右，而是沿着对角线方向的运动，因此还涉及到垂直运动，这是我们在示例中无法看到的。这个例子表明，我们可以感知到运动的部分，但无法完全感知到整个运动，在某些情况下。让我们稍微改变一下我们的例子，在这个例子中，我们改变了我们看到的物体的形状，现在我们再次进行运动，我们清楚地看到这是一个沿对角线方向的运动。因此，虽然场景只稍微改变，但完整的运动变得明显起来，那么这两个例子之间的区别是什么？在第一个例子中，我们只能观察到一个灰度值的边缘，而在第二个例子中，我们可以观察到一个灰度值的角落，这就产生了重要的区别。如果我们能观察到一个角落，我们就能确定完整的运动，如果我们只能观察到一个边缘，我们只能观察到运动的部分。&lt;/p&gt;

&lt;p&gt;我们看到什么样的运动？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/03832927-14d5-495f-b065-cff87f9ea7ab.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/0963d66a-dabc-413f-a168-328f524f8e54.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/8ced9aa5-60e4-415e-ae86-fe9f085c179e.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么什么情况下可以解决Lucas-Kanade方法呢？
如果我们观察公式，我们可以看到涉及一个2x2矩阵，其中包含一些偏导数。当矩阵G具有满秩时，我们可以得到线性方程组的唯一解。
如果它的秩只有1，我们可能得到一组解，也就是说我们没有唯一解；
如果这个矩阵的秩为零，那么所有可能的向量或光流向量都满足这个矩阵，这意味着所有向量都能解决这个方程，我们就无法得到Lucas-Kanade的唯一解。
重要的性质是矩阵G具有满秩，因此它是可逆的。
如果满足条件，我们就能得到唯一解。这适用于当这个矩阵的两个特征值都大于零且远大于零时。&lt;/p&gt;

&lt;p&gt;需要强调的是，这种矩阵始终具有两个实特征值，并且它们都是非负的，但重要的是它们不等于零，也不接近零，而是远离零。如果这两个特征值都满足条件，那么矩阵G是可逆的，并且这种反转也对相机图像中的随机影响具有稳定性。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \underbrace{\left(\begin{array}{ll}
G_{u u} &amp;amp; G_{u v} \\
G_{u v} &amp;amp; G_{v v}
\end{array}\right)}_{=: G}\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \\
&amp;amp; G_{u u}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
&amp;amp; G_{u v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial v}\right) \\
&amp;amp; G_{v v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;矩阵 G 是可逆的&lt;/li&gt;
  &lt;li&gt;G 的特征值都近似相等且 &amp;gt; 0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;那么什么情况下会发生这种情况呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;如果我们观察均匀区域，我们会发现矩阵G的元素几乎都等于零，如果它们都等于零，特征值将是0和0，这意味着我们无法得到唯一解，这是一个糟糕的情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另一个糟糕的情况是灰度边缘，无论是水平还是垂直的边缘，在这种情况下，矩阵G有两个特征值，其中一个是零或接近零，另一个与零不同，对于所有灰度边缘（包括对角线边缘等），都是如此。
这也是我们无法得到Lucas-Kanade方法唯一解的情况。然而，正如我们所见，该方法仍然能够揭示关于运动的一些信息，但不是全部信息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在灰度角点的情况下，我们通常会得到两个不为零的特征值，因此这是一个好的情况。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;同样地，如果我们处理孤立点，我们会得到与零不同的特征值，所以这也是一个好的情况。这个思想类似于Stephen Harris角点检测器，并且在位移计算中也可以找到。基本思想仍然是相同的。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211225.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;variational-approach-变分法&quot;&gt;Variational Approach 变分法&lt;/h3&gt;

&lt;p&gt;由于我们面临着获取满秩矩阵G的问题，我们可能会问，我们计算矩阵G时应该考虑多大的环境范围。
我们只应该考虑像素感兴趣的直接邻居，还是应该考虑间接邻居？
我们应该考虑多少像素？我们可以一般性地增加环境的面积，也可以减小它。
那么最好的做法是什么呢？如果我们选择一个非常小的环境，很明显，我们很可能遇到我们刚刚看到的问题，也就是所谓的光圈问题。在这种情况下，矩阵G的秩不满，我们无法得到唯一解，因为环境中没有足够的纹理、结构，这使我们无法观察到完整的运动。&lt;/p&gt;

&lt;p&gt;因此，我们可能会提出这样的问题：为什么不使用较大的环境来计算这个大写字母G呢？
然而，如果我们选择一个非常大的环境，我们可能会遇到其他问题。
当然，环境越大，我们需要进行所有计算的计算时间就越长。
更重要的是，如果我们选择了大的环境，我们可能会将不同物体的运动混淆在一起，因为在大的环境中，很可能我们不只观察到一个单独的物体，而是可能观察到几个不同的物体，它们以不同的方式运动。
因此，我们计算出的是几个物体不同运动方式的混合。&lt;/p&gt;

&lt;p&gt;因此，这两种选择都不是最佳的，我们可能需要在这两个思想之间做出一些平衡。&lt;/p&gt;

&lt;p&gt;这些方法的优点是我们可以获得几乎所有图像像素的光流向量。然而，缺点是需要大量计算来解决这些大规模优化问题，因此无法实时运行，只适用于批量处理记录的图像。这些方法更适合于批量处理记录的图像。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211701.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;霍恩和肖克最初的方法奠定了变分方法的基础。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;变分方法：假设光流在相邻像素中相似。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在变分方法中，基本思想是根据环境的特性进行自适应选择。如果处于均匀区域，可能需要选择较大的环境；如果处于纹理丰富的区域，可能更倾向于选择较小的环境。这是一种基本的思路，如何表达这个思想并使其更加普适呢？&lt;/p&gt;

&lt;p&gt;早在上世纪80年代，Horn和Schunck提出了一套基于变分方法的光流计算方法，后来的一系列方法都是基于这个思路。这些方法的基本思想是，不是单独估计每个点或单个点的光流向量，而是并行估计所有像素点的光流向量，并建立一个大规模的优化问题，将相邻像素的光流向量之间建立关系。通过这种方式，避免了对环境的特定选择，使其更加灵活。&lt;/p&gt;

&lt;p&gt;具体来说，假设我们有一幅灰度图像，包含一组像素点。对于每个像素点，我们可以推导出运动约束方程，该方程建立了像素点的灰度值和光流向量之间的关系。我们假设相邻像素的光流向量是相似的，它们可能是相等的，或者至少在像素之间变化不大。我们通过一个条件来表达这种相似性，即希望相邻像素的光流向量之间的差异接近于零。&lt;/p&gt;

&lt;p&gt;现在，我们有了一组从运动约束方程得出的条件，以及确定相邻光流向量相似性的条件。我们可以基于这些条件建立一个大规模的优化问题，然后使用数值方法来解决这个优化问题，以并行地找到所有像素点的光流向量。这里不详细介绍具体的方法，只是介绍了这个基本思路。&lt;/p&gt;

&lt;p&gt;这些方法的优点是可以为几乎所有像素点计算光流向量，缺点是需要大量计算来解决这些大规模的优化问题，因此无法实时工作，只适用于批量处理记录的图像或视频。&lt;/p&gt;

&lt;p&gt;如果想了解更详细的信息，请参考提供的参考文献，其中介绍了变分方法在光流计算中的基本原理和扩展。当然，Horn和Schunck的方法已经不再是最新技术，现在有许多对这种方法进行了改进并获得更好结果的扩展方法。不过，让我们先看一下Horn和Schunck方法的结果，以了解这些变分方法的工作原理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212309.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，当今已经有很多对这种方法的扩展，比基本的霍恩和肖克方法表现更好。
不过，让我们看一下霍恩和肖克的结果，以了解这些变分方法是如何工作的。
我们从之前使用卢卡斯-卡纳达方法的示例开始，然后应用霍恩和肖克的方法，经过长时间的计算后，我们得到下面的结果。&lt;/p&gt;

&lt;p&gt;我们可以看到，现在光流向量的估计比之前要好得多，尽管仍然存在一些估计错误和箭头状的伪影，但整体估计效果更好。我们还可以看到，平均光流向量的长度比卢卡斯-卡纳达方法更大，并且相邻像素更可能具有相似的光流向量，因为这是变分方法中引入的内容。&lt;/p&gt;

&lt;p&gt;基于变分方法的解决方案：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;变分优化问题，类似于随机场&lt;/li&gt;
  &lt;li&gt;数值迭代计算&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;无法实时运行&lt;/strong&gt;！&lt;/li&gt;
  &lt;li&gt;有关详细信息，请参考提供的参考资料&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212943.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;optical-flow-and-stereo-vision-光流和立体视觉&quot;&gt;Optical Flow and Stereo Vision 光流和立体视觉&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;光流计算 ≈ 立体视觉的对应问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总结一下光流计算，我们已经了解了一些光流计算方法。
在之前的章节中，我们介绍了双目视觉，在双目视觉中，我们也面临着类似的问题，即我们想计算两幅图像中某个点的像素位置之间的关系，因此我们有了对应问题。&lt;/p&gt;

&lt;p&gt;虽然光流计算与双目重建不同，但我们仍然可以认为这两个问题之间存在密切的联系。
在光流问题中，我们比较图像序列中的图像，而在双目视觉中，我们比较立体图像对。
在光流计算中，我们希望获得两个对应点之间的矢量，而在双目视觉中，我们希望计算视差，也可以将其解释为矢量。&lt;/p&gt;

&lt;p&gt;因此，我们确定了一些可能的方法。&lt;/p&gt;

&lt;p&gt;例如，可以使用&lt;em&gt;运动约束方程进行光流计算，但如果需要的话，也可以用于双目重建&lt;/em&gt;。
&lt;strong&gt;变分方法&lt;/strong&gt;主要用于光流计算，但也有非常类似的变分方法用于立体重建。
&lt;strong&gt;极线几何&lt;/strong&gt;是在双目视觉背景下引入的概念，但也可以用于光流计算。
&lt;strong&gt;块匹配&lt;/strong&gt;也是用于双目重建的方法，但也可以用于光流计算。
当然，特征点方法也可用于两个问题，至少可以用于获取稀疏光流或稀疏视差。&lt;/p&gt;

&lt;p&gt;可能的方法（适用于两者）包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;运动约束方程&lt;/li&gt;
  &lt;li&gt;变分方法&lt;/li&gt;
  &lt;li&gt;极线几何&lt;/li&gt;
  &lt;li&gt;块匹配/相关过程&lt;/li&gt;
  &lt;li&gt;特征点方法&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;稀疏流&quot;&gt;稀疏流&lt;/h3&gt;

&lt;p&gt;为了说明特征点方法的有用性，这里有一个标准图像序列的示例。我使用SURF特征点为两幅图像创建了特征点，并连接那些相互匹配的特征点对。结果如下图所示，每条黄线表示一个光流矢量，我们可以看到大多数光流矢量是有意义的。当然，右上角存在一些特征点连接不合理的伪影，导致了一些奇怪的光流，我们并不期望这种情况发生。当然，汽车部分也产生了一些奇怪的光流，这也是我们所预期的。然而，总体结果还是相当不错的。当然，这只是对于光流的稀疏估计，我们并没有获得每个像素的光流，但至少对于那些获得光流的像素，结果还是相当好的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614213941.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;image-based-tracking-基于图像的跟踪&quot;&gt;Image Based Tracking 基于图像的跟踪&lt;/h3&gt;

&lt;p&gt;在许多应用中，不需要计算每个像素的光流矢量，而是只对跟踪物体感兴趣，也就是确定属于某个特定物体的像素的光流。我们希望为整个物体获取一个单一的光流矢量。我们假设我们使用某种物体检测器，在第一帧中提供了一个感兴趣区域（ROI）。基于此，我们希望在整个视频序列中跟踪这个区域。我们假设我们不知道当前检测到的是什么物体，可能是汽车、人或动物等，我们只是想能够在整个视频中跟踪这个物体。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214319.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里有一个例子，仅包含了一系列图像中的四个图像。我们可以看到几个物体。假设在第一幅图像中，物&lt;em&gt;体检测器给出了三个感兴趣区域，用红色、绿色和蓝色矩形表示&lt;/em&gt;。我们的任务是在随后的图像中再次找到这些物体，并确定相应的感兴趣区域。
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214155.png&quot; alt=&quot;&quot; /&gt;
&lt;strong&gt;解决这个问题的基本思路如下&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214514.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从第一幅图像中，我们获取了对感兴趣物体的一些信息，即我们对物体的外观有一些概念。我们可以将这个外观作为该物体的模板，即我们只需将图像中的这个矩形区域作为模板。&lt;/p&gt;

&lt;p&gt;然后在下一幅图像中，我们可以搜索相同的模板出现的位置。我们将该区域在整个图像上进行移动，对于每个位置，我们检查模板是否与图像中所见的内容匹配，并确定相似度的度量。在这种情况下，我们可能发现在这里显示的第一个区域的左侧区域不匹配，因此模板与该区域的内容的相似度非常低，而在右侧的另一个模板中，模板与图像内容的相似度相对较高。我们可以将其视为一种块匹配，再次比较图像的感兴趣区域的灰度值，并尝试找到最佳匹配。一旦我们找到了最佳匹配，我们就知道这个物体在第二幅图像中最有可能再次出现的位置。&lt;/p&gt;

&lt;p&gt;现在，我们可以利用这第二幅图像，因为我们知道同一物体在第二幅图像中的位置，我们可以得到显示相同物体（或至少可能是相同物体）的第二个感兴趣区域。现在，我们可以使用第一幅图像和第二幅图像的两个感兴趣区域，并以最佳方式调整模板，使其适应两者。&lt;/p&gt;

&lt;p&gt;这样就得到了一个适应的模板。有了这个适应的模板，我们可以进入第三幅图像，并根据最佳匹配搜索第三幅图像中最合适的区域。基于这个最佳匹配，我们可以再次调整模板以适应新找到的感兴趣区域的外观。&lt;/p&gt;

&lt;p&gt;通过这样的步骤，我们可以逐步变得越来越好，以确定代表这种物体的良好模板。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于图像的跟踪：超越块匹配 Beyond Block Matching&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因此，创建模板并将其与图像块进行比较的方法既可以视为一种块匹配，也可以以不同的方式处理，并将其解释为分类任务。也就是说，我们想要搜索特定类别的物体，这些分类器通常使用一些示例图像进行训练。&lt;/p&gt;

&lt;p&gt;在我们的情况下，我们从一个正例图像开始，即来自图像序列中的第一幅图像的感兴趣区域，然后我们选择一些其他图像块作为负例。一旦我们在第二幅图像中找到了感兴趣区域，我们可以将第二幅图像中的感兴趣区域视为第二个训练示例，用于训练专门针对相关对象类别的分类器，通过这种方式我们可以不断进行下去。&lt;/p&gt;

&lt;p&gt;因此，我们对模板匹配使用可训练的分类器。参加过机器视觉或相关模式识别讲座的人可能已经对我们可以使用哪些分类器有一些了解，例如人工神经网络、支持向量机、决策树等等。在我们这里，我们将坚持支持向量机的思想，但不使用纯粹的支持向量机，而是经过改进的某种机器。&lt;/p&gt;

&lt;h3 id=&quot;example-kernelized-correlation-filter-kcf-核化相关滤波器-kcf&quot;&gt;Example: Kernelized Correlation Filter (KCF) 核化相关滤波器 (KCF)&lt;/h3&gt;

&lt;p&gt;这导致了一种被称为核化相关滤波器的方法。相关滤波器让我们想起了块匹配方法，而核化则提醒我们支持向量机的思想，因为这些方法的基本思想是将一种块匹配与核化相结合。&lt;/p&gt;

&lt;p&gt;在这种情况下，训练示例的创建如下所示：
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614215729.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设我们在最初的图像中的感兴趣区域显示了这个骑自行车的补丁，然后我们将这个补丁复制并填充整个平面。此外，我们创建了一种类似原始补丁大小的标签图像，这个标签图像的值介于0和1之间。中心点的值为1，在边界处的值为0，两者之间的值从1递减。然后我们创建一组训练示例，第一个示例是从原始图像补丁和相应的标签创建的，标签的值是标签图像中心处的值。然后，我们围绕原始图像补丁转动这个红色矩形，并以相同的方式转动用于确定相应训练示例标签的标签图像中的点。当然，标签不仅仅是0和1，这是纯粹分类任务的预期，而是介于0和1之间的实数。因此，这些标签在某种程度上告诉我们一个正确示例的级别，我们就是这样创建训练示例的。对于你所看到的红色矩形的每个位置，我们创建一个训练示例。之后，我们可能会在灰度图像或彩色图像上计算一些之前计算的特征，并将其应用于这些灰度图或者彩色图。&lt;/p&gt;

&lt;p&gt;之后，我们可能会在灰度图像或彩色图像上计算一些特征，并将其应用于这些训练示例，而不是直接使用颜色或灰度值。之前参加过机器视觉讲座的人会了解到一些特征，例如HOG特征或LBP特征，这些特征也可以用来创建训练示例，而不是直接使用原始图像数据。&lt;/p&gt;

&lt;p&gt;然后，我们应用一个分类器，它类似于支持向量机，但不完全是支持向量机。在我们的情况下，可以使用快速傅里叶变换以高效地进行训练，因此这种训练只需现代计算机上的10到20毫秒，可以实时进行。这样，我们就训练出了一个分类器，现在我们可以在下一幅图像中搜索适当的最佳匹配。在这种的情况下，也可以使用快速傅里叶变换来实现这一点，从而获得非常快速的响应时间。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Example: Tracking with Occlusions 使用遮挡进行跟踪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是的，我们在获取新图像时逐步更新模板。在这里，我们可以看到核化相关滤波方法的一个例子，它通过一种额外的技术扩展以处理遮挡。这是我们团队中Weitian的工作成果。让我们开始视频，我们可以看到这种方法跟踪了一个骑自行车的人，即使自行车被汽车遮挡，它仍然能够跟踪。这里的思路是分析物体的哪些部分仍然可见，然后在这个可见区域上初始化第二个核化相关滤波器，可见区域显示为绿色。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/bb28588d-b509-4bcd-bfd6-94c43a518c5d.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Example: Tracking in Fog 雾中跟踪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们看另一个示例视频，在右下方的图像中，你可以看到初始情况，绿色矩形定义了一开始提供的感兴趣区域，很难确定我们实际上正在跟踪的是什么。如果你看左上方的图像，也显示相同的图片，我们可以看到有些东西，但很难说那是什么，即使我们放大并查看右上方的图像，我们几乎无法确定我们真正看到了什么，只有一些与周围的雾有些不同的深灰色区域。然而，让我们启动这个核化相关滤波器来跟踪物体。&lt;/p&gt;

&lt;p&gt;现在我们可以看到物体的真正是什么，即一辆汽车。然而，从第一幅图像来看，几乎不可能确定这确实是一辆车，因此在第一幅图像中，车辆检测器无法确定这是一辆车，但我们仍然能够跟踪它，这真的很有趣。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/d96751c9-e29a-4f87-baf7-87295e60fa47.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;总结一下光流计算和基于图像的跟踪这一章节。我们开始讨论光流，介绍了光流的基本概念，推导了运动约束方程，并基于此引入了Lucas-Kanade方法。然后，我们更详细地分析了Lucas-Kanade方法，推导了光圈问题，并介绍了变分流计算方法的一些基本思想。&lt;/p&gt;

&lt;p&gt;对于基于图像的跟踪，我们引入了模板匹配的思想和核化相关滤波器作为一种有用且实时可行的方法来实现这种模板匹配思想，用于真实图像序列。&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/04-Optic-Flow-and-Image-Based-Tracking/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/04-Optic-Flow-and-Image-Based-Tracking/</guid>
        
        <category>专业</category>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision - Binocular Vision / Stereo Vision 双目视觉/立体视觉</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-2-binocular-vision--双目视觉&quot;&gt;chapter 2 Binocular Vision &lt;br /&gt; 双目视觉&lt;/h1&gt;

&lt;p&gt;欢迎来到《汽车视觉》第二章，今天我们将讨论双目视觉系统，也称为立体视觉。这是一些提供有关双目视觉系统章节的教科书列表。如果你需要超出本讲座范围的背景信息，请参考这些书籍以获取更多信息。让我们通过介绍对极几何概念来开始我们对双目视觉的讨论。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;R. Hartley, A. Zisserman, Multiple View Geometry in computer vision. Cambridge
University Press, 2006&lt;/li&gt;
  &lt;li&gt;E. R. Davies, Machine Vision. Theory. Algorithms. Practicalities. Elsevier, 2005, ch.
21.6 ff&lt;/li&gt;
  &lt;li&gt;D. A. Forsyth, J. Ponce, Computer Vision. A Modern Approach. Prentice Hall, 2003,
ch. 10&lt;/li&gt;
  &lt;li&gt;R. Szilinsik, Computer Vision: Algorithms and Applications, 2010, ch. 10&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;epipolar-geometry-对极几何&quot;&gt;Epipolar Geometry 对极几何&lt;/h2&gt;

&lt;h3 id=&quot;binocular-vision--stereo-vision-双目视觉立体视觉&quot;&gt;Binocular Vision / Stereo Vision 双目视觉/立体视觉&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615142533.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;双目视觉或立体视觉系统由两个相机组成。每个相机将三维世界映射到二维图像上。当使用两个不同的相机从两个不同的视点观察同一场景时，我们会获得两幅图像。这意味着我们有一个从三维世界到二维（两倍）世界的映射，或者换句话说，从三维到四维世界的映射。这种映射使我们能够确定一个点相对于相机的距离，这是使用单个相机无法实现的。我们将这个距离称为点的深度。此外，我们将双目相机系统中两个相机之间的距离称为立体设置或立体摄像机的基线。&lt;/p&gt;

&lt;p&gt;一旦我们确定了所有点的三维位置，我们就可以创建环境的三维模型。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;场景是用两个摄像头拍摄的&lt;/li&gt;
  &lt;li&gt;$\mathbb{R}^3 \rightarrow \mathbb{R}^2 \times \mathbb{R}^2$&lt;/li&gt;
  &lt;li&gt;3d 重建：确定到物体的距离（深度）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/68d8081b-56f5-4e5f-b9d8-b50989567816.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;让我们从以下的图示开始分析：&lt;/p&gt;

&lt;p&gt;我们有一个以焦点和图像平面为模型的相机。在现实中，相机的图像平面位于焦点后方。然而，为了简化分析，让我们引入一个位于相机前方的虚拟图像平面。由于针孔相机模型仅使用相机的焦点作为投影中心来实现透视映射，我们将在虚拟图像平面上观察到与在真实图像平面上相同的图像。然而，左右和上下是翻转的。此外，我们假设虚拟图像平面与相机之间的距离为1。&lt;/p&gt;

&lt;p&gt;如果我们观察一个三维点P，我们可以通过连接这个点P与相机的焦点来构建一个视线。该视线与图像平面的交点将给出该点的图像点，我们在这个图示中将其表示为ql。&lt;/p&gt;

&lt;p&gt;这里所示的点Fl和图像平面描述了左侧相机。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615143811.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在，让我们引入立体摄像机设置中的右侧相机，它也由其焦点和虚拟右图像平面定义。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615143923.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们添加了第三条连接两个焦点的线，实际上就是基线。我们观察到这个基线也与图像平面在两个点相交，我们将其表示为eL和eR，并将它们称为相机系统的epipolar”。请注意，图像平面本身是一个无限延伸的平面。我们在相机中感知到的图像只是该平面内的一个小区域。因此，即使epipolar”在图像之外，它仍然存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615144259.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;点FL、FR和P构成了一个三角形，这个三角形定义了一个平面，我们称之为极线平面（epipolar plane）。极线平面与虚拟图像平面在一条线上相交，这条线被称为相机设置的极线（epipolar line）。&lt;/p&gt;

&lt;p&gt;在位于两个相机前方的极线平面上的所有点都会被映射到两个相机的图像平面上的极线上。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;现在，我们可以基于这个模型进行计算&lt;/strong&gt;，区分左侧相机和右侧相机的相关坐标系。我们引入大写索引’L’和’R’分别表示左侧和右侧相机的坐标系。在进行计算时，始终小心并检查我们当前所处的坐标系，因为混淆不同的坐标系可能会导致问题。&lt;/p&gt;

&lt;p&gt;让我们首先建立起点P在左侧相机坐标系统中的三维位置描述向量PL与点P在左侧相机图像平面中的图像点位置描述向量ql之间的关系。从图示中，我们可以很容易地看出这两个向量只是彼此的缩放版本，&lt;strong&gt;缩放因子由1/zLL（1除以zLL）给出&lt;/strong&gt;。这是因为&lt;em&gt;虚拟图像平面与焦点之间的深度为1&lt;/em&gt;，而zLL是点P在左侧相机坐标系中的深度。因此，zLL只是向量PLL的第三个分量。&lt;/p&gt;

&lt;p&gt;类似地，我们可以对右侧相机坐标系和向量PR应用相同的推理过程。&lt;/p&gt;

&lt;p&gt;此外，我们观察到点FL、FR和P构成了极线平面，而向量PL、PR和B是极线平面的一部分。这意味着如果我们计算这些向量中任意两个的叉乘，我们将得到一个垂直于该平面的向量。此外，如果我们将这样一个垂直向量与平面上的其中一个向量进行点积运算，结果将为零。我们可以执行这个计算，例如，首先将基线向量B与向量PL进行叉乘，然后计算与向量PR的点积。当然，我们必须确保所有这些计算都在同一个坐标系中进行，特别是左侧相机的坐标系。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;左侧相机坐标系统： $\vec{q}_l^L=\frac{1}{z_l^L} \vec{p}_l^L$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;右侧相机坐标系统： $\vec{q}_r^R=\frac{1}{z_r^R} \vec{p}_r^R$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;假设向量位于一个平面上： $\left(\vec{p}_r^L\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在我们之前的计算中，我们使用了向量PR，但是将其表示为左侧相机的坐标系，这有点不寻常。因此，让我们看看如何将其转换为在右侧相机坐标系中表示的向量。由于两个相机坐标系都是右手坐标系、正交坐标系，并且使用相同的长度单位，我们可以通过将这些点与幻灯片上表示的旋转矩阵（用大写字母D表示）相乘，并通过一定的偏移来将它们从一个坐标系转换到另一个坐标系。在这种情况下，偏移量是基线向量B。现在，对于在左侧相机坐标系中表示的向量PR，它实际上是连接FR和P的向量。这个向量可以被重写为从FR到FL，然后从FL到P的组合。换句话说，它是从FL到P的向量减去从FL到FR的向量。这两个向量表示了左侧相机坐标系中两个点的位置。现在，我们可以使用这个替换，应用上述的坐标变换规则，并将这些向量替换为在右侧相机坐标系中表示的相应向量。&lt;/p&gt;

&lt;p&gt;在此之后，我们观察到项BL出现了两次，一次为正，一次为负，因此该项消失了。此外，我们可以将旋转矩阵D提取出来。括号中剩下的项实际上就是连接FR和P的向量，表示在右侧摄像机坐标系中。这实际上就是PRR。&lt;/p&gt;

&lt;p&gt;结合我们之前的结果，我们可以得出以下结论：
&lt;strong&gt;旋转矩阵D乘以括号中的PRR转置，再乘以BL和PLL的叉乘，必须等于零。&lt;/strong&gt; *(下面式子最后一行)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;坐标变换：$\vec{x}^L=D \vec{x}^R+\vec{b}^L$&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}
&amp;amp; \vec{p}_r^L={\overrightarrow{F_r P}}^L={\overrightarrow{F_l P}}^L-{\overrightarrow{F_l F_r}}^L \\
&amp;amp; =D \cdot{\overrightarrow{F_l}}^R+\vec{b}^L-\left(D \cdot{\overrightarrow{F_l F_r}}^R+\vec{b}^L\right) \\
&amp;amp; =D \cdot\left({\overrightarrow{F_l P}}^R-{\overrightarrow{F_l F_r}}^R\right) \\
&amp;amp; =D \cdot \vec{F}_r R=D \vec{p}_r^R \\
&amp;amp; \left(\vec{p}_r^L\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0 \quad \Rightarrow \quad\left(D \vec{p}_r^R\right)^T \cdot\left(\vec{b}^L \times \vec{p}_l^L\right)=0 \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615144259.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在，我们将这个结果与先前关于矢量ql和pl之间关系的结果相结合。我们已经得出这两个向量是通过一个缩放因子相关联的。现在，我们将这个关系代入以下方程中，将PRR替换为QRR，将PLL替换为QLL。
由于zRR和zLL（点在两个坐标系中的深度）始终是正数，我们可以将整个方程除以这两个深度值。我们得到下面的等式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;结合：&lt;/li&gt;
&lt;/ul&gt;

\[\begin{array}{r}
z_r^R\left(\vec{q}_r^R\right)^T D^T\left(\vec{b}^L \times z_l^L \vec{q}_l^L\right)=0 \\
\left(\vec{q}_r^R\right)^T D^T\left(\vec{b}^L \times \vec{q}_l^L\right)=0
\end{array}\]

&lt;p&gt;最后一步是将叉乘BL叉乘QLL重新写成矩阵-向量乘法的形式。通过一些变换，我们可以将其重写为矩阵为3x3的矩阵乘以一个三维向量，如下所示。让我们将其表示为BL叉乘。你可以在纸上试一下验证这个等式。&lt;/p&gt;

\[\vec{b}^L \times \vec{q}_l^L=\left(\begin{array}{ccc}
0 &amp;amp; -b_z^L &amp;amp; b_y^L \\
b_z^L &amp;amp; 0 &amp;amp; -b_x^L \\
-b_y^L &amp;amp; b_x^L &amp;amp; 0
\end{array}\right) \vec{q}_l^L=\left[\vec{b}^L\right]^L \times \cdot \vec{q}_l^L\]

&lt;p&gt;现在我们可以简化我们感兴趣的方程，最终结果为：QR的转置乘以E乘以QLL等于零，其中E，也被称为本质矩阵  essential matrix，就是转置的旋转矩阵乘以矩阵BL叉乘。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \text { with: } E=D^T\left[\vec{b}^L\right] \\
&amp;amp; \qquad\left(\vec{q}_r^R\right)^T E \vec{q}_l^L=0
\end{aligned}\]

&lt;p&gt;很容易看出，本质矩阵只包含有关相机设置的内部参数的信息，也就是关于两个相机之间的相对位置的信息。&lt;/p&gt;

\[\left(\vec{q}_r^R\right)^T E \vec{q}_l^L=0\]

&lt;p&gt;为什么这个结果如此重要呢？如果我们知道$\vec{q}_l^L$，也就是我们知道了&lt;strong&gt;左相机图像中的某个点&lt;/strong&gt;，那么根据这个方程，我们可以确定右图像中的对极线。
因为右图像上的所有点都必须满足这个方程：$\left(\vec{x}^R\right)$的转置乘以E乘以$\vec{q}_l^L$必须等于零。所以这其实就是右相机图像平面上一条直线的定义。&lt;/p&gt;

\[\left(\vec{x}^R\right)^T E \vec{q}_l^L=0\]

&lt;p&gt;类似地，如果我们知道右相机图像中的一个点，我们可以确定左相机图像中相应的对极线。&lt;/p&gt;

&lt;p&gt;我们还可以确定&lt;strong&gt;立体摄像机系统的对极点&lt;/strong&gt;，因为对极点是所有对极线共有的点。这意味着对于右相机的对极点，我们得到ERR的转置乘以本质矩阵乘以QLL必须对所有可能的QLL值都相等。类似地，我们也可以得到左相机对极点的结果。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \left(\vec{e}_r^R\right)^T E \vec{q}_l^L=0 \text { for all } \vec{q}_l^L \\
&amp;amp; \left(\vec{q}_r^R\right)^T E \vec{e}_l^L=0 \text { for all } \vec{q}_r^R
\end{aligned}\]

&lt;p&gt;因此，如果我们想从立体摄像机系统中重建三维点，我们可以利用这一点。假设我们已经获得了立体摄像机系统的左图像和右图像，并且我们在左图像中找到了一个有趣的点QL。问题是，对应的右图像中的点在哪里？它可能在任何地方。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615152840.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而，如果我们知道了点QL对应的对极线，我们就可以限制搜索范围，因为我们知道对应的点只能位于对极线上。这意味着知道对极线可以帮助我们将搜索空间限制在一维结构上，即一条一维线上。如果我们知道一对对极线，我们还可以确定对极平面。&lt;/p&gt;

&lt;h2 id=&quot;fundamental-matrix&quot;&gt;Fundamental Matrix&lt;/h2&gt;

&lt;p&gt;在许多情况下，使用本质矩阵并不方便，因为如果我们想要使用图像坐标进行操作，通常希望使用图像坐标系统中的u和v坐标，而不是相机坐标系统中的坐标。为此，我们可以引入另一个矩阵，称为基础矩阵F，它实际上与本质矩阵相同，但使用图像坐标系统中的坐标。它可以通过将本质矩阵从左侧和右侧乘以两个相机的内部参数矩阵来导出，如方程中所示。&lt;/p&gt;

&lt;p&gt;现在，我们之前针对本质矩阵导出的方程同样适用于基础矩阵。对于一对对应的图像坐标UL、VL和UR、VR，我们得到UR、VR、1乘以基础矩阵乘以UL、VL、1必须等于零。&lt;/p&gt;

&lt;p&gt;基础矩阵可以从已标定的相机配置中导出，因为我们&lt;em&gt;知道内部相机参数和外部参数&lt;/em&gt;，可以从中导出本质矩阵和基础矩阵。即使我们不知道这些内部和外部参数，如果我们有一定数量的左右相机图像上的对应点，仍然可以导出基础矩阵。如果我&lt;strong&gt;们至少知道八个点，我们可以使用所谓的八点算法估计基础矩阵F，但无法确定一个未知的比例因子&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在有基本矩阵 F 的情况下，首选图像坐标：
    &lt;ul&gt;
      &lt;li&gt;具有内在相机参数的矩阵 Al, Ar&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[F=A_r^{-T} E A_l^{-1}\]

&lt;ul&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;在一对对应的图像坐标的情况下：&lt;/li&gt;
&lt;/ul&gt;

\[\left(u_r, v_r, 1\right) F\left(\begin{array}{c}
u_l \\
v_l \\
1
\end{array}\right)=0\]

&lt;ul&gt;
  &lt;li&gt;基本矩阵的形状可以通过一组≥8个对应的图像点（8点算法）直到一个未知的比例因子来计算。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;例子&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;让我们来看一些例子。这里，我们看到两个图像显示的是同一个场景，但&lt;strong&gt;在左图中，视角稍微向左&lt;/strong&gt;，而&lt;strong&gt;在右图中，视角稍微向右&lt;/strong&gt;。我们看到一些蓝色的线，它们是极线，以及一些用小绿点标记的点集。在这些情况下，极线大致是水平的，并且极点远离图像之外。&lt;/p&gt;

&lt;p&gt;– horizontal panning motion 水平平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615153747.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这张图片展示了类似的情况，但现在视角位置重叠。极线是垂直的。&lt;/p&gt;

&lt;p&gt;– vertical panning motion 垂直平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615153935.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;– horizontal and vertical panning motion  水平和垂直平移运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615154100.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是一个情况，其中两个摄像机的视角在水平和垂直方向上发生了移动，因此极线有些倾斜，至少部分倾斜。最后，让我们来看一下摄像机不是向左、向右、向上或向下移动，而是向前或向后移动，离场景越来越近或越来越远的情况。在这种设置中，四个极点都位于图像内部，正如我们在所有极线的交点处所看到的，这些交点就是立体设置的极点。
– motion parallel to optical axis 平行于光轴的运动
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615154216.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;此外，还有一个非常特殊的极线几何情况，即具有相同图像平面、相同内部参数的相机，且相机完全平行且方向相同。这种情况如图所示，两个摄像机只是平行于摄像机坐标系的x轴向左或向右移动。在这种情况下，极线是平行的且完全水平的。我们需要在另一个图像的同一行上搜索对应的点。极点位于无限远处。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615155041.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这样的设置中，我们称之为矫正相机设置，计算特定点的深度相对容易。首先，我们需要确定该点的视差，即图像坐标中对应点的 u 坐标之差。因此，视差（表示为 Ddisparity）等于 UL 减去 UR。这总是一个非负数。基于视差，我们可以轻松计算出点 P 的三维位置。它由基线（两个焦点之间的距离）乘以 alpha prime（相机设置的有效焦距）除以视差，再乘以向量 [XL, YL, 1] 给出。该向量表示左侧相机的焦点和相机坐标系中的图像点的位置。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;视差（以像素为单位）：$d=u_l-u_r$&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

\[P^L=\frac{b}{x_l^L-x_r^R}\left(\begin{array}{c}
x_l^L \\
y_l^L \\
1
\end{array}\right)=\frac{b \alpha^{\prime}}{u_l-u_r}\left(\begin{array}{c}
x_l^L \\
y_l^L \\
1
\end{array}\right)\]

&lt;p&gt;&lt;strong&gt;Derivation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230615155538.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disparity 视差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们可以看到校正或矫正立体设置的视觉效果。在顶部，您可以看到立体摄像机的左图像和右图像，在底部，您可以看到两个图像一个接一个地显示。我们可以观察到，当图像发生变化时，所有的点都向左和向右移动，然而它们不上下移动。我们还可以进一步观察到，远离我们的点，例如背景中的房屋，移动得不多，即视差较小，而前景中的点，例如行人，移动得很多，这些点的视差很大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150252.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rectification 矫正&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实际上，几乎不可能构建一个完全矫正的相机系统，因为我们在安装相机时所需的精度在机械上很难实现。那么，如果我们无法构建矫正相机，我们如何使用矫正相机呢？答案很简单，我们可以从实际的立体设置中创建虚拟矫正相机。这个原理在下面的图片中展示。我们从原始相机设置的图像开始。这个设置并不差，所以相机的对准尽可能好，但不完美。然后，我们进行一些转换，称为图像的矫正，然后稍微修改图像，使其完全矫正。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150522.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;它是如何实现的？起点是我们有立体设置的两个相机，具有不同的相机参数Al和AR，以及不同的坐标系。我们的目标是定义两个新的虚拟相机，一个左虚拟相机和一个右虚拟相机，两者应该具有相同的焦距，以及相同的内部参数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616150731.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;两个虚拟摄像机的对齐方式应该是完全一致的，这意味着它们的相机坐标系应该完全对齐。它们的相机坐标系的x轴应该与连接两个焦点的基线平行，并且焦点应该与原始摄像机的焦点相同。也就是说，左侧虚拟摄像机的焦点应与真实左侧摄像机的焦点相同，虚拟右侧摄像机的焦点应与真实右侧摄像机的焦点相同。&lt;/p&gt;

&lt;p&gt;我们可以将这个过程可视化如下：我们从一个真实相机开始，你可以看到相机坐标系彼此不对齐。然后我们将它们旋转，使它们的x坐标与基线平行，而它们的y和z坐标也互相平行。然后我们忘记原始坐标系，只使用这个虚拟双目相机设置。我们如何计算这个呢？&lt;/p&gt;

&lt;p&gt;首先，我们需要根据相机参数定义一个共同的内部矩阵a’，这个矩阵类似于原始内部相机矩阵Al和Ar。&lt;/p&gt;

&lt;p&gt;其次，我们要找到一个共同的相机坐标系，使得x轴平行于基线。在定义这个坐标系时，我们有一定的自由度，因为我们可以始终围绕x轴旋转，并得到不同可能的矫正相机坐标系的选择。
实际上，我们在实践中使用尽可能与原始两个相机坐标系相似的坐标系。一旦我们定义了这些新的坐标系，我们确定所需的旋转矩阵，用于将原始坐标转换为新的坐标。
然后，我们将原始相机图像转换为虚拟相机的图像，也就是创建了新的虚拟矫正相机图像。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这可以按照以下方式完成&lt;/strong&gt;：从透视投影中，我们知道如果我们知道点p在原始相机设置和左相机的坐标系中的3D点位置，通过将Al与p相乘，我们得到图像坐标。左侧的结果是深度pz乘以该点的图像坐标。我们可以对新的虚拟左相机系统进行类似的计算。对于新的虚拟相机坐标系，我们有P’×a’ = pz’×u’×b’，其中带有撇号的变量是与新的虚拟相机坐标系相关的变量，这个新坐标系中的点的深度和坐标都可能发生变化。&lt;/p&gt;

&lt;p&gt;知道两个坐标系之间有一个已知的变换，仅由一个旋转矩阵定义，我们可以将点P’转换为DL乘以p。&lt;/p&gt;

&lt;p&gt;现在我们可以合并这两个方程，并通过从上面的方程推导出的相应方程替换点P，最终我们得到了你在这里看到的术语。通过将整个方程除以Pz，我们得到一个简化的项目P’ / Pz，这只是一个缩放因子，我们可以通过这个方程的第三行确定缩放因子。一旦我们知道了缩放因子，我们就可以确定U’和V’。如果我们想根据实际图像中的位置确定虚拟图像中的点的位置，这意味着我们可以创建一个描述实际图像中的点如何映射到虚拟矫正图像中的点的映射。我们可以对左右两个虚拟相机都这样做，并最终得到结果。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; p_z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=A_l \cdot \vec{p} \\
&amp;amp; p_z^{\prime} \cdot\left(\begin{array}{l}
u^{\prime} \\
v^{\prime} \\
1
\end{array}\right)=A^{\prime} \cdot \vec{p}^{\prime}=A^{\prime} \cdot D_l \cdot \vec{p}=A^{\prime} \cdot D_l \cdot A_l^{-1} \cdot p_z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right) \\
&amp;amp; \frac{p_z^{\prime}}{p_z}\left(\begin{array}{l}
u^{\prime} \\
v^{\prime} \\
1
\end{array}\right)=A^{\prime} D_l A_l^{-1} \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)
\end{aligned}\]

&lt;p&gt;最后，让我们分析从我们可以确定该点的视差的准确性来看，深度计算的灵敏度如何。&lt;/p&gt;

&lt;p&gt;我们已经推导出深度Pz取决于视差D的公式，其中包括项基线B乘以有效焦距Alpha Prime除以视差D。如果我们假设我们只能确定视差到某个位置，那么我们假设在计算这个视差时会产生一定的误差Epsilon。让我们考虑一下这个误差和视差计算对计算深度的影响有多大。为此，我们使用泰勒展开。对于视差D + Epsilon，我们可以近似为视差D - Epsilon的点的深度，其中深度对视差的一阶导数为B乘以Alpha Prime除以D的平方。这可以表示为D-Epsilon / B乘以Alpha Prime乘以Z平方的术语，这意味着在深度估计中获得的误差与点的距离的平方成正比。也就是说，点离得越远，我们在深度估计中得到的误差就越大。&lt;/p&gt;

&lt;p&gt;该图显示了这种误差增长的典型示例。现在我们清楚地看到在水平轴上是点的真实距离，而在垂直轴上是如果我们对视差进行了半个像素的小猜测或小测量所得到的误差。我们很容易看到误差的正确二次增长。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616152729.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;correspondence-problem-对应问题&quot;&gt;Correspondence Problem 对应问题&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616152832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在让我们来讨论对应问题。到目前为止，我们假设我们知道左图像中的哪些点和右图像中的哪些点表示三维世界中的同一点，但实际上这是未知的，我们需要计算它。我们来看一对经过矫正的立体图像。&lt;/p&gt;

&lt;p&gt;在左图像中，一个点用橙色圆圈标出，它是建筑物的左上角。对于这个点，找到右图像中的对应点相对容易，因为这个点非常显著，我们可以比较容易地确定它。&lt;/p&gt;

&lt;p&gt;对于第二个点，它位于一个窗户的垂直边缘上，情况稍微复杂一些。在右图像中，我们可以找到同样的垂直边缘，但是如果没有任何额外的信息，我们不会确切地知道这个边缘上的哪个点是对应点。幸运的是，在这种情况下，我们知道我们正在处理的是矫正的相机图像，这意味着我们知道我们必须在同一行中搜索，因为这是对应的极线。如果我们利用这个额外的知识，我们可以轻松找到对应点。&lt;/p&gt;

&lt;p&gt;在第三种情况下，我们处理的是轨道上的一个点。同样，我们可以使用相同的技巧并利用极线，但不幸的是，在这条极线上有两个非常相似的点，两个轨道上的点都有可能是对应点。如果我们分析整个图像并理解整个图像，我们将能够轻松区分左侧的轨道和右侧的轨道。但如果我们只看局部区域并比较右图像中的哪个区域与左图像中的哪个区域相似，可能会遇到问题，因为在这种情况下，错误的对应点看起来比正确的对应点更相似。&lt;/p&gt;

&lt;p&gt;最后，最糟糕的情况发生在雪地中的这个点。我们知道我们必须在极线上搜索，但不幸的是，图像中没有足够的结构来确定对应点的位置，我们只能说它必定在这个区域，但无法确定确切位置。&lt;/p&gt;

&lt;p&gt;为了确定对应点，我们可以利用几个特性，特别是在矫正的图像中。如果图像是由相同类型的相机拍摄，并且曝光时间选择相同，那么点的灰度值应该是相同的。它们应该具有相同的局部环境，看起来非常相似。它们必须位于同一对极线上。这些点的邻域也应该大部分时间保持不变，这意味着如果我们在左图像中有两个点，一个在另一个点的左边，那么相应的右图像中的点的顺序也应该如此。正如我所说，有一些例外情况，不满足这些条件，但这些例外情况相当罕见。最后，在左图像中，U坐标大于右图像中的U坐标，因此视差始终是非负的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对应的点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;具有相同的灰度值&lt;/li&gt;
  &lt;li&gt;具有相同的局部环境&lt;/li&gt;
  &lt;li&gt;位于同一对极线上&lt;/li&gt;
  &lt;li&gt;邻域被保留（大部分情况下）&lt;/li&gt;
  &lt;li&gt;在左图像中的u坐标大于在右图像中的u坐标（矫正后的图像）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;block-matching-块匹配&quot;&gt;Block Matching 块匹配&lt;/h3&gt;

&lt;p&gt;我们如何确定对应点呢？方法是比较两个点的局部环境，这就得到了一种称为块匹配的方法，因为我们比较的是灰度值的块。在这种情况下，我选择了左图像中的一个图像块，如顶部所示，并提供了三个可能的右图像中的候选点，它们可能是对应点。&lt;/p&gt;

&lt;p&gt;现在我们可以比较这些图像块，看灰度值结构的相似程度，例如通过一个灰度值差异度量，我们可以得到左&lt;strong&gt;边的图像块的差异为74.9，中间的图像块的差异为43.8，右边的图像块的差异为3.2&lt;/strong&gt;。在这种情况下，&lt;strong&gt;我们只是计算了逐像素的绝对灰度值差异，然后取平均值&lt;/strong&gt;。当然，我们还&lt;em&gt;可以选择其他灰度值差异度量的方法&lt;/em&gt;，例如如果我们喜欢，我们可以选择平方差异而不是计算绝对差异。在这种情况下，我们将得到这些值。最后，我们会选择最相似的图像块，也就是具有最小差异的图像块，并将其选为最有可能的对应点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616153711.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;数学上，我们会检查以左图像中感兴趣像素 UL、VL 为中心的一定区域，并分析通过该区域中的所有像素的灰度值结构，使用两个运行索引 i 和 j。&lt;/p&gt;

&lt;p&gt;对于右图像中的潜在对应点，我们也会考虑相同区域内的所有像素，并逐像素比较灰度值，取绝对差异并对所有像素求和。如果需要，我们可以通过将结果除以该区域中的像素数量来取平均值。这将得到灰度值绝对差异的总和。对于平方差异，计算方式非常类似，只是在差异的计算中取差值的平方。另一个选项是使用相关性，如此处所示。该相关性是从统计学上确定的，具有一些不同的特性。前两种度量方式，如果图像非常相似，它们会很小；相关性在两个图像相似时很大；它们在两个图像完全相同时达到最大值 1；而当它们非常不相似时，相关性为 -1。&lt;/p&gt;

&lt;p&gt;相关性具有一些优势，因为它对消除具有不变性。如果两个图像块通常稍微亮或暗一些，相关性对这些变化不敏感，例如由于相机的曝光时间不同。然而，灰度值绝对差异和平方差异是不具有这种不变性的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;左图中像素 (ul,vl) 周围的局部环境：&lt;/li&gt;
&lt;/ul&gt;

\[g_l\left(u_l+i, v_l+j\right), \quad-n \leq i, j \leq n\]

&lt;ul&gt;
  &lt;li&gt;左右分割段的区别：
    &lt;ul&gt;
      &lt;li&gt;对灰度值绝对差求和：&lt;br /&gt;
\(\sum_{i=-n}^n \sum_{j=-n}^n\left|g_l\left(u_l+i, v_l+j\right)-g_r\left(u_r+i, v_r+j\right)\right|\)&lt;br /&gt;&lt;/li&gt;
      &lt;li&gt;对灰度值平方误差求和：&lt;br /&gt;
\(\sum_{i=-n}^n \sum_{j=-n}^n\left(g_l\left(u_l+i, v_l+j\right)-g_r\left(u_r+i, v_r+j\right)\right)^2\)&lt;br /&gt;&lt;/li&gt;
      &lt;li&gt;相关性:&lt;br /&gt;
\(\frac{\frac{1}{(2 n+1)^2} \sum_{i=-n}^n \sum_{j=-n}^n\left(g_l\left(u_l+i, v_l+j\right)-\bar{g}_l\right) \cdot\left(g_r\left(u_r+i, v_r+j\right)-\bar{g}_r\right)}{\sqrt{V\left(g_l\right) V\left(g_r\right)}}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;让我们以一个例子来说明。
上方是我在左图像中选择的图像块，下方是右图像。
我们可以将此图像块与右图像中的所有可能像素进行比较，不考虑首先考虑极线几何关系。然后，对于每个像素，我们得到一个特定的误差项，如此处所示。颜色表示了右图像中相应像素周围区域的差异程度，&lt;strong&gt;蓝色表示差异小，非常相似&lt;/strong&gt;，&lt;strong&gt;红色表示差异大，非常不同&lt;/strong&gt;。&lt;em&gt;如果我们寻找最小值，我们实际上会找到一个位置，如右图像中用红色矩形标示的位置，这是实际的对应点。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616154845.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在实际应用中，我们对图像的所有像素进行这个过程，并当然使用了极线来限制搜索范围，只搜索相应的极线，以避免过多的计算。&lt;/p&gt;

&lt;p&gt;我们这样做会得到视差图像，你可以在右侧看到示例。这个视差图像显示了每个像素的视差值，视差值使用颜色编码，&lt;strong&gt;绿色表示小的视差，红色表示大的视差，对于黑色区域，我们无法确定视差&lt;/strong&gt;，因为点周围的环境结构不足，没有足够的纹理来确定对应点，正如我们在这里看到的，尤其是在非常均匀的雪地区域，无法确定对应点。但对于铁轨、架空线缆、背景建筑或铁路车辆等场景，我们可以确定对应点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616155152.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里是另一个例子，展示了一位前博士生安德烈亚斯·盖格（Andreas Geiger）开发的块匹配方法，他添加了一些额外的技术来得到一些密集的视差图，如你在这里所见。可能有趣的是，在第二列的视差图中有一些黑色区域，看起来像是物体的阴影。例如，对于行人的背后，我们看到一个黑色的区域，无法计算出视差。在这种情况下，该区域的结构足够丰富以计算视差，但行人本身遮挡了其后面的一些区域。这些遮挡区域在左右相机中是不同的，因此对于在一个相机中被遮挡而在另一个相机中没有遮挡的点，我们显然无法计算出视差值，因此在这些区域中，我们得到这些视差阴影。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230616155406.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关于块匹配的一些说明&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;它是一种具有许多&lt;strong&gt;优点&lt;/strong&gt;的方法，非常通用，可以用于很多应用，双目重建是其中一个可能的应用，但不是唯一的应用。光流计算，我们在第四章中讨论过的内容，是另一个应用。我们可以利用极线几何来限制搜索范围，但如果我们无法访问极线几何，我们也可以在整个图像上执行块匹配。&lt;/p&gt;

&lt;p&gt;在使用块匹配时，存在一些&lt;strong&gt;不足&lt;/strong&gt;之处。完整的搜索可能需要大量计算资源，尤其是对于大图像而言，因为它涉及对大量图像块进行比较。此外，只有当图像块中的灰度结构足够丰富时，才能明确地确定对应点。如果图像块的结构较差，存在找不到准确对应点的风险。&lt;/p&gt;

&lt;p&gt;另一个考虑因素是我们在块匹配中比较的区域大小。如果区域太小，图像块中的灰度结构将较差，增加了错误匹配的风险。然而，如果区域太大，计算时间会增加，并且区域可能包含属于不同对象且具有不同深度的像素，这会增加错误结果的可能性。&lt;/p&gt;

&lt;p&gt;在实践中，&lt;strong&gt;块匹配通常应用于预先校准的图像上&lt;/strong&gt;，这样它们就不会受到整体照明条件的影响。为了避免由于左右图像的亮度差异（由于曝光时间不同或其他原因）而导致块匹配失败，许多研究人员&lt;strong&gt;首先对图像进行Sobel或Laplace运算，以获得一阶或二阶滤波图像，然后在梯度图像上应用块匹配。通过使用导数计算（如梯度），消除了整体亮度水平的影响，使整个过程对消除不变。&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/02-BinocularVision/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/02-BinocularVision/</guid>
        
        <category>专业</category>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第二部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习&quot;&gt;深度学习&lt;/h1&gt;

&lt;h2 id=&quot;语义分割和目标检测-semantic-segmentation-and-object-detection&quot;&gt;语义分割和目标检测 (Semantic Segmentation and Object Detection)&lt;/h2&gt;

&lt;h3 id=&quot;场景标注-scene-labeling&quot;&gt;场景标注 Scene Labeling&lt;/h3&gt;

&lt;p&gt;分割图像&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类每个像素&lt;/li&gt;
  &lt;li&gt;自动编码器/解码器结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111358.png&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;h3 id=&quot;实例标签-instance-labeling&quot;&gt;实例标签 Instance Labeling&lt;/h3&gt;

&lt;p&gt;语义标签不提供对象边界！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111731.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;想法：将方向标记为对象中心&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112000.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;C:\Users\Wenbo Li\AppData\Roaming\Typora\typora-user-images\image-20220310112145711.png&quot; alt=&quot;image-20220310112145711&quot; /&gt;&lt;/p&gt;

&lt;center&gt;video provided by Nick Schneider, Daimler AG  &lt;/center&gt;

&lt;h3 id=&quot;区域生成网络region-proposal-networks&quot;&gt;区域生成网络Region Proposal Networks&lt;/h3&gt;

&lt;p&gt;Region Proposal Network，直接翻译是“&lt;strong&gt;区域生成网络&lt;/strong&gt;”，通俗讲是“筛选出可能会有目标的框”。其本质是基于滑窗的无类别object检测器，输入是任意尺度的图像，输出是一系列矩形候选区域。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112344.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112421.png&quot; style=&quot;zoom: 68%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112445.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们在哪里可以找到哪些对象？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将图像划分为单元&lt;/li&gt;
  &lt;li&gt;在每个单元中应用区域生成网络&lt;/li&gt;
  &lt;li&gt;改变划分的单元大小以处理更大/更小的对象&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;深度学习技术&quot;&gt;深度学习技术&lt;/h3&gt;

&lt;p&gt;没有比更多数据更重要的数据了！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的严格验证&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的正则化&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;– 提前停止&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 权重衰减/L2 正则化&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– dropout&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 随机梯度下降&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 多任务学习&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 使用预训练网络&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 损失函数&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重用 （他人的）实践知识&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的网络结构&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的培训过程&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;训练期间的典型错误进展&quot;&gt;训练期间的典型错误进展&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113429.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么早期停止作为正则化技术起作用？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提前停止更倾向小权重&lt;/li&gt;
  &lt;li&gt;小权重意味着几乎没有非线性&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;小权重正则化&quot;&gt;小权重正则化&lt;/h4&gt;

&lt;p&gt;假设感知器的绝对权重较小&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113609.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113743.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;小权重促进感知器的线性行为&lt;/p&gt;

&lt;p&gt;假设具有线性激活的全连接网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113904.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→感知器的线性行为降低了非线性表达性&lt;/p&gt;

&lt;p&gt;→正则化&lt;/p&gt;

&lt;h3 id=&quot;权重衰减l2-正则化-weight-decay--l2-regularisation&quot;&gt;权重衰减/L2-正则化 Weight Decay / L2-Regularisation&lt;/h3&gt;

&lt;p&gt;通过正则化规则扩大训练目标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过在训练期间随机关闭感知器进行正则化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114520.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dropout 迫使神经网络以分布式方式存储相关信息&lt;/p&gt;

&lt;p&gt;dropout 减少过拟合&lt;/p&gt;

&lt;h3 id=&quot;梯度下降的修正&quot;&gt;梯度下降的修正&lt;/h3&gt;

&lt;h4 id=&quot;随机梯度下降&quot;&gt;&lt;strong&gt;随机梯度下降&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114745.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;加速&lt;/li&gt;
  &lt;li&gt;减少一点过拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;动量梯度下降&quot;&gt;&lt;strong&gt;动量梯度下降&lt;/strong&gt;&lt;/h4&gt;

\[\begin{aligned}
\Delta \vec{w} &amp;amp; \leftarrow \alpha \cdot \Delta \vec{w}-\varepsilon \cdot \frac{\partial}{\partial \vec{w}} \sum_{j \in S} \operatorname{err}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right), \vec{t}^{(j)}\right) \\
\vec{w} \leftarrow \vec{w}+\Delta \vec{w}
\end{aligned}\]

&lt;p&gt;用一个α&amp;gt;0参数来控制后续步骤的一致性&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在平坦区域加速&lt;/li&gt;
  &lt;li&gt;减少曲折&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;多任务学习-multi-task-learning&quot;&gt;多任务学习 Multi Task Learning&lt;/h3&gt;

&lt;p&gt;想法：在单个网络示例中学习多个相关任务：&lt;/p&gt;

&lt;p&gt;场景标记+实例标记+深度估计&lt;/p&gt;

&lt;p&gt;scene labeling + instance labeling + depth estimation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115128.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;强制网络在隐藏层中开发共同特征&lt;/li&gt;
  &lt;li&gt;减少对单个任务的过度拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;预训练特征网络的使用&quot;&gt;&lt;strong&gt;预训练特征网络的使用&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;想法：重用预训练的网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115236.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用大型训练集训练其他任务&lt;/li&gt;
  &lt;li&gt;丢弃其他任务的分类层&lt;/li&gt;
  &lt;li&gt;为新任务创建新的分类层&lt;/li&gt;
  &lt;li&gt;训练新分类层的权重，同时保留特征层&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;输出层和损失函数-output-layers-and-loss-functions&quot;&gt;输出层和损失函数 Output Layers and Loss Functions&lt;/h3&gt;

&lt;p&gt;损失函数将网络输出与期望的输出进行比较&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115431.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（回归任务）：期望的输出应该是实数&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用线性激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用平方误差，即&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[\operatorname{err}(\vec{y}, \vec{t})=\|\vec{y}-\vec{t}\|^{2}\]

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（分类任务）：期望的输出应该是类别标签&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用softmax激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用交叉熵误差 cross entropy error&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115748.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;不平衡训练集的变体&quot;&gt;不平衡训练集的变体&lt;/h3&gt;

&lt;p&gt;对于严重不平衡的训练集（即每个类的示例数量不相等），训练可能会失败&lt;/p&gt;

&lt;p&gt;引入加权因子来补偿不平衡&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120231.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;来自深度学习工具箱的其他技术&quot;&gt;来自深度学习工具箱的其他技术&lt;/h2&gt;

&lt;h3 id=&quot;生成对抗网络-gan-generative-adversarial-networks-gan&quot;&gt;生成对抗网络 (GAN) Generative Adversarial Networks (GAN)&lt;/h3&gt;

&lt;p&gt;我们可以使用深度网络生成逼真的图像吗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120527.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120601.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;生成网络应该学会生成逼真的图像&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;鉴别性网络应该学习如何区分图像是真实的还是生成的。&lt;/li&gt;
  &lt;li&gt;训练：两个网络都是零和游戏中的竞争对手&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;应用领域： • 图像渲染 • 域适应 • 为分类器生成（附加）训练数据&lt;/p&gt;

&lt;h3 id=&quot;序列处理sequence-processing&quot;&gt;序列处理Sequence Processing&lt;/h3&gt;

&lt;p&gt;我们如何处理序列，例如 视频序列？&lt;/p&gt;

&lt;p&gt;(1) 多通道输入层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120707.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有在以下情况下才有可能&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2)图像单独处理+拼接层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(3) 图像的单独处理+附加层（深度集）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120924.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;图像的顺序并不重要&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(4)递归网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121006.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121023.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;学习算法：通过时间进行反向传播&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;问题：梯度消失&lt;/li&gt;
  &lt;li&gt;解决方案：用适当的处理单元（GRU、LSTM）取代网络C中的感知器。
适当的处理单元(GRU, LSTM)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;循环单元-grulstm-recurrent-units-grulstm&quot;&gt;循环单元 (GRU+LSTM) Recurrent Units (GRU+LSTM)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;实现简单状态机的专用单元&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;状态从不通过双曲切线的逻辑函数→来传递
没有消失的梯度&lt;/li&gt;
  &lt;li&gt;内部结构有几个控制信息流的闸门&lt;/li&gt;
  &lt;li&gt;使用感知器机制打开/关闭闸门&lt;/li&gt;
  &lt;li&gt;LSTM：更早（1997年），更复杂（需要5个感知器）。&lt;/li&gt;
  &lt;li&gt;GRU：较新（2014年），门数较少，参数较少（需要3个感知器）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;门控循环单元-gru&quot;&gt;门控循环单元 (GRU)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121136.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;长短期记忆单元-lstm&quot;&gt;长短期记忆单元 (LSTM)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121153.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第一部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习-deep-learning&quot;&gt;深度学习 Deep Learning&lt;/h1&gt;

&lt;h2 id=&quot;多层感知器multi-layer-perceptrons--mlp&quot;&gt;多层感知器Multi-Layer Perceptrons  （MLP）&lt;/h2&gt;

&lt;p&gt;MLP 是高度参数化的非线性函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094040.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;示例：图像分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$\vec{x}$   特征向量，例如 图像中所有灰度值的向量&lt;/p&gt;

&lt;p&gt;$\vec{y}$  1-of-q-vector 为 q 个可能类别中的每一个建模概率，例如 笑脸是快乐/悲伤/沮丧&lt;/p&gt;

&lt;p&gt;感知器, 感知机&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094519.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094543.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;许多感知器的分层排列：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094857.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;网络结构创建了一组高度非线性的函数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;许多权重&lt;/li&gt;
  &lt;li&gt;深层架构：通常 &amp;gt;5 个隐藏层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们如何确定 MLP 的权重？&lt;/p&gt;

&lt;p&gt;– 基本思想：最小化训练样例的误差&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095152.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解决&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p} \operatorname{err}\left(f_{M L P} ^ {\vec{w} }\left(\vec{x}^ {(j)}\right), \vec{t}^ {(j)}\right)\]

&lt;p&gt;用于适当的误差测量（损失函数）&lt;/p&gt;

&lt;p&gt;for appropriate error measure (loss function)&lt;/p&gt;

&lt;p&gt;算法：梯度下降（反向传播）&lt;/p&gt;

&lt;h2 id=&quot;梯度下降反向传播gradient-descent-backpropagation&quot;&gt;梯度下降（反向传播）Gradient Descent (Backpropagation)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;

\[\underset{\vec{w}} {\operatorname{minimize}} g(\vec{w}) \text { with } g(\vec{w}):=\sum_{j=1}^{p} \operatorname{err}\left(f_{M L P}^{\vec{w} }\left(\vec{x}^{(j)}\right), \bar{t}^{(j)}\right)\]

&lt;p&gt;&lt;strong&gt;算法&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用小数字随机初始化权重 $\vec{w}$&lt;/li&gt;
  &lt;li&gt;计算梯度 $\frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;以小的学习率$\varepsilon&amp;gt;0$更新权重 $\varepsilon&amp;gt;0\vec{w} \leftarrow \vec{w}-\varepsilon \frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;转到 第2步 直到达到停止标准&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095811.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;改进： – 稍后讨论&lt;/p&gt;

&lt;h2 id=&quot;训练-mlp传统方法training-mlps-traditional-methods&quot;&gt;训练 MLP（传统方法）Training MLPs (traditional methods)&lt;/h2&gt;

&lt;p&gt;传统训练方法的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重太多，训练样例太少&lt;/li&gt;
  &lt;li&gt;太慢&lt;/li&gt;
  &lt;li&gt;数值问题，局部最小值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;👉过拟合、欠拟合、泛化不足&lt;/p&gt;

&lt;p&gt;克服问题的传统技术：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;正则化（例如提前停止、权重衰减、贝叶斯学习）&lt;/li&gt;
  &lt;li&gt;模式预处理、特征提取、降维&lt;/li&gt;
  &lt;li&gt;选择更小的 MLP、更少的层、更少的隐藏神经元、网络修剪&lt;/li&gt;
  &lt;li&gt;用其他方法替换神经网络 （例如 SVM、boosting 等）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;深度学习&quot;&gt;深度学习&lt;/h2&gt;

&lt;p&gt;深度学习有什么不同的？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更大的训练集（数百万而不是数百）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更强大的计算机，多核 CPU 和 GPU 上的并行实现&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特殊网络结构&lt;/p&gt;

    &lt;p&gt;自编码器&lt;/p&gt;

    &lt;p&gt;卷积网络&lt;/p&gt;

    &lt;p&gt;循环网络/LSTM&lt;/p&gt;

    &lt;p&gt;(深度信念网络/受限玻尔兹曼机)&lt;/p&gt;

    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;权重共享 weight sharing&lt;/li&gt;
  &lt;li&gt;逐层学习 layer-wise learning&lt;/li&gt;
  &lt;li&gt;Dropout&lt;/li&gt;
  &lt;li&gt;有用特征的学习 learning of useful features&lt;/li&gt;
  &lt;li&gt;从无标签的例子中学习 learning from unlabeled examples&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;特征学习&quot;&gt;特征学习&lt;/h3&gt;

&lt;p&gt;观察：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;许多像素并没有提供太多的信息&lt;/li&gt;
  &lt;li&gt;相邻的像素是高度相关的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：笑脸&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102320.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们如何将相关信息与无关信息分开？&lt;/p&gt;

&lt;h3 id=&quot;自动编码器-autoencoder&quot;&gt;自动编码器 Autoencoder&lt;/h3&gt;

&lt;p&gt;👉具有这种结构的 MLP&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102549.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学习识别功能：&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right)-\vec{x}^{(j)}\right)^{2}\]

&lt;p&gt;隐蔽层必须分析压缩图像内容的神经主成分的种类&lt;/p&gt;

&lt;h3 id=&quot;堆叠自动编码器-stacked-autoencoders&quot;&gt;堆叠自动编码器 Stacked Autoencoders&lt;/h3&gt;

&lt;p&gt;多层自动编码器的增量训练&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;训练具有单个隐藏层的自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103140.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103247.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过附加隐藏层扩展自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103315.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103412.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;类似地重复过程以添加更多隐藏层&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;👉信息压缩逐层增加非线性、多层主成分分析&lt;/p&gt;

&lt;h3 id=&quot;用于分类的堆叠自动编码器&quot;&gt;用于分类的堆叠自动编码器&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;训练堆叠自动编码器&lt;/li&gt;
  &lt;li&gt;用全连接分类器网络替换解码器网络&lt;/li&gt;
  &lt;li&gt;训练分类器网络&lt;/li&gt;
  &lt;li&gt;训练编码器和分类器网络的所有权重进行几次迭代&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103608.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;堆叠式自动编码器可以使用未标记的示例进行训练&lt;/li&gt;
  &lt;li&gt;增量训练获得更好的结果&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;局部感受野local-receptive-fields&quot;&gt;局部感受野Local Receptive Fields&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%84%9F%E5%8F%97%E9%87%8E/8989338&quot;&gt;感受野是什么&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28492837&quot;&gt;深度神经网络中的感受野(Receptive Field)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;评论里有句话：convNets(cnn)每一层输出的特征图(feature map)上的像素点在原始图像上映射的区域大小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103920.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部感受野迫使网络在本地处理信息。&lt;/p&gt;

&lt;p&gt;示例：图像的局部特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104631.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;权值共享--weight-sharing&quot;&gt;权值共享  Weight Sharing&lt;/h3&gt;

&lt;p&gt;权值共享就是说，给一张输入图片，用一个&lt;a href=&quot;https://baike.baidu.com/item/卷积核/3377590&quot;&gt;卷积核&lt;/a&gt;去扫这张图，卷积核里面的数就叫权重，这张图每个位置是被同样的卷积核扫的，所以&lt;a href=&quot;https://baike.baidu.com/item/权重/10245966&quot;&gt;权重&lt;/a&gt;是一样的，也就是共享。&lt;/p&gt;

&lt;p&gt;我们可以为所有像素生成相同的局部特征吗？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重共享：绑定不同感知器的权重&lt;/li&gt;
  &lt;li&gt;卷积层：绑定一层所有感知器的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104849.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;多通道特征层multi-channel-feature-layers&quot;&gt;多通道特征层Multi-Channel Feature Layers&lt;/h3&gt;

&lt;p&gt;在每个隐藏层中，想为每个像素计算几个不同的特征 → &lt;u&gt;多通道层&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310105353.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积核是大小$h×w×k$的&lt;a href=&quot;https://baike.baidu.com/item/%E5%BC%A0%E9%87%8F/380114&quot;&gt;张量&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;最大池化max-pooling&quot;&gt;最大池化Max-Pooling&lt;/h3&gt;

&lt;p&gt;池化层旨在在空间上聚合信息&lt;/p&gt;

&lt;p&gt;池化（Pooling）是卷积神经网络中的一个重要的概念，它实际上是一种形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化（Max pooling）”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效的原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了过拟合。通常来说，CNN的卷积层之间都会周期性地插入池化层。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Max-Pooling：从局部感受野计算最大值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;池化通常与降低层的分辨率相结合&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110357.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;卷积网络convolutional-networks&quot;&gt;卷积网络Convolutional Networks&lt;/h3&gt;

&lt;p&gt;卷积神经网络（CNN）结合了&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;卷积层&lt;/li&gt;
  &lt;li&gt;池化层&lt;/li&gt;
  &lt;li&gt;全连接分类器网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;例如：Alexnet是2012年Imagenet竞赛的冠军模型，准确率达到了57.1%, top-5识别率达到80.2%。&lt;/p&gt;

&lt;p&gt;AlexNet包含5个卷积层和3个&lt;a href=&quot;https://so.csdn.net/so/search?q=全连接层&amp;amp;spm=1001.2101.3001.7020&quot;&gt;全连接层&lt;/a&gt;，模型示意图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从层到层… – 特征在几何上变得越来越复杂 – 特征变得越来越独立于位置 – 特征变得越来越独立于图案大小 – 特征变得越来越具体&lt;/p&gt;

&lt;h3 id=&quot;resnet层-resnet-layers&quot;&gt;ResNet层 ResNet Layers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.0/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.0/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-模式识别(第二部分) Pattern Recognition</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;模式识别&quot;&gt;模式识别&lt;/h1&gt;

&lt;h2 id=&quot;组合方法-ensemble-methods&quot;&gt;组合方法 Ensemble Methods&lt;/h2&gt;

&lt;p&gt;如果想解决分类问题，应该怎么做？&lt;/p&gt;

&lt;p&gt;– 创建专家：训练分类器&lt;/p&gt;

&lt;p&gt;– 训练几个分类器 → 并构建一个组合&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;集成学习归属于机器学习，他是一种「训练思路」，并不是某种具体的方法或者算法。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现实生活中，大家都知道「人多力量大」，「3 个臭皮匠顶个诸葛亮」。而集成学习的核心思路就是「人多力量大」，它并没有创造出新的算法，而是把已有的算法进行结合，从而得到更好的效果。&lt;/p&gt;

&lt;p&gt;那组合怎么工作？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309112402.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;k分类器 $c_{1}, c_{2}, \ldots, c_{k}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将相同的模式应用于所有分类器 → k 个预测&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\begin{array}{c}
c_{1}(\vec{x}) \in{-1,+1} &lt;br /&gt;
c_{2}(\vec{x}) \in{-1,+1} &lt;br /&gt;
c_{k}(\vec{x}) \in{-1,+1}
\end{array}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;总结所有预测并与零进行比较：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\operatorname{ensemble}(\vec{x})=\operatorname{sign}\left(\sum_{j=1}^{k} c_{j}(\vec{x})\right)$&lt;/p&gt;

&lt;p&gt;最好的四种数字识别方法:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– (2) “线拟合”特征：99.7%&lt;/li&gt;
  &lt;li&gt;– (3) 像素值：99.4%&lt;/li&gt;
  &lt;li&gt;– (4) HOG 特征：99.7%&lt;/li&gt;
  &lt;li&gt;– (5) Haar 特征：99.4%&lt;/li&gt;
  &lt;li&gt;– (6) LBP 特征：99.3%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些方法的组合会共享错误（在 1000 个测试示例中）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309112824.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在实验数字识别中, 组合这些方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、像素、Haar&lt;/p&gt;

    &lt;p&gt;错误率：5/1000 • 成员错误：3、6、6/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、HOG、Haar&lt;/p&gt;

    &lt;p&gt;错误率：1/1000&lt;/p&gt;

    &lt;p&gt;成员错误：3、3、6/1000&lt;/p&gt;

    &lt;p&gt;具有联合特征的 SVM 错误：2/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、HOG、LBP&lt;/p&gt;

    &lt;p&gt;错误率 1/1000&lt;/p&gt;

    &lt;p&gt;成员错误：3、3、7/1000&lt;/p&gt;

    &lt;p&gt;具有联合特征的 SVM 错误：5/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合所有
错误率 1/1000&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;什么时候组合更有利？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最佳情况：分类器不共享错误&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;组合错误：0&lt;/li&gt;
  &lt;li&gt;每个分类器的错误：100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309113528.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最差情况：分类器共享所有错误&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;组合错误：150&lt;/li&gt;
  &lt;li&gt;每个分类器的错误：100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以关键问题就是：&lt;strong&gt;避免分类器共享错误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接下来引入：Boosting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;训练相互依赖的分类器&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;u&gt;第 n+1 号分类器&lt;/u&gt; 应该专注于被&lt;em&gt;&lt;u&gt;第 1...n号分类器&lt;/u&gt;&lt;/em&gt;   &lt;strong&gt;错误分类&lt;/strong&gt; 的例子&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boosting&quot;&gt;Boosting&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;实现思路：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一、加权训练模式：为每个训练模式引入权重$\gamma_{i} \geq 0$以模拟其重要性&lt;/p&gt;

&lt;p&gt;→ 有必要修改训练算法，例如soft margin SVM。&lt;/p&gt;

&lt;p&gt;$\underset{\vec{w}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{w}|^{2}+C \sum_{i}\left(\gamma_{i} \cdot \xi_{i}\right)$
subject to $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1-\xi_{i} \quad$ for all $i$ $\xi_{i} \geq 0 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;如何确定模式权重？
→ 训练分类器后重新计算权重。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;增加被错误分类的模式的权重&lt;/li&gt;
  &lt;li&gt;降低分类良好的模式的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;实现思路：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;二、 加权表决&lt;/p&gt;

&lt;p&gt;为每个分类器引入权重$\beta_{k} \geq 0$以模拟其可靠性&lt;/p&gt;

&lt;p&gt;→ 修改投票方案：&lt;/p&gt;

&lt;p&gt;$\operatorname{ensemble}(\vec{x})=\operatorname{sign}\left(\sum_{k} \beta_{k} \cdot \text { vote }_{k}\right)$&lt;/p&gt;

&lt;p&gt;如何确定投票权重？&lt;/p&gt;

&lt;p&gt;→根据分类器的性能选择权重：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类器权重大，准确率高&lt;/li&gt;
  &lt;li&gt;权重小，分类器准确率低&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309115611.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;adaboost算法&quot;&gt;AdaBoost算法&lt;/h4&gt;

&lt;p&gt;Boosting是一种集合技术，试图从许多弱分类器中创建一个强分类器。这是通过从训练数据构建模型，然后创建第二个模型来尝试从第一个模型中纠正错误来完成的。添加模型直到完美预测训练集或添加最大数量的模型。&lt;/p&gt;

&lt;p&gt;AdaBoost是第一个为二进制分类开发的真正成功的增强算法。这是理解助力的最佳起点。现代助推方法建立在AdaBoost上，最着名的是随机梯度增强机。&lt;/p&gt;

&lt;p&gt;Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。&lt;/p&gt;

&lt;p&gt;算法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309115745.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AdaBoost 的特性：&lt;/p&gt;

&lt;p&gt;集成的训练误差由以下限制：&lt;/p&gt;

\[\prod_{t=1}^{T}\left(2 \sqrt{\epsilon_{t}\left(1-\epsilon_{t}\right)}\right) \leq \exp \left\{-2 \sum_{t=1}^{T}\left(\frac{1}{2}-\epsilon_{t}\right)^{2}\right\}\]

&lt;p&gt;如果 所有的$\epsilon_{t} \leq \lambda&amp;lt;\frac{1}{2}$ 和$T \rightarrow \infty$ AdaBoost 会产生一个完美的分类器&lt;/p&gt;

&lt;h4 id=&quot;haar分类器&quot;&gt;Haar分类器&lt;/h4&gt;

&lt;p&gt;概括来说:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Haar分类器=Haar-like特征+AdaBoost算法+级联+积分图快速计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(1) Haar 特性&lt;/p&gt;

&lt;p&gt;$s=\frac{1}{N_{\text {red }}} \sum_{(u, v) \in \text { red area }} g(u, v)-\frac{1}{N_{\text {blue }}} \sum_{(u, v) \in \text { blue area }} g(u, v)$&lt;/p&gt;

&lt;p&gt;(2) 制作分类器&lt;/p&gt;

&lt;p&gt;$c(s)=\operatorname{sign}(z \cdot(s-\theta))$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121157.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参数：&lt;/p&gt;

&lt;p&gt;$\theta \in \mathbb{R}$ 阈值&lt;/p&gt;

&lt;p&gt;$z \in{+1,-1}$ 方向&lt;/p&gt;

&lt;p&gt;(3)从加权示例训练分类器：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;尝试 θ 和 z 的所有可能值&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择最小化加权误差的值&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\sum_{s_{i}&amp;lt;\theta, d^{(i)}=z} \gamma_{i}+\sum_{s_{i}&amp;gt;\theta, d^{(i)}=-z} \gamma_{i}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121411.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(4)具有多种功能的 Haar 分类器：&lt;/p&gt;

&lt;p&gt;​	分类器在一组选项中选择一个 Haar 特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121537.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;boosting-结合haar分类器&quot;&gt;Boosting 结合Haar分类器&lt;/h4&gt;

&lt;p&gt;Idea：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(1) 将 AdaBoost 与 Haar 分类器一起使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数字识别任务的测试错误：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个分类器：56/1000&lt;/li&gt;
  &lt;li&gt;集合大小 5：54/1000&lt;/li&gt;
  &lt;li&gt;集合大小 50：16/1000&lt;/li&gt;
  &lt;li&gt;集合大小 200：10/1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121744.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121756.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2)每个特征产生一个分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;例如 像素灰度&lt;/p&gt;

&lt;p&gt;数字识别任务的测试错误：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个分类器：193/1000&lt;/li&gt;
  &lt;li&gt;集合大小 5：90/1000&lt;/li&gt;
  &lt;li&gt;集合大小 50：24/1000&lt;/li&gt;
  &lt;li&gt;集合大小 200：18/1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309122153.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309122208.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;平衡错误&quot;&gt;平衡错误&lt;/h5&gt;

&lt;p&gt;组合分类器：$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless 0$&lt;/p&gt;

&lt;p&gt;延伸：$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless \delta$&lt;/p&gt;

&lt;p&gt;δ &amp;gt; 0 ：仅当非常确定时才分类为positive&lt;/p&gt;

&lt;p&gt;δ &amp;lt; 0 ：即使不确定，也可以将其归为positive&lt;/p&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;p&gt;具有 Haar 功能的 AdaBoost，组合大小为5&lt;/p&gt;

&lt;p&gt;$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless \delta$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123029.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成. 假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片，那么在这个任务中，飞机就是正例，大雁就是反例。&lt;/p&gt;

&lt;p&gt;现在做如下的定义：
True positives : 飞机的图片被正确的识别成了飞机。
True negatives: 大雁的图片没有被识别出来，系统正确地认为它们是大雁。
False positives: 大雁的图片被错误地识别成了飞机。
False negatives: 飞机的图片没有被识别出来，系统错误地认为它们是大雁。&lt;/p&gt;

&lt;p&gt;Precision其实就是在识别出来的图片中，True positives所占的比率：&lt;/p&gt;

&lt;p&gt;$precision = \frac{tp}{tp+fp} = \frac{tp}{n}$&lt;/p&gt;

&lt;p&gt;其中的n代表的是(True positives + False positives)，也就是系统一共识别出来多少照片 。&lt;/p&gt;

&lt;p&gt;$recall = \frac{tp}{tp+fn}$&lt;/p&gt;

&lt;p&gt;Recall 是被正确识别出来的飞机个数与测试集中所有飞机的个数的比值。&lt;/p&gt;

&lt;p&gt;Recall的分母是(True positives + False negatives)，这两个值的和，可以理解为一共有多少张飞机的照片。&lt;/p&gt;

&lt;h4 id=&quot;搜索对象-searching-for-objects&quot;&gt;搜索对象 Searching for Objects&lt;/h4&gt;

&lt;p&gt;我们如何使用分类器在图像中找到对象？&lt;/p&gt;

&lt;p&gt;– 例如 在字母上找到数字“1”；使用“1”的分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123827.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123945.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;想法：&lt;/p&gt;

&lt;p&gt;将分类器应用于所有图像中所有可能的区域&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;改变区域的位置&lt;/li&gt;
  &lt;li&gt;改变区域的大小&lt;/li&gt;
  &lt;li&gt;改变区域的方向（可选择）。
→ 需要数百万次的试验
效率如何？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;改进的想法：&lt;/p&gt;

&lt;p&gt;使用两个分类器&lt;/p&gt;

&lt;p&gt;分类器1&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;高效&lt;/li&gt;
  &lt;li&gt;不准确&lt;/li&gt;
  &lt;li&gt;高召回率&lt;/li&gt;
  &lt;li&gt;低精度&lt;/li&gt;
  &lt;li&gt;适用于所有领域&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分类器2&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;低效率&lt;/li&gt;
  &lt;li&gt;精度&lt;/li&gt;
  &lt;li&gt;高召回率&lt;/li&gt;
  &lt;li&gt;高精度&lt;/li&gt;
  &lt;li&gt;适用于由分类器1发现的区域&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;想法可以扩展到一系列许多分类器 → &lt;strong&gt;Viola/Jones 算法&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;violajones-approach&quot;&gt;Viola/Jones Approach&lt;/h5&gt;

&lt;p&gt;结合：&lt;/p&gt;

&lt;p&gt;– Haar 分类器&lt;/p&gt;

&lt;p&gt;– AdaBoost&lt;/p&gt;

&lt;p&gt;– 增加集合大小的分类器系列（“级联”）&lt;/p&gt;

&lt;p&gt;– 调整集合以最大化召回率&lt;/p&gt;

&lt;p&gt;– 搜索具有不同区域位置和大小的整个图像&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309124646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;violajones算法举例&quot;&gt;Viola/Jones算法举例&lt;/h5&gt;

&lt;p&gt;人脸识别&lt;/p&gt;

&lt;p&gt;轮廓线检测&lt;/p&gt;

&lt;h3 id=&quot;决策树decision-trees&quot;&gt;决策树：Decision Trees&lt;/h3&gt;

&lt;p&gt;决策树。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;树状结构，分支因子2&lt;/li&gt;
  &lt;li&gt;内部节点：二进制分类器&lt;/li&gt;
  &lt;li&gt;叶子结点：类标签&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125041.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从训练示例创建决策树:&lt;/p&gt;

&lt;p&gt;创建具有未知类标签的叶节点作为根节点。&lt;/p&gt;

&lt;p&gt;将所有训练示例分配给它.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125151.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125211.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125440.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;哪些分类器是合适的？&lt;/p&gt;

&lt;p&gt;– 一般来说：全部&lt;/p&gt;

&lt;p&gt;– 类似的想法，例如 boosting：&lt;/p&gt;

&lt;p&gt;通过组合简单分类器创建一个复杂分类器，即阈值分类器: 如使用 Haar 分类器进行数字识别&lt;/p&gt;

&lt;p&gt;数字识别决策树：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309130254.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;改进决策树的技术&quot;&gt;改进决策树的技术&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;正则化技术Regularization techniques:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;机器学习中的一个核心问题是设计不仅在训练集上误差小，而且在新样本上泛化能力好的算法。许多机器学习算法都需要采取相应的策略来减少测试误差，这些策略被统称为正则化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 早期止损&lt;/strong&gt;
在构建树时使用验证集。当你在验证集上观察到非递减的错误时，停止分割节点。
你观察到验证集上的错误没有减少。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;例如：数字识别的验证误差是。
深度为1的树为54
深度为2的树为37
深度3的树为29
深度4的树为29
深度5的树为29
深度为7的树为36
深度为7的树为37
→ 取深度为3的树&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.修剪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先创建完整的决策树。 之后去除不平衡或病态的分支。&lt;/p&gt;

&lt;p&gt;• 几个修剪标准&lt;/p&gt;

&lt;p&gt;• 已经应用过，例如 在决策树算法 C4.5&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.随机决策树和森林&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;u&gt;通过以下方式随机创建决策树&lt;/u&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;随机选择训练数据的子集&lt;/li&gt;
  &lt;li&gt;随机选择作为下一次拆分选项的特征子集&lt;/li&gt;
  &lt;li&gt;随机选择区分阈值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;u&gt;构建许多随机树的集合：&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;→ 随机决策森林&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建决策森林&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 使用 Haar 特征&lt;/p&gt;

&lt;p&gt;– 随机选择特征和阈值（在 k 个试验中最好）&lt;/p&gt;

&lt;p&gt;– 训练集没有变化&lt;/p&gt;

&lt;p&gt;– 允许深度树&lt;/p&gt;

&lt;p&gt;– 改变集合大小 n&lt;/p&gt;

&lt;p&gt;测试集错误：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131242.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用早期停止训练的决策树：29&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AdaBoost 集成&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;大小 5：54&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;大小 50：16&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;大小 200：10&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SVM：6&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;结合多类别分类器的决策树&quot;&gt;结合多类别分类器的决策树&lt;/h4&gt;

&lt;p&gt;扩展到两个以上的类：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131610.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;训练分类器以最小化叶节点中的香农熵&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131637.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131849.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;熵衡量模式集的同质性&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;所有模式属于同一类：熵最小 (0)&lt;/li&gt;
  &lt;li&gt;相同数量的模式属于每个类：熵最大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309134356.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV8.2/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV8.2/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-模式识别(第一部分) Pattern Recognition</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;模式识别-pattern-recognition&quot;&gt;模式识别 Pattern Recognition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308165314.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分类：将对象分配到类别（classes）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;维基百科：&lt;/p&gt;

&lt;p&gt;模式识别，就是通过计算机用数学技术方法来研究模式的自动处理和判读。我们把环境和客体统称为“模式”。随着计算机技术的发展，人类有可能研究复杂的信息处理过程。&lt;/p&gt;

&lt;p&gt;信息处理过程的一个重要形式是生命体对环境及客体的识别。&lt;/p&gt;

&lt;p&gt;以光学字元识别之“汉字识别”为例：首先将汉字图像进行处理，抽取主要表达特征并将特征与汉字的代码存在计算机中。就像老师教我们“这个字叫什么、如何写”记在大脑中。这一过程叫做“训练”。识别过程就是将输入的汉字图像经处理后与计算机中的所有字进行比较，找出最相近的字就是识别结果。这一过程叫做“匹配”。&lt;/p&gt;

&lt;p&gt;我们如何区分物体？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;几何特征，如长宽比、圆度，……。&lt;/li&gt;
  &lt;li&gt;颜色特征，如主要色调、平均
饱和度，颜色的差异性，…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从实例中学习&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;收集物体的图像&lt;/li&gt;
  &lt;li&gt;为每个物体创建一个特征向量（”模式”）。&lt;/li&gt;
  &lt;li&gt;找到一个决策规则来区分不同类别的特征向量之间的类别&lt;/li&gt;
  &lt;li&gt;从实例模式中创建一个决策规则的过程，决策规则的过程被称为 “学习”或 “训练”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;许多方法用于决策规则和学习&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线性分类器&lt;/li&gt;
  &lt;li&gt;人工神经网络/深度学习&lt;/li&gt;
  &lt;li&gt;基于原型的方法&lt;/li&gt;
  &lt;li&gt;基于案例的推理&lt;/li&gt;
  &lt;li&gt;决策树&lt;/li&gt;
  &lt;li&gt;支持向量机&lt;/li&gt;
  &lt;li&gt;boosting算法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本次我们讨论：
&lt;strong&gt;线性分类器，支持向量机，boosting，决策树，深度学习&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;线性分类器linear-classification&quot;&gt;线性分类器：Linear Classification&lt;/h2&gt;

&lt;p&gt;线性分类器是以下类型的函数：&lt;/p&gt;

&lt;p&gt;$\vec{x} \mapsto \begin{cases}+1 &amp;amp; \text { if }\langle\vec{x}, \vec{w}\rangle+b \geq 0 \ -1 &amp;amp; \text { otherwise }\end{cases}$&lt;/p&gt;

&lt;p&gt;$\vec{w}$是线性分类器的权向量&lt;/p&gt;

&lt;p&gt;$b$是分类器的偏置权重&lt;/p&gt;

&lt;p&gt;线性分类器将&lt;strong&gt;输入空间&lt;/strong&gt;细分为&lt;strong&gt;两个半空间&lt;/strong&gt;。 决策边界是一个超平面&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308190140.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学习任务：&lt;/p&gt;

&lt;p&gt;给定一组训练样例：&lt;/p&gt;

\[\left\{\left(\vec{x}^{(1)}, d^{(1)}\right), \ldots,\left(\vec{x}^{(p)}, d^{(p)}\right)\right\}\]

&lt;p&gt;$d^{(i)}=+1$属于一类的例子（“positive examples”）&lt;/p&gt;

&lt;p&gt;$d^{(i)}=-1$对于属于另一类的示例（“negative examples”）&lt;/p&gt;

&lt;p&gt;寻找 $\vec{w}$和 使其：&lt;/p&gt;

&lt;p&gt;$d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right)&amp;gt;0 \quad$ for all $i \in{1, \ldots, p}$$&lt;/p&gt;

&lt;p&gt;许多可能的解决方案，哪一个是最好的？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308190736.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;g 和 h，两者都不会产生分类错误&lt;/li&gt;
  &lt;li&gt;g 与模式的距离比 h 短&lt;/li&gt;
  &lt;li&gt;g 新模式的错误分类风险大于 h&lt;/li&gt;
  &lt;li&gt;（未知）类概率分布的支持类似于&lt;a href=&quot;https://baike.baidu.com/item/%E5%87%B8%E5%8C%85/179150&quot;&gt;凸包&lt;/a&gt; 训练示例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;边距：超平面和训练模式的凸包之间的最小距离&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\rho=\min _{i}\left(d^{(i)} \cdot \frac{\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b}{|\vec{w}|}\right)$&lt;/p&gt;

&lt;h2 id=&quot;支持向量机-svm&quot;&gt;支持向量机 SVM&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;支持向量机 (SVM)&lt;/strong&gt; ：support vector machine (SVM) ： &lt;strong&gt;最大化边距&lt;/strong&gt;的线性分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308192211.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;支持向量机 (SVM)——训练 SVM 意味着解决：&lt;/p&gt;

&lt;p&gt;$\begin{array}{ll}\underset{\rho, \vec{w}, b}{\operatorname{maximise}} &amp;amp; \rho^{2} \ \text { subject to } &amp;amp; d^{(i)} \cdot \frac{\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b}{|\vec{w}|} \geq \rho \quad \text { for all } i \ &amp;amp; \rho&amp;gt;0\end{array}$&lt;/p&gt;

&lt;p&gt;一个自由度：$|\vec{w}|$&lt;/p&gt;

&lt;p&gt;简化：&lt;/p&gt;

&lt;p&gt;$|\vec{w}|=\frac{1}{\rho}$&lt;/p&gt;

&lt;p&gt;$\underset{\vec{w}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{w}|^{2}$
subject to $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;一个简单的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308192733.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模式是一维的：&lt;/p&gt;

&lt;p&gt;正的：5，10；&lt;/p&gt;

&lt;p&gt;负的：-1，2&lt;/p&gt;

&lt;p&gt;参数：$\vec{w_1},b$&lt;/p&gt;

&lt;p&gt;最优化问题：&lt;/p&gt;

&lt;p&gt;$\underset{w_{1}, b}{\operatorname{minimise}} \frac{1}{2} w_{1}^{2}$&lt;/p&gt;

&lt;p&gt;使其：&lt;/p&gt;

&lt;p&gt;$b \geq 1-5 w_{1}$
$b \geq 1-10 w_{1}$
$b \leq-1+w_{1}$
$b \leq-1-2 w_{1}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308193206.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是如何训练一个SVM呢？&lt;/p&gt;

&lt;p&gt;$\operatorname{minimise}_{\vec{w}, b} \frac{1}{2}|\vec{w}|^{2}$
使其 $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;…跳过所有细节…&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 应用拉格朗日乘数理论&lt;/p&gt;

&lt;p&gt;– 每个训练模式一个拉格朗日乘数&lt;/p&gt;

&lt;p&gt;– 解决方案完全由拉格朗日乘数描述&lt;/p&gt;

&lt;p&gt;– 许多拉格朗日乘数为零&lt;/p&gt;

&lt;p&gt;– 存在计算拉格朗日乘数的算法&lt;/p&gt;

&lt;p&gt;解决方案：&lt;/p&gt;

&lt;p&gt;• 由支持向量确定的最优分离超平面&lt;/p&gt;

&lt;p&gt;• 移除非支持向量不会改变解&lt;/p&gt;

&lt;p&gt;• 添加距离大于边距的模式不会改变解&lt;/p&gt;

&lt;p&gt;• 移除支持向量会改变解&lt;/p&gt;

&lt;p&gt;• 添加距离小于边距的模式会改变解&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308204325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;容错svm-fault-tolerant-svms&quot;&gt;容错SVM Fault-tolerant SVMs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;重叠的类迫使制造错误&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;人为错误$\xi_{i}$&lt;/p&gt;

&lt;p&gt;冲突的目标：&lt;/p&gt;

&lt;p&gt;使 $\rho$最大化，使$\xi_{i}$ 最小化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205120.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最优化问题：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205248.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;C&amp;gt;0：正则化参数控制小误差和大余量之间的平衡（必须手动选择）&lt;/p&gt;

&lt;p&gt;容错 SVM 被称为“soft-margin-SVMs”（与“hard-margin-SVMs”相反）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hard-margin-SVMs有类似的解决方案&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;支持向量是产生单个错误或位于边缘区域边界上的所有模式&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;非线性svm-nonlinear-svms&quot;&gt;非线性SVM Nonlinear SVMs&lt;/h3&gt;

&lt;p&gt;具有非重叠支持的类可能不是线性可分的 → &lt;strong&gt;非线性分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 直接方式：使用圆形/椭圆/非线性曲线进行分类 → 难以分析&lt;/p&gt;

&lt;p&gt;• 间接方式：非线性变换数据并改为对变换后的数据进行分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;非线性问题可能在非线性变换后变为线性问题&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205543.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设非线性变换&lt;/p&gt;

\[\Phi:\left\{\begin{array}{l}\mathbb{R}^{n} \rightarrow \mathbb{R}^{m} \\ \vec{x} \mapsto \Phi(\vec{x})=\vec{X}\end{array}\right.\]

&lt;p&gt;找到解决问题的 SVM：&lt;/p&gt;

&lt;p&gt;$\underset{\vec{W}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{W}|^{2}$
subject to $d^{(i)} \cdot\left(\left\langle\vec{X}^{(i)}, \vec{W}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;在知道拉格朗日乘数的情况下，解决方案完全确定：&lt;/p&gt;

&lt;p&gt;– 不需要计算&lt;/p&gt;

&lt;p&gt;– 模式仅作为点积的参数成对出现&lt;/p&gt;

\[\left\langle\vec{X}^{(i)}, \vec{X}^{(j)}\right\rangle=\left\langle\Phi\left(\vec{x}^{(i)}\right), \Phi\left(\vec{x}^{(j)}\right)\right\rangle\]

&lt;p&gt;考虑到：$\left\langle\Phi\left(\vec{x}^{(i)}\right), \Phi\left(\vec{x}^{(j)}\right)\right\rangle$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308210103.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;快捷方式：核函数$K(\vec{x}, \vec{y})=\langle\Phi(\vec{x}), \Phi(\vec{y})\rangle$&lt;/p&gt;

&lt;p&gt;通过$\phi$ 消除$K(\vec{x}, \vec{y})$ 来代替$\langle\Phi(\vec{x}), \Phi(\vec{y})\rangle$&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%A0%B8%E5%87%BD%E6%95%B0/4693132&quot;&gt;核函数&lt;/a&gt;是隐藏复杂性的肮脏技巧吗？&lt;/p&gt;

&lt;p&gt;例如：$\Phi(x)=\left(\begin{array}{c}x^{2} \ x\end{array}\right)$&lt;/p&gt;

&lt;p&gt;•评估 Φ(x) 和 Φ(y) 需要 2 次乘法&lt;/p&gt;

&lt;p&gt;•评估特征空间中的点积需要 2 次乘法和 1 次加法，总共：4 次乘法和 1 次加法&lt;/p&gt;

&lt;p&gt;$K(x, y)=\langle\Phi(x), \Phi(y)\rangle=(x y)^{2}+(x y)$&lt;/p&gt;

&lt;p&gt;•评估核函数需要 2 次乘法和 1 次加法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一些内核基于无限维的希尔伯特空间&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一些有用的核函数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;点积：$K(\vec{x}, \vec{y})=\langle\vec{x}, \vec{y}\rangle$&lt;/li&gt;
  &lt;li&gt;多项式核函数：$K(\vec{x}, \vec{y})=(\langle\vec{x}, \vec{y}\rangle)^{q}$ or $(\langle\vec{x}, \vec{y}\rangle+1)^{q}$&lt;/li&gt;
  &lt;li&gt;径向基函数 (RBF) 内核 $K(\vec{x}, \vec{y})=e^{-\frac{|\vec{x}-\vec{y}|^{2}}{2 \sigma^{2}}}$&lt;/li&gt;
  &lt;li&gt;直方图交叉核（仅适用于直方图特征）&lt;/li&gt;
&lt;/ul&gt;

\[K(\vec{x}, \vec{y})=\sum_{i} \min \left\{x_{i}, y_{i}\right\}\]

&lt;p&gt;内核参数必须手动设置&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;现在结合所有想法：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;支持向量机最大化边距以最小化错误分类的风险&lt;/li&gt;
  &lt;li&gt;软边距支持向量机允许个别错误。 由参数 C 控制边距大小和误差之间的平衡&lt;/li&gt;
  &lt;li&gt;核函数允许在不改变理论框架的情况下进行非线性分类。 内核类型和内核参数控制非线性程度&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;使用svms&quot;&gt;使用SVMs&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;应用SVM：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308211640.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;训练SVM：&lt;/p&gt;

    &lt;p&gt;我们如何确定 C 和内核？&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308211921.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;评估svm&quot;&gt;评估SVM&lt;/h4&gt;

&lt;p&gt;错误分类的风险 = “false negative”的风险 + “false positive  ”的风险&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308212031.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;E 未知，但可以从样本集中近似&lt;/p&gt;

&lt;p&gt;$E \approx \frac{n_{f n}+n_{f p}}{n}$&lt;/p&gt;

&lt;p&gt;– 样本集中的元素数量&lt;/p&gt;

&lt;p&gt;– 样本集中的假阳误报数量&lt;/p&gt;

&lt;p&gt;– 样本集中的假阴误报数量&lt;/p&gt;

&lt;p&gt;• 验证是在样本集（“测试集”、“验证集”）上测试分类器性能的过程&lt;/p&gt;

&lt;p&gt;• 选择测试集上误分类率最小的 SVM&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;• 测试集必须独立于训练集！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 验证允许比较使用不同 C 值和不同内核训练的 SVM 的性能&lt;/p&gt;

&lt;h4 id=&quot;交叉验证-cross-validation&quot;&gt;交叉验证 Cross Validation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213208.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;• 验证过程的缺点：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;– 仅部分数据用于训练

– 仅部分数据用于验证
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;• k -fold 交叉验证&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;– 想法：用不同的训练和验证集重复训练/验证过程几次

–  k 是重复次数（介于 2 和模式数之间）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;K-fold交叉验证法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将模式集细分为K个大小相同的不相干子集&lt;/li&gt;
  &lt;li&gt;对每个子集j重复。
2.1 从子集1,…,j-1,j+1,…k训练SVM
2.2. 评估子集j的错误分类率&lt;/li&gt;
  &lt;li&gt;平均错误分类率&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;p&gt;– 所有模式都用于验证&lt;/p&gt;

&lt;p&gt;– 训练集包含一定比例$\frac{k-1}{k}$的模式&lt;/p&gt;

&lt;p&gt;如果 k 等于模式总数 → leave-one-out-error&lt;/p&gt;

&lt;p&gt;例子 3-fold-cross-validation  ：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213511.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在参数空间中搜索最优参数的可能性，例如&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213542.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;应该听说过的一些概念：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;过度拟合：分类器在训练数据上表现良好，但在验证或测试数据上表现不佳&lt;/li&gt;
  &lt;li&gt;欠拟合：分类器在训练和验证数据上表现不佳&lt;/li&gt;
  &lt;li&gt;泛化：从训练示例中学习一个概念 也适用于测试数据，而不仅仅是记住训练示例&lt;/li&gt;
  &lt;li&gt;正则化：“帮助”过度拟合的分类器来提高泛化能力&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;实验-数字识别&quot;&gt;实验： 数字识别&lt;/h4&gt;

&lt;p&gt;对手写数字的图像进行分类（美国邮政编码）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309085545.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简化任务：分类——图像显示数字“1”——图像不显示数字“1”&lt;/p&gt;

&lt;p&gt;在这里：&lt;/p&gt;

&lt;p&gt;– 用于训练和验证：500 个“1”图像，500 个“no-1”图像&lt;/p&gt;

&lt;p&gt;– 用于测试：500 个“1”图像，500 个“not-1”数据集图像&lt;/p&gt;

&lt;h5 id=&quot;第一种方法-2-dimensional-patterns&quot;&gt;第一种方法 2-dimensional patterns&lt;/h5&gt;

&lt;p&gt;– 二维模式&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;平均灰度值&lt;/li&gt;
  &lt;li&gt;纵横比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;– 模式重新调整为区间 [-1, +1]&lt;/p&gt;

&lt;p&gt;– 带 RBF 内核的软边距 SVM&lt;/p&gt;

&lt;p&gt;– 5-fold交叉验证&lt;/p&gt;

&lt;p&gt;– 参数空间中的网格搜索：&lt;/p&gt;

&lt;p&gt;$10^{-5} \leq C \leq 10^{15}$(on log scale)&lt;/p&gt;

&lt;p&gt;$-  10^{-3} \leq \sigma \leq 10^{15} $(on log scale)&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：93.1% − 测试集：80.3%&lt;/p&gt;

&lt;p&gt;支持向量数：167（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309093927.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第二种方法-添加第三个特征&quot;&gt;第二种方法 添加第三个特征&lt;/h5&gt;

&lt;p&gt;– 添加第三个特征：拟合线到暗像素的平均距离&lt;/p&gt;

&lt;p&gt;– 准确度： - 交叉验证：98.5% - 测试集：98.7%&lt;/p&gt;

&lt;p&gt;支持向量的数量：95（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5&quot;&gt;混淆矩阵&lt;/a&gt;: (Confusion matrix)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094500.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094606.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第二种方法改进-找到连通分量-ccl-并屏蔽除最大段以外的所有部分&quot;&gt;第二种方法改进 找到连通分量 (CCL) 并屏蔽除最大段以外的所有部分&lt;/h5&gt;

&lt;p&gt;– 找到连通分量 (CCL) 并屏蔽除最大段以外的所有部分&lt;/p&gt;

&lt;p&gt;– 从预处理图像计算特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094647.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：98.5% − 测试集：99.7%&lt;/p&gt;

&lt;p&gt;支持向量数：95（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094804.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第三种方法-统一缩放图片&quot;&gt;第三种方法 统一缩放图片&lt;/h5&gt;

&lt;p&gt;– 将所有图像的大小调整为 28x28 像素，并使用像素的灰度值作为特征&lt;/p&gt;

&lt;p&gt;→ 784-维模式&lt;/p&gt;

&lt;p&gt;准确率：- 交叉验证：99.0% - 测试集：98.7%&lt;/p&gt;

&lt;p&gt;支持向量数量：220（1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094957.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第三种方法改进-只使用一部分像素&quot;&gt;第三种方法改进 只使用一部分像素&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;观察：很多像素不影响分类，例如 边界像素&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;仅使用所有像素的子集，例如 24x18 子区域 → 432 维图案&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095209.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;准确度：- 交叉验证：99.0% - 测试集：99.4%&lt;/p&gt;

&lt;p&gt;支持向量数：219（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095130.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095151.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第四种方法-hog-features&quot;&gt;第四种方法 HOG-features&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;HOG-features&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 定向梯度直方图 (Dalal&amp;amp;Triggs, 2005)&lt;/p&gt;

&lt;p&gt;使用梯度信息而不是灰度级&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095854.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309100002.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309100115.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;HOG 排列 4 个相邻单元的归一化块:&lt;/p&gt;

\[\vec{V}_{1}=(\underbrace{2,5,1,0,0,0,0,0,}_{\text {from cell } 1} \underbrace{0,17,13,0,0,5,8,0}_{\text {from cell } 2}, \underbrace{15,0,0,0,0,0,0,7}_{\text {from cell } 5}, \underbrace{0,2,4,3,2,3,2,12}_{\text {from cell } 6})\]

&lt;p&gt;规范化描述符：&lt;/p&gt;

\[\vec{V}_{1}^{n o r m}=\frac{\vec{V}_{1}}{\left\|\vec{V}_{1}\right\|+\epsilon}\]

&lt;p&gt;组装所有块的描述符：&lt;/p&gt;

\[\vec{V}=\left(\vec{V}_{1}^{\text {norm }}, \ldots, \vec{V}_{9}^{\text {norm }}\right)\]

&lt;p&gt;将向量$\vec{V}$应用于 SVM&lt;/p&gt;

&lt;p&gt;第四种方法： – 仅使用 HOG 特征 → 288 维模式&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：99.4% − 测试集：99.7%&lt;/p&gt;

&lt;p&gt;支持向量的数量：174（共 1000 个）&lt;/p&gt;

&lt;h5 id=&quot;第五种方法-哈尔特征-haar-features&quot;&gt;第五种方法 哈尔特征 Haar features&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/哈尔特征&quot;&gt;哈尔特征&lt;/a&gt;（Haar features）&lt;/p&gt;

&lt;p&gt;哈尔特征使用检测窗口中指定位置的相邻矩形，计算每一个矩形的像素和并取其差值。然后用这些差值来对图像的子区域进行分类。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101607.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较矩形区域的灰度，即红色区域的平均灰度减去蓝色区域的平均灰度。&lt;/p&gt;

&lt;p&gt;Haar特征在一定程度上反应了图像灰度的局部变化。&lt;/p&gt;

&lt;p&gt;在人脸检测中，脸部的一些特征可由矩形特征简单刻画，例如，眼睛比周围区域的颜色要深，鼻梁比两侧颜色要浅等。&lt;/p&gt;

&lt;p&gt;有很多可能的特征&lt;/p&gt;

&lt;p&gt;边缘特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101642.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;线特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101716.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;棋盘特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101752.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;中心环绕特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101840.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对角线方向的特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101903.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 计算哈尔特征&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;简单的直接操作：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$s=\sum_{u=u_{0}}^{u_{0}+w-1} \sum_{v=v_{0}}^{v_{0}+h-1} g(u, v)$&lt;/p&gt;

&lt;p&gt;用 for 循环实现这一点需要操作&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102145.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;比较好用的方式&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$s=\sum_{u=0}^{u_{0}+w-1} \sum_{v=0}^{v_{0}+h-1} g(u, v)-\sum_{u=0}^{u_{0}-1} \sum_{v=0}^{v_{0}+h-1} g(u, v)+\sum_{u=0}^{u_{0}-1} \sum_{v=0}^{v_{0}-1} g(u, v)-\sum_{u=0}^{u_{0}+w-1} \sum_{v=0}^{v_{0}-1} g(u, v)$&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;积分图像：
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$I(x, y):=\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)$&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;计算 s 需要 4 个操作：
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$\begin{array}{c}
s=I\left(u_{0}+w-1, v_{0}+h-1\right)-I\left(u_{0}-1, v_{0}+h-1\right)+ &lt;br /&gt;
I\left(u_{0}-1, v_{0}-1\right)-I\left(u_{0}+w-1, v_{0}-1\right)
\end{array}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102650.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 计算积分图像&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102838.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$I(x, y):=\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)$&lt;/p&gt;

&lt;p&gt;$\begin{aligned}
I(x+1, y+1) &amp;amp;=\sum_{u=0}^{x+1} \sum_{v=0}^{y+1} g(u, v) &lt;br /&gt;
&amp;amp;=\sum_{u=0}^{x+1} \sum_{v=0}^{y} g(u, v)+\sum_{u=0}^{x} \sum_{v=0}^{y+1} g(u, v)-\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)+g(x+1, y+1) &lt;br /&gt;
&amp;amp;=I(x+1, y)+I(x, y+1)-I(x, y)+g(x+1, y+1)
\end{aligned}$&lt;/p&gt;

&lt;p&gt;–&amp;gt; 产生一个迭代算法，通过操作计算$O\left(w_{\text {image }} \cdot h_{\text {image }}\right)$整个积分图像&lt;/p&gt;

&lt;p&gt;–&amp;gt;如果想计算一个矩形，简单的方法更好；如果要计算许多矩形，积分图像会更好&lt;/p&gt;

&lt;p&gt;Haar 特征，在 7x7 位置使用水平和垂直边缘特征 → 98 维模式&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：99.1% − 测试集：99.4%&lt;/p&gt;

&lt;p&gt;支持向量数：109（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309103309.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309103325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第六种方法：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E6%A8%A1%E5%BC%8F&quot;&gt;局部二值模式&lt;/a&gt; [Local binary patterns (LBP) ]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分析局部灰度变化&lt;/li&gt;
  &lt;li&gt;对多个区域执行直方图&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;对于每个相邻像素，检查相邻像素是更亮 (1) 还是更暗 (0)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104104.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算块中所有像素的这些数字&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104159.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104218.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;制作直方图&lt;/li&gt;
  &lt;li&gt;将所有块的直方图排列在一个向量中&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104357.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部二进制模式 → 4096 维稀疏模式&lt;/p&gt;

&lt;p&gt;准确度：- 交叉验证：98.6% - 测试集：99.3%&lt;/p&gt;

&lt;p&gt;支持向量的数量：264（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104503.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104518.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;总结&quot;&gt;总结&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104833.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;见解：&lt;/p&gt;

&lt;p&gt;– 训练和测试的准确度不一样&lt;/p&gt;

&lt;p&gt;– “智能”特性有很大帮助&lt;/p&gt;

&lt;p&gt;– 更多的功能并不意味着更高的准确度&lt;/p&gt;

&lt;p&gt;–  “智能”特性包括预处理&lt;/p&gt;

&lt;p&gt;– “通用”特征（像素值、HOG、Haar）&lt;/p&gt;

&lt;h4 id=&quot;图像数据增强data-tuning&quot;&gt;图像数据增强Data Tuning&lt;/h4&gt;

&lt;p&gt;训练数据的&lt;strong&gt;质量&lt;/strong&gt;和&lt;strong&gt;数量&lt;/strong&gt;对分类结果的影响很大&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;(一) 我们如何提高数量？&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– 选择和标记更多图像&lt;/li&gt;
  &lt;li&gt;– 搜索数据库/互联网以获取更多训练示例（ImageNet、KITTI、CalTech 数据集、INRIA 数据集、Microsoft COCO，…）&lt;/li&gt;
  &lt;li&gt;– 改变亮度、对比度、ROI 中对象位置、旋转的示例&lt;/li&gt;
  &lt;li&gt;– 添加抖动（ 随机噪声）&lt;/li&gt;
  &lt;li&gt;– 镜像示例，如果对象是对称的&lt;/li&gt;
  &lt;li&gt;– 弹性变形 Elastic Distortion&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;弹性变形&quot;&gt;弹性变形&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;对于每个像素：样本从高斯分布随机偏移&lt;/li&gt;
  &lt;li&gt;通过与高斯滤波器的卷积平滑移位值&lt;/li&gt;
  &lt;li&gt;对于每个像素：将像素移动到新位置&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111157.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;（二）我们如何提高质量？&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– 检查标签的一致性&lt;/li&gt;
  &lt;li&gt;– 标准化/标准化模式&lt;/li&gt;
  &lt;li&gt;– 从各种来源/具有不同条件的各种图像序列中获取数据 → 增加模式集中的变化&lt;/li&gt;
  &lt;li&gt;– 检查 ROI 是否一致&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\begin{array}{l}
x_{i}^{\prime}=\frac{x_{i}-\bar{x}}{s_{x}} &lt;br /&gt;
\text { with } \bar{x}=\frac{1}{n} \sum_{i} x_{i} &lt;br /&gt;
\text { and } s_{x}=\sqrt{\frac{1}{n} \sum_{i}\left(x_{i}-\bar{x}\right)^{2}}
\end{array}$&lt;/p&gt;

&lt;h4 id=&quot;多种类分类&quot;&gt;多种类分类&lt;/h4&gt;

&lt;p&gt;具有两个以上类别的分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111553.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;一对一的方法&quot;&gt;一对一的方法：&lt;/h5&gt;

&lt;p&gt;为每个类构建一个分类器，对类元素与非类元素进行分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;克服歧义：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV8.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV8.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-图像分割(第二部分) Segmentation</title>
        <description>&lt;head&gt;
    &lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
   &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;形态学运算-morphological-operations&quot;&gt;形态学运算 Morphological Operations&lt;/h1&gt;

&lt;p&gt;对于图像具有的问题：孔洞， 参差不齐的轮廓，间隙，微小区域等，我们提出了形态学运算。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;两个关键概念&lt;/strong&gt;：扩展和缩小区域：&lt;/p&gt;

&lt;p&gt;——&lt;strong&gt;腐蚀erosion：&lt;/strong&gt; 将区域缩小一个像素&lt;/p&gt;

&lt;p&gt;——&lt;strong&gt;膨胀dilation&lt;/strong&gt;：将区域扩大一个像素&lt;/p&gt;

&lt;p&gt;最基本的形态学运算是膨胀和腐蚀。膨胀指将像素添加到图像中对象的边界，而腐蚀指删除对象边界上的像素。&lt;/p&gt;

&lt;p&gt;现在我们假设：&lt;/p&gt;

&lt;p&gt;背景的像素用0编码，前景像素用大于1的数字编码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308094220.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;如图是四个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308094331.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;八个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;image/2022-02-08-MV6.1/1646729074143.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;24个相邻的像素八个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;strong&gt;腐蚀&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \operatorname{erode}\{g\}(u, v)=\min \{&amp;amp; g(u, v) \\ &amp;amp; g(u+1, v), g(u+1, v+1) \\ &amp;amp; g(u, v+1), g(u-1, v+1) \\ &amp;amp; g(u-1, v), g(u-1, v-1) \\ &amp;amp;g(u, v-1), g(u+1, v-1)\} \end{aligned}\]

&lt;p&gt;取相邻的最小值&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;膨胀&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \operatorname{dilate}\{g\}(u, v)=\max &amp;amp;\{g(u, v)\\ &amp;amp; g(u+1, v), g(u+1, v+1), \\ &amp;amp; g(u, v+1), g(u-1, v+1) \\ &amp;amp; g(u-1, v), g(u-1, v-1) \\ &amp;amp;g(u, v-1), g(u+1, v-1)\} \end{aligned}\]

&lt;p&gt;取相邻的最大值&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095334.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后一个巧妙地知识：腐蚀和膨胀能够结合&lt;/p&gt;

&lt;p&gt;—— 闭合colsing：先膨胀，再腐蚀&lt;/p&gt;

&lt;p&gt;在不改变区域整体延伸的情况下填充间隙和孔洞&lt;/p&gt;

&lt;p&gt;—— 开放opening：先腐蚀，再膨胀&lt;/p&gt;

&lt;p&gt;去除薄区域而不改变大区域的整体延伸&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095744.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image/2022-02-08-MV6.1/1646729944200.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;到目前为止，我们的分割是：&lt;/p&gt;

&lt;p&gt;——分割基于颜色（或灰度值）&lt;/p&gt;

&lt;p&gt;——不同的颜色表示和不同的相似度测量&lt;/p&gt;

&lt;p&gt;问题是：我们如何分割颜色不显著的图像&lt;/p&gt;

&lt;p&gt;例如：将图像分割成相同阴影的区域&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100342.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那我们分割图像又需要什么呢？&lt;/p&gt;

&lt;p&gt;对每个像素：对该像素的描述（图像特征）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如：颜色&lt;/li&gt;
  &lt;li&gt;如：纹理信息&lt;/li&gt;
  &lt;li&gt;如：点的深度（三维扫描仪/立体视觉)&lt;/li&gt;
  &lt;li&gt;如：像素的运动（光流）。&lt;/li&gt;
  &lt;li&gt;如：描述像素是否属于某些物体类别的特征&lt;/li&gt;
  &lt;li&gt;再例如，这些特征的组合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在上述例子中，我们又将找到了什么样子的图像特征呢：&lt;/p&gt;

&lt;p&gt;图像特征：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;颜色和灰度等级不突出&lt;/li&gt;
  &lt;li&gt;线条的方向是突出的&lt;/li&gt;
  &lt;li&gt;例如
    &lt;ul&gt;
      &lt;li&gt;计算灰度等级的梯度&lt;/li&gt;
      &lt;li&gt;确定主要的梯度方向
在像素周围的局部环境中&lt;/li&gt;
      &lt;li&gt;用2维矢量表示方向&lt;/li&gt;
      &lt;li&gt;矢量的长度与平均梯度长度成正比
梯度长度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们的准则和算法：&lt;/p&gt;

&lt;p&gt;• 邻域标准&lt;/p&gt;

&lt;p&gt;• 最小分段大小&lt;/p&gt;

&lt;p&gt;• CCL&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100853.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100930.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;水平集方法-let-set-methods&quot;&gt;水平集方法 Let Set Methods&lt;/h1&gt;

&lt;p&gt;这个方法我的个人理解是通过一段任意封闭的曲线进行扩张，当扩张到图像梯度明显的地方开始放缓扩张速度直到停止，从而形成一段对具有对明显图像特征的区域进行包络。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102404.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102429.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;二类图像分割：&lt;/p&gt;

&lt;p&gt;表示分类任务中有两个类别，比如我们想识别一幅图片是不是猫。也就是说，训练一个分类器，输入一幅图片，用特征向量x表示，输出是不是猫，用y=0或1表示。二类分类是假设每个样本都被设置了一个且仅有一个标签 0 或者 1。&lt;/p&gt;

&lt;p&gt;这类分割的特点：&lt;/p&gt;

&lt;p&gt;所有像素的集合都属于分割；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;指示函数indicator function：&lt;/strong&gt;&lt;/p&gt;

\[\phi(\vec{x}) \begin{cases}&amp;lt;0 &amp;amp; \text { if pixel } \vec{x} \text { belongs to segment } \\ &amp;gt;0 &amp;amp; \text { if pixel } \vec{x} \text { belongs to background }\end{cases}\]

&lt;p&gt;边界线&lt;/p&gt;

&lt;p&gt;有符号距离函数&lt;/p&gt;

\[|\phi(\vec{x})|= \text{ distance of } \vec{x} \text{ from contour}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103407.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;轮廓点：&lt;/p&gt;

\[\phi(\vec{x})= 0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103807.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103922.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对有符号距离函数的时间演化建模: 
\(\phi(\vec{x}, t)\)&lt;/p&gt;

&lt;p&gt;随着时间的推移跟踪边界上的一个点\(\vec{x}(t)\)&lt;/p&gt;

&lt;p&gt;显然：&lt;/p&gt;

\[\phi(\vec{x}(t), t)=0\]

&lt;p&gt;for all \(t\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308104216.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308104804.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由上可得：&lt;/p&gt;

\[\frac{\partial \phi}{\partial t}=-\nabla \phi \cdot \frac{\partial \vec{x}}{\partial t}\]

&lt;p&gt;水平集方法的基本思想：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;初始化：\(\phi(\cdot, 0)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;合理假设：\(\frac{\partial \vec{x}}{\partial t}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;随着时间跟随：\(\phi(\cdot, t)\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;使用数值积分实现，例如欧拉逼近（棘手！）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;与轮廓正交的演化&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \frac{\partial \vec{x}}{\partial t} &amp;amp;=\alpha \cdot \frac{\nabla \phi}{\|\nabla \phi\|} \\ \frac{\partial \phi}{\partial t} &amp;amp;=-\nabla \phi \cdot \alpha \cdot \frac{\nabla \phi}{\|\nabla \phi\|} \\ &amp;amp;=-\alpha \frac{\|\nabla \phi\|^{2}}{\|\nabla \phi\|}=-\alpha\|\nabla \phi\| \end{aligned}\]

&lt;p&gt;如果 α &amp;gt; 0, 轮廓扩张； 如果 α &amp;lt; 0, 轮廓收缩&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308105251.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308105650.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;水平集演化可用于实现形态学运算：&lt;/p&gt;

&lt;p&gt;膨胀 = 扩张&lt;/p&gt;

&lt;p&gt;腐蚀 = 缩小&lt;/p&gt;

&lt;p&gt;闭运算 = 缩小后扩张&lt;/p&gt;

&lt;p&gt;开运算 = 扩张后缩小&lt;/p&gt;

&lt;p&gt;使轮廓更加平滑&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在凹陷的地方扩大&lt;/li&gt;
  &lt;li&gt;在凸面区域缩小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i演化水平集&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;正交于轮廓线&lt;/li&gt;
  &lt;li&gt;取决于局部曲率\(\kappa\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在凸区域：局部近似轮廓的圆 \(\kappa = 1/r\)&lt;/p&gt;

&lt;p&gt;在凹面区域：局部近似轮廓的圆\(\kappa = -1/r\)&lt;/p&gt;

&lt;p&gt;一般来说：\(\kappa=\nabla\left(\frac{\nabla \phi}{\|\nabla \phi\|}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;level set update:&lt;/strong&gt; 水平集升级：&lt;/p&gt;

&lt;p&gt;\(\frac{\partial \vec{x}}{\partial t}=-\beta \kappa \frac{\nabla \phi}{\|\nabla \phi\|}\)
\(\frac{\partial \phi}{\partial t}=\beta \kappa\|\nabla \phi\|\)&lt;/p&gt;

&lt;p&gt;对黑白图非常简单的想法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从一个非常大的轮廓线开始&lt;/li&gt;
  &lt;li&gt;在白色像素处缩减轮廓线&lt;/li&gt;
  &lt;li&gt;不要在黑色像素处收缩&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;轮廓包围黑色区域：&lt;/p&gt;

\[\frac{\partial \vec{x}}{\partial t}= \begin{cases}-\gamma \cdot \frac{\nabla \phi}{\|\nabla \phi\|} &amp;amp; \text { if white pixel } \\ 0 &amp;amp; \text { if black pixel }\end{cases}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102404.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将分割与轮廓矫正相结合&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308152349.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基于梯度的图像分割方法。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从一个非常大的轮廓线开始&lt;/li&gt;
  &lt;li&gt;在梯度长度小的像素处缩小轮廓&lt;/li&gt;
  &lt;li&gt;在梯度长度大的像素处不收缩（边缘像素）。
→ 等高线包裹边缘的区域&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial \vec{x}}{\partial t}=-\epsilon(g) \cdot \frac{\nabla \phi}{\|\nabla \phi\|}\]

\[\epsilon(g)=\frac{\gamma}{\gamma+\mid \text { Gauss }\left.* \nabla g\right|^{p}}\]

&lt;p&gt;with appropriate \(\gamma&amp;gt;0, p \geq 1\) \(g\)denotes gray level image&lt;/p&gt;

&lt;h2 id=&quot;基于-mumford-shah-的分割&quot;&gt;基于 Mumford-Shah 的分割&lt;/h2&gt;

&lt;p&gt;理念：像素应被分配到具有最相似分割的灰度值（颜色值）。&lt;/p&gt;

&lt;p&gt;\(\bar{g}_{\text {foreground }}\)：前景段像素的平均灰度值（颜色）&lt;/p&gt;

&lt;p&gt;\(\bar{g}_{\text {background }}\):背景段中像素的平均灰度值（颜色）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308152913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用灰色（颜色）值检查边界上的像素 &lt;em&gt;Ⅰ&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;像素更类似于外部区域
 缩小轮廓&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;像素更类似于外部区域：&lt;/p&gt;

\[\left(g-\bar{g}_{\text {foreground }}\right)^{2}&amp;lt;\left(g-\bar{g}_{\text {background }}\right)^{2}\]

    &lt;p&gt;扩张轮廓&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于 Mumford-Shah 的分割：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308154055.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;随机场&quot;&gt;随机场&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;每个像素属于一个分割。 但是哪一个？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308160246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;每个像素的分段标签被看作是一个变量
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;
    &lt;p&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;像素的特征向量&lt;/strong&gt;与其&lt;strong&gt;标签&lt;/strong&gt;有关&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308161049.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;像素的特征向量也被视为变量，然而，它的值是被观察到的&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\phi_{f}(l(u, v), f(u, v)) \begin{cases}\text { is small } &amp;amp; \text { if } f(u, v) \text { supports label } l(u, v) \\ \text { is large } &amp;amp; \text { if } f(u, v) \text { does not support label } l(u, v)\end{cases}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308155748.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;相邻像素的标签也相关&lt;/p&gt;

&lt;p&gt;\(l(u, v) \leftrightarrow l(u+1, v)\)
\(l(u, v) \leftrightarrow l(u, v+1)\)&lt;/p&gt;

&lt;p&gt;该关系再次由势函数建模&lt;/p&gt;

&lt;p&gt;\(\phi_{n}(l(u, v), l(u+1, v))\)
\(\phi_{n}(l(u, v), l(u, v+1))\)&lt;/p&gt;

\[\phi_{n}(l(u, v), l(u+1, v))\left\{\begin{array}{l}\text { is small } \\ \text { if } l(u, v) \text { and } l(u+1, v) \text { are similar } \\ \text { is large } \\ \text { if } l(u, v) \text { and } l(u+1, v) \text { are dissimilar }\end{array}\right.\]

&lt;p&gt;找到标签 l(u,v) 使得势函数最小化&lt;/p&gt;

\[\begin{aligned} \operatorname{minimize}_{l(\cdot, \cdot)} &amp;amp; \alpha_{f} \cdot \sum_{u, v} \phi_{f}(l(u, v), f(u, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u+1, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u, v+1)) \end{aligned}\]

&lt;p&gt;带权重因子\(\alpha_{f}, \alpha_{n}&amp;gt;0\)&lt;/p&gt;

&lt;p&gt;优化问题的解决方案： 精确 → 困难（一般来说，存在例外）；近似&lt;/p&gt;

&lt;p&gt;例如：从深色背景中提取明亮的前景对象&lt;/p&gt;

&lt;p&gt;\(l=0 \quad\) background
\(l=1 \quad\) foreground
\(f \quad\) gray value \(0 \leq f \leq 255\)&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\phi_{f}(l, f)=\left(l-\frac{1}{255} f\right)^{2} \\
&amp;amp;\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}
\end{aligned}\]

&lt;p&gt;实现分割标准。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;预定的颜色标准&lt;/li&gt;
  &lt;li&gt;空间标准&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164349.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随机场建模的优势。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分割问题被表述为优化问题&lt;/li&gt;
  &lt;li&gt;潜在函数允许对许多分割标准进行建模，例如
    &lt;ul&gt;
      &lt;li&gt;种子点
对种子点保持标签函数不变&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对某些分段标签的一般偏好（先验的）。
→ 增加单项潜力函数
例如，指定前景物体应在图像的中心位置&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164451.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原型分割特征向量。像素应该被分配到具有最相似原型特征向量的分割。
原型特征最相似的分割。
→ 将原型变量添加到随机域中，每分割一个。
→ 添加势函数，对原型特征和像素特征的相似性进行建模 f&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164649.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;–&amp;gt;应用同质性标准&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;假设前景和背景的划分是
    &lt;ul&gt;
      &lt;li&gt;前景物体位于图像的中心位置&lt;/li&gt;
      &lt;li&gt;前景物体和背景物体具有独特的颜色&lt;/li&gt;
      &lt;li&gt;使用像素颜色（例如在RGB中）作为特征&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\phi_{\text {prior }}(l(u, v))= \begin{cases}\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{|2 v-h e i g h t|}{h e i g h t}\right\} &amp;amp; \text { if } l(u, v)=1 \\ 1-\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{\mid 2 v-h e i g h t}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=0\end{cases}\]

\[\phi_{\text {prototype }}(l, f, p)=\|f-p(l)\|^{2}\]

\[\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}\]

&lt;p&gt;\(\phi_{\text {prior }}(l(u, v))= \begin{cases}\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{\mid 2 v-\text { height } \mid}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=1 \\ 1-\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{|2 v-h e i g h t|}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=0\end{cases}$
$\phi_{\text {prototype }}(l, f, p)=\|f-p(l)\|^{2}\)
\(\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}\)&lt;/p&gt;

\[\begin{aligned} \operatorname{minimize}_{l(\cdot, \cdot), p(\cdot)} &amp;amp; \alpha_{\text {prior }} \cdot \sum_{u, v} \phi_{\text {prior }}(l(u, v)) \\ &amp;amp;+\alpha_{f} \cdot \sum_{u, v} \phi_{\text {prototype }}(l(u, v), f(u, v), p) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u+1, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u, v+1)) \end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164951.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV6.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV6.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
  </channel>
</rss>
