<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>高傲的电工李</title>
    <description>欢迎来到我的个人博客</description>
    <link>https://wenboli-cn-de.github.io/</link>
    <atom:link href="https://wenboli-cn-de.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 14 Jun 2023 17:11:26 +0200</pubDate>
    <lastBuildDate>Wed, 14 Jun 2023 17:11:26 +0200</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Machine Learning-Neural Networks 神经网络</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;neural-networks-神经网络&quot;&gt;Neural Networks 神经网络&lt;/h1&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

We will learn today…

- What a (deep) neural network is&lt;br /&gt;
-  How do we train it?&lt;br /&gt;
-  … which requires a calculus refresher ☺&lt;br /&gt;
-  Why is everybody talking about it?&lt;br /&gt;
-  Various ways to accelerate gradient descent&lt;br /&gt;
-  Practical tips and tricks for training NNs
  
    &lt;/div&gt;

    &lt;div style=&quot;width: 50%;&quot;&gt;

我们今天将学习以下内容：&lt;br /&gt;
&lt;br /&gt;
- 什么是（深度）神经网络&lt;br /&gt;
- 如何训练神经网络？&lt;br /&gt;
- 这需要温习一下微积分 ☺&lt;br /&gt;
- 为什么大家都在谈论它？&lt;br /&gt;
- 加速梯度下降的各种方法&lt;br /&gt;
- 训练神经网络的实际技巧和诀窍&lt;br /&gt;

    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

Today‘s Agenda!&lt;br /&gt;
&lt;br /&gt;
-  What is a Neuron?&lt;br /&gt;
-  Architectures and Activation Functions&lt;br /&gt;
-  Loss-functions&lt;br /&gt;
-  Backpropagation and the Chain Rule&lt;br /&gt;
-  Computation graphs&lt;br /&gt;
&lt;br /&gt;
Advanced Topics:
- Accelerating gradient descent
- Regularization in Neural Networks
- Practical considerations
  
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

今天的议程如下：&lt;br /&gt;
&lt;br /&gt;
- 什么是神经元？&lt;br /&gt;
- 架构和激活函数&lt;br /&gt;
- 损失函数&lt;br /&gt;
- 反向传播和链式法则&lt;br /&gt;
- 计算图&lt;br /&gt;
&lt;br /&gt;
深入话题:&lt;br /&gt;
- 加速梯度下降&lt;br /&gt;
- 神经网络中的正则化&lt;br /&gt;
- 实际考虑因素&lt;br /&gt;
  
    &lt;/div&gt;
&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;biological-inspiration-the-brain-生物学灵感大脑&quot;&gt;Biological Inspiration: The brain 生物学灵感：大脑&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;A neuron is the basic computational unit of the brain:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;神经元是大脑的基本计算单元：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144017.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our brain has ~ 1011 neurons&lt;/li&gt;
  &lt;li&gt;Each neuron is connected to ~ 104 other neurons (via synapses)&lt;/li&gt;
  &lt;li&gt;Synapses have different connectivity&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Approx. model: Input impulses are weighted by synapse strength and added up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;我们的大脑有大约10^11个神经元。&lt;/li&gt;
  &lt;li&gt;每个神经元通过大约10^4个突触连接到其他神经元。&lt;/li&gt;
  &lt;li&gt;突触具有不同的连接方式。&lt;/li&gt;
  &lt;li&gt;近似模型：输入脉冲通过突触的强度加权并相加。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Neurons receive input signals and accumulate voltage. After some threshold they will fire spiking responses (highly non-linear response).&lt;/p&gt;

&lt;p&gt;神经元接收输入信号并积累电压。 在达到某个阈值后，它们将激发尖峰响应（高度非线性响应）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144249.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;artificial-neurons-人工神经元&quot;&gt;Artificial Neurons 人工神经元&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;For neural nets, we use a much simpler unit (neuron, perceptron):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对于神经网络，我们使用更简单的单元（神经元、感知器）：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;

3 ingredients:
- Weighting of the input
- Summation
- Non-linear activation function
    &lt;/div&gt;
    &lt;div style=&quot;width: 50%;&quot;&gt;
    
三个要素：
- 输入的加权
- 总和计算
- 非线性激活函数
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Example we already know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Logistic regression 逻辑回归&lt;/li&gt;
&lt;/ul&gt;

\[y=\sigma\left(\mathbf{w}^T \mathbf{x}+b\right)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614144739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;feedforward-neural-networks-前馈神经网络&quot;&gt;Feedforward Neural Networks 前馈神经网络&lt;/h3&gt;

&lt;p&gt;Building a network:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We can connect lots of units
together into a directed acyclic
graph.&lt;/li&gt;
  &lt;li&gt;This gives a feed-forward
neural network. That’s in
contrast to recurrent neural
networks, which can have
cycles.&lt;/li&gt;
  &lt;li&gt;Typically, units are grouped
together into layers.&lt;/li&gt;
  &lt;li&gt;Each layer connects N input units to M output units.&lt;/li&gt;
  &lt;li&gt;In the simplest case, all input units are connected to all output units. We call this a fully
connected layer.&lt;/li&gt;
  &lt;li&gt;Note: the inputs and outputs for a layer are distinct from the inputs and outputs to the network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;构建一个网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;我们可以将很多单元连接在一起形成一个有向无环图。&lt;/li&gt;
  &lt;li&gt;这就得到了一个前馈神经网络。与循环神经网络形成对比，后者可以有循环。&lt;/li&gt;
  &lt;li&gt;通常，单元被分组成层。&lt;/li&gt;
  &lt;li&gt;每一层将N个输入单元连接到M个输出单元。&lt;/li&gt;
  &lt;li&gt;在最简单的情况下，所有输入单元都连接到所有输出单元。我们称之为全连接层。&lt;/li&gt;
  &lt;li&gt;注意：层的输入和输出与网络的输入和输出是不同的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I.e., each layer has a M x N weight matrix W&lt;/li&gt;
  &lt;li&gt;Equation in matrix form: $\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;Output units are a function of input units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Feedforward neural networks are also often called multi-layer perceptrons (MLPs)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;每一层具有一个大小为M x N的权重矩阵W。&lt;/li&gt;
  &lt;li&gt;以矩阵形式的方程为：$\mathbf{y}=\phi(\mathbf{W} \mathbf{x}+\mathbf{b})$
    &lt;ul&gt;
      &lt;li&gt;输出单元是输入单元的函数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;前馈神经网络通常也被称为多层感知器（MLP）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145355.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;activation-funcitons-激活函数&quot;&gt;Activation funcitons 激活函数&lt;/h3&gt;

&lt;p&gt;Different activation functions for introducing non-linearities:
引入非线性的不同激活函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614145629.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[\sigma(x)=\frac{1}{1+\exp (-x)}\]

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[0,1]&lt;/li&gt;
  &lt;li&gt;从历史上来看它们非常流行，因为它们可以很好地解释为神经元的饱和“发射率”
    &lt;blockquote&gt;
      &lt;p&gt;常用的激活函数（如Sigmoid函数）在输入值较大或较小的情况下会饱和，即输出值接近0或1，并具有类似于神经元发射的特性。因此，这些激活函数的输出值可以被解释为神经元的饱和“发射率”。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;问题：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;饱和的神经元会使得梯度消失&lt;/li&gt;
  &lt;li&gt;Sigmoid函数的输出不以零为中心（对于初始化很重要）&lt;/li&gt;
  &lt;li&gt;exp()计算耗费资源&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150009.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将数字压缩到范围[-1,1]&lt;br /&gt;
✓ 以零为中心（很好）&lt;br /&gt;
× 当饱和时仍然会消失梯度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614150446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;修正线性单元（Rectified Linear Unit，ReLU）&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和（在正区间内）&lt;br /&gt;
✓ 计算效率非常高&lt;br /&gt;
✓ 在实践中比sigmoid/tanh函数收敛速度快得多（例如，快6倍）&lt;/p&gt;

&lt;p&gt;× 输出不以零为中心&lt;br /&gt;
× 对于x &amp;lt; 0没有梯度&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152248.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (0.1 x, x)$&lt;/p&gt;

&lt;p&gt;✓ 不会饱和&lt;br /&gt;
✓ 计算效率高&lt;br /&gt;
✓ 在实践中收敛速度比sigmoid/tanh函数快很多！（例如，6倍）&lt;br /&gt;
✓ 不会“消失”&lt;/p&gt;

&lt;p&gt;Parametric Rectifier (PReLu):&lt;br /&gt;
参数整流器 (PReLu)：&lt;/p&gt;

&lt;p&gt;计算： $f(x)=\max (\alpha x, x)$&lt;/p&gt;

&lt;p&gt;Also learn alpha&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614152454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;指数线性单元&lt;/p&gt;

&lt;p&gt;计算：&lt;/p&gt;

\[f(x)= \begin{cases}x &amp;amp; \text { if } x&amp;gt;0 \\ \alpha(\exp (x)-1) &amp;amp; \text { if } x \leq 0\end{cases}\]

&lt;p&gt;其中，alpha是一个预定义的常数，通常取一个较小的正数。&lt;/p&gt;

&lt;p&gt;✓ 具有ReLU的所有优点&lt;br /&gt;
✓ 输出接近零均值&lt;br /&gt;
× 计算过程中需要使用exp()函数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In practice:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使用ReLU。在学习率和初始化时要小心。
    &lt;blockquote&gt;
      &lt;p&gt;对于学习率（learning rate），选择一个合适的值非常重要。过大的学习率可能导致训练不稳定或发散，而过小的学习率可能导致收敛速度过慢。&lt;/p&gt;

      &lt;p&gt;对于初始化（initialization），权重和偏置的初始值也需要谨慎选择。使用不合适的初始化方法可能导致梯度消失或梯度爆炸等问题，影响网络的训练效果。对于使用ReLU的网络，一种常见的初始化方法是使用较小的随机值，如从均匀分布或正态分布中采样得到的值。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;尝试使用Leaky ReLU / ELU。&lt;/li&gt;
  &lt;li&gt;尝试使用tanh函数，但不要期望太多。&lt;/li&gt;
  &lt;li&gt;不要使用sigmoid函数。
    &lt;ul&gt;
      &lt;li&gt;sigmoid函数仅在分类问题的输出激活中使用。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Formalisation:&lt;/p&gt;

&lt;p&gt;每层计算一个函数，因此网络计算函数的组合：&lt;/p&gt;

\[\begin{aligned}
\mathbf{h}^{(1)} &amp;amp; =f^{(1)}(\mathbf{x}) \\
\mathbf{h}^{(2)} &amp;amp; =f^{(2)}\left(\mathbf{h}^{(1)}\right) \\
\vdots &amp;amp;
\end{aligned}\]

&lt;p&gt;或者更简单地：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \mathbf{y}=f^{(L)}\left(\mathbf{h}^{(L-1)}\right) \\
&amp;amp; \mathbf{y}=f^L \circ f^{L-1} \circ \ldots f^{(1)}(\mathbf{x})
\end{aligned}\]

&lt;p&gt;神经网络提供模块化：我们可以将每一层的计算实现为一个黑盒子&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614154844.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-xor-异或&quot;&gt;Example: XOR 异或&lt;/h4&gt;

&lt;p&gt;设计一个实现 XOR 的网络：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161308.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单个单元无法计算!&lt;/li&gt;
  &lt;li&gt;经典的例子，为什么我们需要多层次&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;XOR in terms of elemental operations:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;XOR(a,b) = (a OR b) AND NOT (a AND b)&lt;/p&gt;

&lt;p&gt;设计一个实现XOR的网络：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;激活函数的硬阈值，x1和x2是二进制的&lt;/li&gt;
  &lt;li&gt;h1 计算 x1 OR x2&lt;/li&gt;
  &lt;li&gt;h2 计算 x1 AND x2&lt;/li&gt;
  &lt;li&gt;y 计算 h1 AND NOT h2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614161739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deep-architectures深层架构&quot;&gt;Deep Architectures深层架构&lt;/h3&gt;

&lt;p&gt;为什么我们需要深入？&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;任何线性层序列都可以用单个线性层等效地表示&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{y}=\underbrace{\mathbf{W}^{(3)} \mathbf{W}^{(2)} \mathbf{W}^{(1)}}_{\tilde{\mathbf{W}}} \mathbf{x}\]

&lt;p&gt;即，我们需要非线性，以利用多个层次&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;具有非线性激活函数的FF-NN是通用函数近似器：
    &lt;ul&gt;
      &lt;li&gt;给定一个潜在的无限量的单元，它们可以任意地逼近任何函数&lt;/li&gt;
      &lt;li&gt;通用函数逼近定理： 单层就足以实现 “普适性”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;那么，单层是否足够？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;尽管通用函数逼近定理表示单层理论上足够，但实际上我们需要指数级（与输入维度成正比）的神经元数量才能实现这一点。
    &lt;ul&gt;
      &lt;li&gt;如果可以学习任何函数，那么结果很可能会过拟合。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;相反，多层网络可以用更少的神经元实现类似的效果。
    &lt;ul&gt;
      &lt;li&gt;紧凑的表示方式比”通用表示”更有效。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-损失函数&quot;&gt;Loss-functions 损失函数&lt;/h2&gt;

&lt;p&gt;训练神经网络的目标函数：&lt;/p&gt;

&lt;p&gt;通用的机器学习方法：逐样本损失 + 正则化惩罚&lt;/p&gt;

\[\boldsymbol{\theta}^*=\underset{\text { parameters } \boldsymbol{\theta}}{\arg \min } \sum_{i=1}^N l\left(\boldsymbol{x}_i, \boldsymbol{\theta}\right)+\lambda \text { penalty }(\boldsymbol{\theta})\]

&lt;p&gt;对于不同的任务，损失函数和输出激活函数的选择有所不同：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;回归任务（Regression）：通常使用均方误差（Mean Squared Error）作为损失函数，输出激活函数可以是线性函数或恒等函数。&lt;/li&gt;
  &lt;li&gt;二分类任务（Binary Classification）：常见的损失函数包括二元交叉熵（Binary Cross-Entropy）或对数损失（Log Loss），输出激活函数通常选择sigmoid函数。&lt;/li&gt;
  &lt;li&gt;多类别分类任务（Multi-class Classification）：常用的损失函数是多类别交叉熵（Categorical Cross-Entropy），输出激活函数则通常选择softmax函数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Regression 回归&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\boldsymbol{b}^{(L)}
$$

&lt;b&gt;Loss：&lt;/b&gt;

squared error 方差

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\frac{1}{2}\left(\mathbf{f}\left(\mathbf{x}_i\right)-\mathbf{y}_i\right)^2
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

linear Gaussian

$$
p(\mathbf{y} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{y} \mid \mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}, \mathbf{\Sigma}\right)
$$

&lt;br /&gt;

negative log-likelihood 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\log \mathcal{N}\left(\mathbf{y}_i \mid \boldsymbol{\mu}\left(\mathbf{x}_i\right), \boldsymbol{\Sigma}\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Binary classification 二元分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
f=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

hinge-loss 铰链损失

$$
l\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=\max \left(0,1-y_i f\left(\boldsymbol{x}_i\right)\right)
$$

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
f=\sigma\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+b^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
\begin{aligned}
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)= &amp;amp; -c_i \log f\left(\mathbf{x}_i\right)-\left(1-c_i\right) \log \left(1-f\left(\mathbf{x}_i\right)\right)
\end{aligned}
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中$y_i$是 -1/+1 labels, $c_i$ 是0/1 labels。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-class classification 多类别分类&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;display: flex;&quot;&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Output layer: Deterministic 决定性&lt;/b&gt;

linear 线性

$$
\mathbf{f}=\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}
$$

&lt;b&gt;Loss function&lt;/b&gt;

Multi-class SVM loss 多类 SVM 损失&lt;br /&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
 Not covered
&lt;/div&gt;

&lt;/div&gt;
&lt;div style=&quot;flex: 50%;&quot;&gt;

&lt;b&gt;Probabilistic 概率性&lt;/b&gt;

sigmoid 

$$
\mathbf{f}=\operatorname{softmax}\left(\mathbf{W}^{(L)} \mathbf{h}^{(L-1)}+\mathbf{b}^{(L)}\right)
$$

&lt;br /&gt;

neg-loglike 负对数似然

$$
l_i\left(\mathbf{x}_i, \boldsymbol{\theta}\right)=-\sum_{k=1}^K \boldsymbol{h}_{c_i, k} \log y_k\left(\mathbf{x}_i\right)
$$

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;其中 $\boldsymbol{h}_{c_i, k}$ 是 one hot coding&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;One-hot encoding是一种常用的数据预处理技术，用于将离散特征表示为二进制向量的形式。它常用于机器学习和深度学习任务中，特别是当特征数据中包含分类变量时。&lt;/p&gt;

  &lt;p&gt;在One-hot encoding中，如果一个特征具有n个不同的类别，那么它将被表示为一个长度为n的二进制向量，其中只有一个位置为1，其他位置都为0。被设置为1的位置对应于该特征所属的类别。&lt;/p&gt;

  &lt;p&gt;这样的编码方式有助于解决以下问题：&lt;/p&gt;

  &lt;p&gt;解决分类变量的数值化问题：分类变量通常无法直接用于机器学习算法，因为算法通常期望输入是数值型数据。One-hot encoding可以将分类变量转换为数值型数据，使其适用于算法的处理。&lt;/p&gt;

  &lt;p&gt;避免特征之间的顺序关系：One-hot encoding将每个类别都独立地表示为一个二进制向量，不考虑类别之间的顺序关系。这在一些情况下是有益的，例如避免算法错误地学习到类别之间的顺序或大小关系。&lt;/p&gt;

  &lt;p&gt;需要注意的是，当原始特征具有大量类别时，One-hot encoding会导致特征空间的维度增加，可能会导致稀疏矩阵和计算资源的浪费。在处理高维稀疏数据时，可能需要考虑其他的特征编码方法。&lt;/p&gt;

  &lt;p&gt;在实践中，可以使用多种编程语言和库来执行One-hot encoding，例如Python中的scikit-learn、pandas和TensorFlow等。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Feature Learning 特征学习&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;神经网络可以被看作是一种学习特征的方式&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;最后一层是标准的线性回归/分类层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网络学习特征$\psi(\mathbf{x})$使得线性回归/分类可以解决它&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165612.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614165623.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/ML-04-Neural-Networks/</guid>
        
        <category>专业</category>
        
        <category>机器学习</category>
        
        
      </item>
    
      <item>
        <title>工程力学4-动力学/Technische Mechanik IV – Dynamik - Integration der Eulerschen Gleichungen 欧拉方程的积分</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;integration-der-eulerschen-gleichungen-欧拉方程的积分&quot;&gt;Integration der Eulerschen Gleichungen 欧拉方程的积分&lt;/h1&gt;

&lt;p&gt;EULERSCHE Kreiselgleichungen 欧拉陀螺仪方程&lt;/p&gt;

&lt;p&gt;Eulersche Gleichungen beschreiben allgemeine Bewegung eines starren Körpers mit einem fixen Punkt.欧拉方程描述了具有固定点的刚体的一般运动。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162403.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Das Problem der analytischen Lösung dieser Gleichungen hat Wissenschaftler weit über 100 Jahre intensiv beschäftigt. Am Ende hat sich herausgestellt, dass es nur drei Fälle gibt, in denen diese Gleichungen vollständig lösbar sind. (Natürlich numerische Näherungslösung ist immer möglich). Die Nichtintegrierbarkeit dieser Gleichungen wurde ähnlich wir beim Dreikörperproblem auf die fundamentale Arbeiten vom französischen Mathematiker Henry Poincare Ende des XIX Jahrhundert zurückgeführt. Die drei Fälle der Integrierbarkeit werden nach ihren Erfinder genannt&lt;/p&gt;

&lt;p&gt;100 多年来，这些方程的解析解问题一直困扰着科学家们。 最后发现只有三种情况可以完全求解这些方程。  （当然，数值近似总是可能的）。 与三体问题类似，这些方程的不可积性问题可以追溯到19世纪末法国数学家亨利庞加莱的基础工作。 可积性的三种情况以其发明者的名字命名&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613162341.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Der einfachste Falls wurde von Euler untersucht und beschäftigt sich mit einem Körper in der Situation, wo das resultierende Moment aller äußerer Kräfte verschwindet (gleich null ist). Dieser Fall wird realisiert, wenn ein schwerer Kreisel sich im homogenen Schwerekraft (z.B. der Erde befindet) und in seinem Schwerpunkt fixiert wird, d.h. der Aufhänge punkt befindet sich im Schwerpunkt des Körpers. In diesem Fall vereinfachen sich die Bewegungsgleichungen:&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-kreisel-der-eulersche-fall-陀螺仪&quot;&gt;Kräftefreier Kreisel (Der Eulersche Fall) 陀螺仪&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163321.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种最简单的情况是由欧拉研究的，涉及到一个物体在所有外力产生的力矩之和为零的情况。这种情况在一个重质量陀螺仪位于均匀重力场（例如地球）并且被固定在其质心的情况下实现，也就是悬挂点位于物体的质心。在这种情况下，运动方程变得更简化：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=M_1 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=M_2 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=M_3
\end{aligned}\]

&lt;p&gt;Zunächst wird der einfachste Fall eines symmetrischen Körpers behandelt. In diesem Fall
können die Gleichungen in elementaren Funktionen integriert werden:&lt;/p&gt;

&lt;p&gt;首先，处理对称体的最简单情况。 在这种情况下，方程可以集成为初等函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; J_{11}=J_{22}=A ; \quad J_{33}=C \\
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0
\end{aligned}\]

&lt;h2 id=&quot;kräftefreier-symmetrischer-kreisel-kinetik-没有外力作用具有对称性的陀螺&quot;&gt;Kräftefreier symmetrischer Kreisel. Kinetik 没有外力作用、具有对称性的陀螺&lt;/h2&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 A+\omega_2 \omega_3(C-A)=0 \\
&amp;amp; \dot{\omega}_2 A-\omega_3 \omega_1(C-A)=0 \\
&amp;amp; \dot{\omega}_3 C=0 \quad \dot{\omega}_3=0 \rightarrow \quad \omega_3=\omega_{30}=\text { konst } \\
&amp;amp; \left\{\begin{array}{l}
\dot{\omega}_1+\omega_2 \omega_{30} \frac{C-A}{A}=0 \\
\dot{\omega}_2-\omega_1 \omega_{30} \frac{C-A}{A}=0
\end{array} \rightarrow \quad \ddot{\omega}_2=\dot{\omega}_1 \omega_{30} \frac{C-A}{A}=-\omega_1\left(\omega_{30} \frac{C-A}{A}\right)^2\right. \\
&amp;amp; \ddot{\omega}_2+\left(\omega_{30} \frac{C-A}{A}\right)^2 \omega_2=0 \quad \rightarrow \quad \omega_2=\omega_0 \sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\frac{A}{C-A} \frac{1}{\omega_{30}} \dot{\omega}_2=\frac{A}{C-A} \frac{1}{\omega_{30}} \omega_0 \omega_{30} \frac{C-A}{A} \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \omega_1=\omega_0 \cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Damit sind die Komponenten der Winkelgeschwindigkeit vollständig bestimmt.
Es bleiben die kinematischen Gleichungen zur Bestimmung der Eulerschen Winkel als
Funktionen der Zeit.&lt;br /&gt;
角速度的分量因此被完全确定。 用于确定作为时间函数的欧拉角的运动学方程仍然存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613163739.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Geometrische Interpretation: Innerhalb des Körpers umläuft der Vektor der Winkelgeschwindigkeit einen Kreis. Die Umlaufgeschwindigkeit hängt von den Anfangsbedingungen und der Verhältnis der Massenträgheits-momente des Körpers ab.&lt;br /&gt;几何解释：在物体内部，角速度的矢量绕着一个圆旋转。旋转速度取决于初始条件和物体的转动惯量之比。&lt;/p&gt;

\[\Omega_{\text {Umlauf }}=\omega_{30} \frac{C-A}{A}\]

&lt;p&gt;Ermittlung &lt;strong&gt;kinematischer Größen&lt;/strong&gt; wird möglich, wenn wir beachten, dass die Zeitableitung des Drehmomentes im raumfesten Bezugssystem in Abwesenheit des äußeren Momentes gleich null ist.&lt;br /&gt;当我们注意到在没有外部力矩的情况下，相对于固定空间参考系的力矩的时间导数为零时，我们就可以确定&lt;strong&gt;运动学量&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“kinematische Größen” 指的是描述物体运动的量，而不考虑所受到的力或力矩的影响。它们通常包括位置、速度、加速度和角度等物理量。运动学是研究物体运动的分支，主要关注物体的运动状态和其随时间的变化，而不涉及导致这些变化的具体力量或力矩。因此，kinematische Größen 是用来描述物体运动的量，从而提供关于物体位置、速度和加速度等方面的信息。&lt;/p&gt;
&lt;/blockquote&gt;

\[\frac{ {\quad}^I d \vec{L}^{(s)}}{d t}=\overrightarrow{0} \quad \rightarrow \quad \vec{L}^{(s)}=\text { konst }\]

&lt;p&gt;Dies bedeutet, dass der Drall-Vektor in seiner Richtung und betrag konstant bleibt. Wählen wir die raumfesten Koordinaten so, dass der Basisvektor entlang des Drall i3 -Vektors gerichtet ist:&lt;br /&gt;这意味着扭曲矢量的方向和大小保持不变。 让我们选择空间固定坐标，使基本向量沿着扭曲 i3 向量定向：&lt;/p&gt;

\[\vec{L}^{(S)}=L\vec{i}_{\text{3}}\]

&lt;p&gt;Anderseits gilt (vgl. Vorlesung 2, Folie 10):
另一方面（参见第 2 讲，幻灯片 10）：&lt;/p&gt;

\[\vec{L}^{(S)}=\vec{\vec{J}}^{(S)}\cdot{}^I\vec{\omega}^K=A\omega_1\vec{e}_1+A\omega_2\vec{e}_2+C\omega_3\vec{e}_3\]

&lt;p&gt;Aus der Definition der Euler-Winkeln folgt dann: &lt;br /&gt;根据欧拉角的定义，可以得出：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;C\omega_3=L\cos\theta \\
&amp;amp;A\omega_1 =L\sin\theta\sin\varphi  \\
&amp;amp;A\omega_2 =L\sin\theta\cos\varphi 
\end{aligned}\]

&lt;p&gt;Hinweis: Drehung um $\psi$ verändert den Drall-Vektor nicht.&lt;br /&gt;注意：关于$\psi$的旋转不会改变扭曲向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174359.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Daraus folgt sofort:&lt;/p&gt;

\[\begin{aligned}
&amp;amp; C \omega_3=L \cos \theta \rightarrow \quad \cos \theta=\frac{C \omega_3}{L}=\frac{C \omega_{30}}{L}=\text { konst } \\
&amp;amp; \theta=\theta_0=\arccos \left(\frac{C \omega_{30}}{L}\right) \\
&amp;amp; \left.\begin{array}{l}
A \omega_1=L \sin \theta \sin \varphi \\
A \omega_2=L \sin \theta \cos \varphi
\end{array}\right\} \\
&amp;amp; \rightarrow \tan \varphi=\frac{\omega_1}{\omega_2}=\frac{\cos \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}{\sin \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right)}=\cot \left(\omega_{30} \frac{C-A}{A} t+\alpha_0\right) \\
&amp;amp; \varphi=\frac{\pi}{2}-\omega_{30} \frac{C-A}{A} t+\alpha_0 ; \quad \dot{\varphi}=-\omega_{30} \frac{C-A}{A}=\text { konst } \\
&amp;amp; \dot{\psi} \cos \theta+\dot{\varphi}=\omega_{30} \quad \rightarrow \quad \dot{\psi} \frac{C \omega_{30}}{L}-\omega_{30} \frac{C-A}{A}=\omega_{30} \\
&amp;amp; \dot{\psi} \frac{C}{L}-\frac{C-A}{A}=1 \quad \rightarrow \quad \dot{\psi}=\frac{L}{A}=\text { konst } \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613174726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Nutationskegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;自旋轴&lt;/strong&gt;相对于固定空间的进动轴所形成的圆锥。这个圆锥的顶点位于陀螺体的自旋轴上，而圆锥的轴线则与进动轴重合。由于陀螺体的自旋轴会绕着进动轴进行进动，所以形成了这个进动圆锥。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 意味着这个进动圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着进动圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Nutationskegel” 指的是固定在空间中的进动圆锥，用于描述陀螺体或旋转物体的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Spurkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;迹点（运动轨迹上的点）&lt;/strong&gt;相对于固定空间的运动形成的圆锥。这个圆锥的顶点位于迹点所在的位置，而圆锥的轴线则与迹点在空间中的运动方向相对应。&lt;/p&gt;

  &lt;p&gt;“Raumfester” 表示这个迹圆锥是相对于固定的空间来定义和测量的，而不是相对于陀螺体自身。这意味着迹圆锥的方向和位置在固定空间中保持不变，不受陀螺体自身旋转的影响。&lt;/p&gt;

  &lt;p&gt;因此，”Raumfester Spurkegel” 指的是固定在空间中的迹圆锥，用于描述陀螺体或旋转物体迹点的运动特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;在刚体动力学中，”Polkegel” 是指在陀螺体或旋转物体的运动中，其&lt;strong&gt;极轴&lt;/strong&gt;所形成的圆锥。这个圆锥的顶点位于极轴所在的位置，而圆锥的轴线则与极轴重合。&lt;/p&gt;

  &lt;p&gt;“Körperfester” 表示这个极锥是相对于陀螺体自身来定义和测量的，而不是相对于外部空间。这意味着极锥的方向和位置随着陀螺体的运动而变化，取决于陀螺体自身的姿态和旋转状态。&lt;/p&gt;

  &lt;p&gt;因此，”Körperfester Polkegel” 指的是固定在陀螺体自身的极锥，用于描述陀螺体的旋转特性和姿态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;geometrische-interpretation-几何解释&quot;&gt;Geometrische Interpretation 几何解释&lt;/h3&gt;

&lt;p&gt;Der Körper dreht sich mit konstanter Geschwindigkeit $\dot{\varphi}$ um seine Hauptachse $\overrightarrow{e_{3}}$.&lt;/p&gt;

&lt;p&gt;Diese Achse selbst dreht sich mit konstanter Geschwindigkeit $\vec{i}_3$ um die raumfeste Achse, d.h. um den Drall-Vektor $\dot{\psi}$.&lt;/p&gt;

&lt;p&gt;Diese Bewegung wird als reguläre freie Präzession bezeichnet.&lt;/p&gt;

&lt;p&gt;物体以恒定速度 $\dot{\varphi}$ 绕其主轴 $\overrightarrow{e_{3}}$ 自转。&lt;/p&gt;

&lt;p&gt;这个轴本身以恒定速度 $\vec{i}_3$ 绕固定轴旋转，即绕着进动矢量 $\dot{\psi}$。&lt;/p&gt;

&lt;p&gt;这种运动被称为规则的自由进动。&lt;/p&gt;

\[\left.\begin{array}{l}
\dot{\psi}=\frac{L}{A} \\
\cos \theta=\frac{C \omega_{30}}{L} \\
\dot{\varphi}=-\omega_{30} \frac{C-A}{A}
\end{array}\right\}\]

\[\begin{gathered}
L=A \dot{\psi} \\
\rightarrow \quad \omega_{30}=\frac{L}{C} \cos \theta=\frac{A}{C} \dot{\psi} \cos \theta \\
\dot{\varphi}+\frac{C-A}{A} \dot{\psi} \cos \theta=0
\end{gathered}\]

&lt;p&gt;Die letzte Gleichung enthält keine Anfangsbedingungen und stellt den kinematischen Zusammenhang (vgl. Kepplersche Gesetze) dar.&lt;br /&gt;
Die Bewegung kann wie Abrollen des körperfesten Polkegels (von außen) auf dem raumfesten Spurkegel interpretiert werden. Punkte des Körpers bewegen sich auf &lt;strong&gt;Epizykloiden&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最后一个方程不包含任何初始条件并表示运动学关系（参见开普勒定律）。
&lt;br /&gt;
该运动可以解释为固定体极锥（从外部）在固定空间轨道锥上的滚动。物体的点在&lt;strong&gt;外摆线&lt;/strong&gt;上移动&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613195029.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Auch hier kann die Bewegung wie Abrollen des körperfesten Polkegels (von innen) auf dem raumfesten Spurkegels interpretiert werden. Punkte des Körpers bewegen sich auf Perizykloiden&lt;br /&gt;
这里的运动也可以解释为刚体固定的极锥（从内部）在固定的迹锥上滚动。物体上的点沿着柏拉克罗侧线运动。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这句话描述了一种运动的解释，其中涉及到刚体固定的极锥和固定的迹锥之间的关系。具体而言，它提到了刚体固定的极锥从内部滚动在固定的迹锥上的过程。在这个过程中，物体上的点按照柏拉克罗侧线的路径进行运动。&lt;/p&gt;

  &lt;p&gt;“Perizykloiden”（柏拉克罗侧线）是一个几何学术语，指的是由一个固定圆与一个在其上滚动的小圆所形成的曲线。在这种描述中，物体上的点运动的路径类似于柏拉克罗侧线。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204331.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kräftefreier-unsymmetrischer-kreisel非对称陀螺仪&quot;&gt;Kräftefreier unsymmetrischer Kreisel.非对称陀螺仪。&lt;/h2&gt;

&lt;h3 id=&quot;der-fall-von-euler---poinsot&quot;&gt;Der Fall von Euler - Poinsot&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Euler-Poinsot陀螺，也称为Euler-Poinsot陀螺体或Euler陀螺，是一种具有特殊运动特性的刚体模型，它展示了一种被称为Euler-Poinsot情形的旋转现象。&lt;/p&gt;

  &lt;p&gt;在Euler-Poinsot情形下，刚体围绕其一个主惯性轴（也称为长轴）旋转，同时绕另外两个互相垂直的瞬时旋转轴（也称为短轴）进行进动。这种运动形式是非常特殊和复杂的，因为它涉及到刚体的自旋和进动的相互耦合。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot陀螺的运动过程中，其自旋和进动的角速度以及角动量都会发生变化。这种陀螺的稳定性和运动特性使其成为研究刚体动力学和旋转物体行为的重要示例。&lt;/p&gt;

  &lt;p&gt;Euler-Poinsot情形得名于法国数学家与物理学家Leonhard Euler和Louis Poinsot，他们在18世纪分别独立地研究和描述了这种陀螺的运动。这种情形为刚体动力学领域提供了重要的理论基础，并在许多相关学科中被广泛应用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613204539.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jetzt wir der allgemeiner Fall mit drei unterschiedlichen Hauptmassenträgheitsmomenten untersucht (triaxiales Trägheitsellipsoid):&lt;/p&gt;

&lt;p&gt;现在检查具有三个不同主要质量惯性矩的一般情况（三轴惯性椭球）：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

&lt;p&gt;Zwei Integrale des Systems sind einfach zu erkennen. Das erste Integral druck die Erhaltung
der Energie des Systems aus. In diesem Fall ist das nur die kinetische Energie des Körpers.&lt;/p&gt;

&lt;p&gt;系统的两个积分很容易辨认出来。第一个积分表示系统能量的守恒。在这种情况下，它只表示物体的动能。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}-\omega_1 \omega_2 \omega_3\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}+\omega_2 \dot{\omega}_2 J_{22}+\omega_3 \dot{\omega}_3 J_{33}=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}\right)=0 \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2
\end{aligned}\]

&lt;p&gt;Das zweite Integral druckt die Erhaltung des Drehimpulses aus:&lt;/p&gt;

&lt;p&gt;第二个积分表示角动量守恒：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_1 J_{11}-\omega_2 \omega_3\left(J_{22}-J_{33}\right)=0 \\
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \dot{\omega}_3 J_{33}-\omega_2 \omega_1\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; J_{11} \neq J_{22} \neq J_{33}
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3 J_{11}\left(J_{22}-J_{33}\right)-\omega_2 \omega_3 \omega_1 J_{22}\left(J_{33}-J_{11}\right)-\omega_3 \omega_2 \omega_1 J_{33}\left(J_{11}-J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2-\omega_1 \omega_2 \omega_3\left(J_{11} J_{22}-J_{11} J_{33}+J_{22} J_{33}-J_{22} J_{11}+J_{33} J_{11}-J_{33} J_{22}\right)=0 \\
&amp;amp; \omega_1 \dot{\omega}_1 J_{11}^2+\omega_2 \dot{\omega}_2 J_{22}^2+\omega_3 \dot{\omega}_3 J_{33}^2=0 \\
&amp;amp; \frac{d}{d t}\left(\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2\right)=0 \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \quad A \text { und } \Omega \text { sind Integrationskonstanten. }
\end{aligned}\]

&lt;p&gt;Integrationskonstanten – 积分常数&lt;/p&gt;

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：&lt;/p&gt;

\[J_{11}&amp;lt;J_{22}&amp;lt;J_{33}\]

&lt;p&gt;Aus der Definition der Parameter wird ersichtlich:&lt;/p&gt;

&lt;p&gt;参数的定义显示：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; A=\frac{A^2 \Omega^2}{A \Omega^2}=\frac{\omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2}{\omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}} \quad \rightarrow \quad J_{11} \leq A \leq J_{33} \\
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{11} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_2^2 J_{22}\left(J_{22}-J_{11}\right)+\omega_3^2 J_{33}\left(J_{33}-J_{11}\right)=A \Omega^2\left(A-J_{11}\right) \\
&amp;amp; \omega_3^2=\frac{A\left(A-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \Omega^2-\omega_2^2}_{\lambda_3^2})=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Zwecks besserer Eindeutigkeit nehmen wir folgendes Verhältnis zwischen den Parameter an:&lt;/p&gt;

&lt;p&gt;为了清楚起见，我们假设参数之间存在以下关系：
Analog bekommt man&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_1^2 J_{11}+\omega_2^2 J_{22}+\omega_3^2 J_{33}=\text { konst }=A \Omega^2 \mid \cdot J_{33} \\
&amp;amp; \omega_1^2 J_{11}^2+\omega_2^2 J_{22}^2+\omega_3^2 J_{33}^2=\text { konst }=A^2 \Omega^2 \\
&amp;amp; - \\
&amp;amp; \omega_1^2 J_{11}\left(J_{33}-J_{11}\right)+\omega_2^2 J_{22}\left(J_{33}-J_{22}\right)=A \Omega^2\left(J_{33}-A\right) \\
&amp;amp; \omega_1^2=\frac{A\left(J_{33}-A\right)}{J_{11}\left(J_{33}-J_{11}\right)} \Omega^2-\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \omega_2^2 \\
&amp;amp; \omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}(\underbrace{\frac{A\left(J_{33}-A\right)}{J_{22}\left(J_{33}-J_{22}\right)} \Omega^2}_{\lambda_1^2}-\omega_2^2)=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right)
\end{aligned}\]

&lt;p&gt;Diese Ausdrucke können wir in die letzte übriggebliebene Gleichung einsetzen:
我们可以将这些表达式代入最后剩下的等式：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \dot{\omega}_2 J_{22}-\omega_3 \omega_1\left(J_{33}-J_{11}\right)=0 \\
&amp;amp; \left.\begin{array}{l}
\omega_1^2=\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}\left(\lambda_1^2-\omega_2^2\right) \\
\omega_3^2=\frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}\left(\lambda_3^2-\omega_2^2\right)
\end{array}\right\} \\
&amp;amp; \omega_3 \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)} \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \omega_3 \omega_1= \pm \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2 J_{22}= \pm \omega_3 \omega_1\left(J_{33}-J_{11}\right) \frac{J_{22}}{\left(J_{33}-J_{11}\right)} \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp;
\end{aligned}\]

\[\begin{aligned}
&amp;amp; \dot{\omega}_2= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)} \\
&amp;amp; \frac{d \omega_2}{\sqrt{\left(\lambda_1^2-\omega_2^2\right)\left(\lambda_3^2-\omega_2^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Es wird beispielhaft der Fall $J_{22}&amp;lt;A&amp;lt;J_{33}$ untersucht. Es werden eine neue Variable und zwei neue Parameter eingeführt:&lt;/p&gt;

&lt;p&gt;在研究 $J_{22}&amp;lt;A&amp;lt;J_{33}$ 的示例情况时，引入了一个新的变量和两个新的参数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2=\lambda_1 u \\
&amp;amp; k^2=\frac{\lambda_1^2}{\lambda_3^2}=\frac{\left(J_{22}-J_{11}\right)\left(J_{33}-A\right)}{\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}&amp;lt;1 \\
&amp;amp; \frac{\lambda_1 d u}{\lambda_1 \lambda_3 \sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}= \pm \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} d t \\
&amp;amp; n=\lambda_3 \sqrt{\frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}}=\Omega \sqrt{\frac{A\left(A-J_{11}\right)}{J_{22}\left(J_{22}-J_{11}\right)} \frac{\left(J_{33}-J_{22}\right)\left(J_{22}-J_{11}\right)}{J_{11} J_{33}}} \\
&amp;amp; =\Omega \sqrt{\frac{A\left(A-J_{11}\right)\left(J_{33}-J_{22}\right)}{J_{11} J_{22} J_{33}}}
\end{aligned}\]

&lt;p&gt;Damit kommen wir zur folgenden Lösung&lt;/p&gt;

&lt;p&gt;这给我们带来了以下解决方案&lt;/p&gt;

\[\pm n\left(t-t_0\right)=\int_0^U \frac{d u}{\sqrt{\left(1-u^2\right)\left(1-k^2 u^2\right)}}\]

&lt;p&gt;Weitere Transformation führt sofort zum elliptischen Integral:&lt;/p&gt;

&lt;p&gt;进一步变换立即得到椭圆积分：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; u=\sin \Phi \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{\cos \vartheta d \vartheta}{\sqrt{1-\sin ^2 \vartheta} \sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; \pm n\left(t-t_0\right)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}=w(\Phi, k)
\end{aligned}\]

&lt;p&gt;Das ist das unvollständige elliptische Integral 1. Art. Sein Reziprok
führt auf elliptische Funktionen von Jakobi.&lt;/p&gt;

&lt;p&gt;这是第一类不完全椭圆积分，它的倒数导出Jakobi的椭圆函数。&lt;/p&gt;

&lt;p&gt;Definition (Legendre-Normalform) 定义（勒让德范式）&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reziprok davon wird als elliptische Amplitude bezeichnet&lt;/p&gt;

&lt;p&gt;这个的倒数称为椭圆振幅&lt;/p&gt;

\[w(\Phi, k)=\int_0^{\Phi} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \rightarrow \quad \Phi(w)=a m(w)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613205828.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ausgehend von dieser Funktion werden die elliptischen Funktionen
von Jacobi eingeführt:&lt;/p&gt;

&lt;p&gt;基于此函数，引入雅可比的椭圆函数：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \operatorname{sn}(w)=\sin \Phi=\sin (a m(w)) \\
&amp;amp; c n(w)=\cos \Phi=\cos (a m(w)) \\
&amp;amp; d n(w)=\sqrt{1-k^2 \sin ^2 \Phi}=\sqrt{1-k^2 \operatorname{sn}^2(w)}
\end{aligned}\]

&lt;p&gt;Sie werden als &lt;strong&gt;sinus amplitudinis&lt;/strong&gt;, &lt;strong&gt;cosinus amplitudinis&lt;/strong&gt; und  &lt;strong&gt;delta amplitudinis&lt;/strong&gt; bezeichnet.&lt;/p&gt;

&lt;p&gt;Diese Funktionen sind periodisch mit der Periode, die vom Parameter k abhängig ist. Die Abhängigkeit hängt mit dem kompletten elliptischen Integral zusammen:&lt;/p&gt;

&lt;p&gt;它们被称为&lt;strong&gt;正弦波&lt;/strong&gt;、&lt;strong&gt;余弦波&lt;/strong&gt;和&lt;strong&gt;三角波&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这些函数是周期性的，周期取决于参数 k。 依赖关系与完全椭圆积分有关：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; K(k)=\int_0^{\frac{\pi}{2}} \frac{d \vartheta}{\sqrt{\left(1-k^2 \sin ^2 \vartheta\right)}} \\
&amp;amp; d n(w+2 K)=d n(w) \\
&amp;amp; \operatorname{sn}(w+4 K)=\operatorname{sn}(w) \\
&amp;amp; c n(w+4 K)=c n(w) \\
&amp;amp; s n^2(w)+c n^2(w)=1
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210148.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210206.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210222.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210241.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mithilfe dieser Funktionen können wir die Komponenten der Winkelgeschwindigkeit sofort bestimmen:&lt;/p&gt;

&lt;p&gt;使用这些函数，我们可以立即确定角速度的分量：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; \omega_2= \pm \lambda_1 \operatorname{sn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \sqrt{\lambda_1^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_1= \pm \sqrt{\frac{J_{22}\left(J_{33}-J_{22}\right)}{J_{11}\left(J_{33}-J_{11}\right)}} \lambda_1 \operatorname{cn}\left(n\left(t-t_0\right)\right) \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \sqrt{\lambda_3^2-\omega_2^2} \quad \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 \sqrt{1-k^2 s^2\left(n\left(t-t_0\right)\right)} \rightarrow \\
&amp;amp; \omega_3= \pm \frac{J_{22}\left(J_{22}-J_{11}\right)}{J_{33}\left(J_{33}-J_{11}\right)} \lambda_3 d n\left(n\left(t-t_0\right)\right) \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;Kinematische Teilaufgabe führt sofort zu einer weiteren Quadratur.
运动学子任务立即导致另一个正交。&lt;/p&gt;

\[\begin{aligned}
&amp;amp; L \sin \varphi \sin \theta=J_{11} \omega_1 \\
&amp;amp; L \cos \varphi \sin \theta=J_{22} \omega_2 \\
&amp;amp; L \cos \theta=J_{33} \omega_3 \\
&amp;amp; \theta=\arccos \left(\frac{J_{33} \omega_3}{L}\right) \\
&amp;amp; \tan \varphi=\frac{J_{11} \omega_1}{J_{22} \omega_2} \rightarrow \quad \varphi=\arctan \left(\frac{J_{11} \omega_1}{J_{22} \omega_2}\right)
\end{aligned}\]

&lt;p&gt;Für Winkel $\varphi$ bleibt eine Differentialgleichung 1. Ordnung, die bei Bedarf integriert werden kann:&lt;/p&gt;

&lt;p&gt;角度 $\varphi$ 的一阶微分方程仍然存在，必要时可以对其进行积分：&lt;/p&gt;

\[\dot{\psi} \cos \theta+\dot{\varphi}=\omega_3 \quad \rightarrow \quad \dot{\psi}=\frac{\omega_3-\dot{\varphi}}{\cos \theta}=L \frac{J_{11} \omega_1^2+J_{11} \omega_2^2}{J_{11}^2 \omega_1^2+J_{22}^2 \omega_2^2}\]

&lt;p&gt;Der zweite Fall $J_{11}&amp;lt;A&amp;lt;J_{22}$ kann analog untersucht werden.&lt;/p&gt;

&lt;p&gt;第二种情况$J_{11}&amp;lt;A&amp;lt;J_{22}$可以类推.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230613210643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Qualitativer Charakter der Bewegung:&lt;/p&gt;

&lt;p&gt;Ein rotationssymmetrischer Körper bewegt sich so, dass der Nutationswinkel konstant bleibt. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse bleiben auch konstant.&lt;/p&gt;

&lt;p&gt;Bei einem nicht rotationssymmetrischen Körper (einem dreiachsigen Ellipsoid) wird das alles gestört. Die Geschwindigkeiten der Präzession und der Drehung um die eigene Achse werden zeitvariabel. Auch der Nutationswinkel wird zeitveränderlich, aber alle kinematischen Größen der Bewegung können in geschlossener Form (aber nicht in elementaren Funktionen) bestimmt werden.&lt;/p&gt;

&lt;p&gt;运动的定性特征：&lt;/p&gt;

&lt;p&gt;对于一个具有旋转对称性的物体，其运动使得进动角保持恒定。进动和自转的速度也保持恒定。&lt;/p&gt;

&lt;p&gt;然而，对于一个非旋转对称的物体（如一个三轴椭球体），这些特性会受到扰动。进动和自转的速度将随时间变化。进动角度也会随时间变化。尽管如此，运动的所有运动学量可以以闭合形式（但不是基本函数）确定&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/TM4-03/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/TM4-03/</guid>
        
        <category>专业</category>
        
        <category>工程力学</category>
        
        
      </item>
    
      <item>
        <title>汽车视觉 Automotive Vision -SLAM</title>
        <description>&lt;head&gt;
&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;script&gt;
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;], [&apos;\\(&apos;, &apos;\\)&apos;]],
    packages: [&apos;base&apos;, &apos;newcommand&apos;, &apos;configMacros&apos;]
  },
  svg: {
    fontCache: &apos;global&apos;
  }
};
&lt;/script&gt;

&lt;script&gt; 
MathJax = {
  tex: {
    inlineMath: [[&apos;$&apos;, &apos;$&apos;]],
    processEscapes: true
  }
};
&lt;/script&gt;

&lt;h1 id=&quot;chapter-6-self-localization-and-mapping&quot;&gt;Chapter 6: Self-Localization and Mapping&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sebastian Thrun, Wolfram Burgard, Dieter Fox, Probabilistic Robotics. MIT Press,
2005, Chapter 7-13 (partly)&lt;/li&gt;
  &lt;li&gt;Hugh Durrant-Whyte, Tim Bailey, Simultaneous Localization and Mapping: Part I,
IEEE Robotics and Automation Magazine, 13(2), pg. 99-110, 2006&lt;/li&gt;
  &lt;li&gt;Tim Bailey, Hugh Durrant-Whyte, Simultaneous Localization and Mapping: Part II,
IEEE Robotics and Automation Magazine, 13(3), pg. 108-117, 2006&lt;/li&gt;
  &lt;li&gt;Bruno Siciliano, Khatib Oussama (Hrsg.), Springer Handbook of Robotics, Springer,
2008, Chapter 37&lt;/li&gt;
  &lt;li&gt;Joachim Hertzberg, Kai Lingemann, Andreas Nüchter, Mobile Roboter – Eine
Einführung aus Sicht der Informatik, Springer 2012, Chapters 5+6&lt;/li&gt;
  &lt;li&gt;Ingemar J. Cox, Blanche – an Experiment in Guidance and Navigation of an
Autonomous Robot Vehicle. IEEE Transactions on Robots and Automation, 7(2),
pg. 193-204, 1991&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Self Localization 自定位&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;self localization problem 自定位问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;environment is known (map) 环境是已知的&lt;/li&gt;
  &lt;li&gt;vehicle position and orientation are unkonown 车辆位置和方向未知&lt;/li&gt;
  &lt;li&gt;vehicle observes the (local) environment 车辆观察（本地）环境&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612161042.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;localization-with-landmarks-地标定位&quot;&gt;Localization with landmarks 地标定位&lt;/h2&gt;

&lt;h3 id=&quot;landmarks-地标&quot;&gt;landmarks 地标：&lt;/h3&gt;

&lt;p&gt;consistently identifiable points in the world. E.g. lighthouses, feature points in imaging&lt;/p&gt;

&lt;p&gt;一直可以被识别的点，例如灯塔、图像中的特征点&lt;/p&gt;

&lt;p&gt;#### what can we conclude from… 2d：我们可以从…中得出什么结论 ?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the distance to a given landmark?到一个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position on a circle&lt;/li&gt;
      &lt;li&gt;unknown orientatioin&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between two landmarks?到两个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;2 possible positons&lt;/li&gt;
      &lt;li&gt;unknown orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the distance between three landmarks?到三个给定地标的距离？
    &lt;ul&gt;
      &lt;li&gt;robot position(some exceptions are possible)机器人位置（可能有一些例外）&lt;/li&gt;
      &lt;li&gt;orientationo unknown&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162130.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the angle, from which a landmark is being observed 地标的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;positon unknown&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162831.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the angle from which two landmarks are being observed? 两个地标之间的角度已经被观测到
    &lt;ul&gt;
      &lt;li&gt;robot position on an arc or line segment 圆弧或线段上的机器人位置&lt;/li&gt;
      &lt;li&gt;relation between &lt;em&gt;position&lt;/em&gt; and &lt;em&gt;orientation&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;approch: inscribed angle theorem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612162950.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;linear-landmarks-线性地标&quot;&gt;linear landmarks 线性地标&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;例如： roadway lines, curbs, and walls 道路线、路缘和墙壁&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612163335.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;what-can-we-conclude-from-我们可以从中得出什么结论-&quot;&gt;what can we conclude from… ：我们可以从…中得出什么结论 ?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;the orthogonal distance,in which a line is being observed 观测一条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;position on two parallel lines 两条平行线&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the orthogonal distance to two lines 两条线的垂直距离
    &lt;ul&gt;
      &lt;li&gt;4 points / 2 points&lt;/li&gt;
      &lt;li&gt;relation between position and orientation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612164044.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;one-shot-localization-一次性定位算法&quot;&gt;One-Shot Localization 一次性定位算法&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;“One-Shot Localization” 是指在&lt;strong&gt;仅有一次观测&lt;/strong&gt;或信息的情况下进行定位或位置估计的过程。它是指通过&lt;strong&gt;一次观测或一次输入&lt;/strong&gt;，从未知位置或环境中准确地确定目标的位置或姿态。在传感器技术和机器人领域中，这个术语通常用于描述使用单个数据样本进行&lt;strong&gt;位置估计&lt;/strong&gt;的方法或算法。这种方法可能利用传感器数据、图像处理技术或其他信息源来实现目标的定位。与传统的迭代定位算法相比，One-Shot Localization 着重于通过单次观测尽可能准确地确定目标的位置，从而减少计算和时间成本。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;给定：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a map with a set of landmarks&lt;/li&gt;
  &lt;li&gt;a set of boserved landmarks from seen from a vehicle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;任务：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;how do I have to shift and rotate the vehicle so that the observed landmarks match best the land marks in the map?&lt;/li&gt;
  &lt;li&gt;我如何移动和旋转车辆，以便观察到的地标与地图中的地标最匹配？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165012.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;数学方法：mathematically&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;which movement (translation + rotation) transforms &lt;em&gt;vehicle coordinates&lt;/em&gt; into &lt;em&gt;world coordinates&lt;/em&gt; such that observed &lt;strong&gt;landmark positions fit to map position&lt;/strong&gt;?&lt;/li&gt;
  &lt;li&gt;哪种运动（平移+旋转）将&lt;em&gt;车辆坐标&lt;/em&gt;转换为&lt;em&gt;世界坐标&lt;/em&gt;，以便观察到的&lt;strong&gt;地标位置适配到地图位置&lt;/strong&gt;？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612165001.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;landmark positions in world coordinates (map) 世界坐标中的地标位置（地图）：&lt;/li&gt;
&lt;/ul&gt;

\[\vec{p_{1}},\cdots,\vec{p_{i}},...\]

&lt;ul&gt;
  &lt;li&gt;observed landmark positions in vehicle coordinates 在车辆坐标中观察到的地标位置:&lt;/li&gt;
&lt;/ul&gt;

\[\vec{q}_{1},\cdot\cdot\cdot,\vec{q}_{i},\cdot\cdot\cdot,\vec{q}_{N}\]

&lt;ul&gt;
  &lt;li&gt;optimization problem:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612182552.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最小化下面的式子：minimize&lt;/li&gt;
&lt;/ul&gt;

\[E(R,\bar{t})=\frac{1}{N}\sum_{i=1}^{N}||\vec{p_{i}}-(R\vec{q_{i}}+\vec{t})||^{2}\]

&lt;p&gt;with：&lt;/p&gt;

\[\begin{aligned}
&amp;amp; E(R, \vec{t})=\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}+\bar{p}-\left(R\left(\vec{q}_i^{\prime}+\bar{q}\right)+\vec{t}\right)\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right)+(\bar{p}-R \bar{q}-\vec{t})\right\|^2 \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+\frac{2}{N} \sum_{i=1}^N(\bar{p}-R \bar{q}-\vec{t})^T\left(\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\|\bar{p}-R \bar{q}-\vec{t}\|^2+2(\bar{p}-R \bar{q}-\vec{t})^T\left(\frac{1}{N} \sum_{i=1}^N \vec{p}_i^{\prime}-R \frac{1}{N} \sum_{i=1}^N \vec{q}_i^{\prime}\right) \\
&amp;amp; =\frac{1}{N} \sum_{i=1}^N\left\|\vec{p}_i^{\prime}-R \vec{q}_i^{\prime}\right\|^2+\underbrace{\|\bar{p}-R \bar{q}-\vec{t}\|^2} \\
&amp;amp; =0 \quad \underbrace{N}_{=0} \\
&amp;amp; \Rightarrow \vec{t}=\bar{p}-R \bar{q} \\
&amp;amp; =\left\|\vec{p}_i^{\prime}\right\|^2+\left\|\vec{q}_i^{\prime}\right\|^2-2\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime} \\
&amp;amp;
\end{aligned}\]

&lt;p&gt;最大化：&lt;/p&gt;

&lt;p&gt;$\sum_{i=1}^N\left(\vec{p}_i^{\prime}\right)^T R \vec{q}_i^{\prime}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不同的方法，例如 SVD：&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{i=1}^{N}\left(\vec{p}_{i}^{\prime}\right)^{T} R \vec{q}_{i}^{\prime}=\sum_{i=1}^{N} \operatorname{Tr}\left(R \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\right)=\operatorname{Tr}(R H) \quad \text { with } H=\sum_{i=1}^{N} \vec{q}_{i}^{\prime}\left(\vec{p}_{i}^{\prime}\right)^{T}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;mathematical theorem (singular value decomposition, SVD):
for every real matrix H exist orthogonal matrices U,V, and a diagonal matrix D with nonnegative entries, such that:
数学定理（奇异值分解，SVD）：对于每个实数矩阵 H，存在正交矩阵 U、V 和具有非负项的对角矩阵 D，使得：$H=U D V^{T}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;solution：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612190302.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

\[(Derivation and proof: K.S.Arun, T.S.Hunang, S.D.Blostein, Least Squares Fitting of Two 3-D Point Sets,
IEEE Transactions on Pattern Analysis and Machine Intelligence 9(5), 1987)\]

&lt;ul&gt;
  &lt;li&gt;what to do if landmarks are not uniquely identifiable?如果地标不是唯一可识别的怎么办？
    &lt;ul&gt;
      &lt;li&gt;$\vec{q_{i}}\ \mathrm{\bf~might~rester~to~any~of}\ \ \vec{p_{1}},\ …,\vec{p_{i}},…$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;brute force solution: try all possible combinations 蛮力解决方案：尝试所有可能的组合
    &lt;ul&gt;
      &lt;li&gt;computationally too expensive 计算成本太高&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;iterative, greedy assignments: 迭代，贪婪的分配：
    &lt;ul&gt;
      &lt;li&gt;$\text { assign } \vec{q}_i \text { to closest landmark among } \vec{p}_1, \ldots, \vec{p}_i, \ldots$&lt;/li&gt;
      &lt;li&gt;reassign all observations incrementally 逐步重新分配所有观察结果&lt;/li&gt;
      &lt;li&gt;👉 ICP algorithm 迭代最近算法&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;icp-algorithm-三维点云配准&quot;&gt;ICP algorithm 三维点云配准&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;ICP（Iterative Closest Point）算法是一种迭代的点云配准算法，用于将两个或多个点云之间进行对齐和匹配。它是一种常用的三维点云配准算法，在计算机视觉、机器人和地图构建等领域得到广泛应用。&lt;/p&gt;

  &lt;p&gt;ICP算法的基本思想是通过迭代的方式，将待配准的目标点云与参考点云对齐，使它们在空间中尽可能重合。算法的核心是找到两个点云之间的最佳刚性变换（旋转和平移），使得它们的重叠部分最大化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230612192547.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Iterative Closest Point (ICP)(Besl, McKay 1992)
    &lt;ul&gt;
      &lt;li&gt;calculates rotation $R$ and translation $\overrightarrow{t}$ in order to transform a set of points $Q$ onto another set of points $P$ 计算旋转矩阵 $R$ 和平移向量 $\overrightarrow{t}$，以将点集 $Q$ 变换到另一个点集 $P$&lt;/li&gt;
      &lt;li&gt;ICP always terminates ICP总是终止&lt;/li&gt;
      &lt;li&gt;ICP converges to local minimum of &lt;br /&gt; 收敛到局部最小值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[E(R,\vec{t})\longrightarrow\frac{1}{N}\sum_{i=1}^{N}\,||\vec{p}_{j}(i)-\left(R\vec{q}_{i}+\vec{t}\right)||^{2}\]

&lt;ul&gt;
  &lt;li&gt;简要证明
    &lt;ul&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 8 assuming fixed assignments between points 根据结构，在步骤8中，$E(R,\overrightarrow{t})$是最小化的，假设点之间有固定的分配。&lt;/li&gt;
      &lt;li&gt;by construction, $E(R,\overrightarrow{t})$ is minimized in step 4 assuming fixed translation and rotation 根据结构，在步骤4中，假设固定的平移和旋转，$E(R,\overrightarrow{t})$被最小化了&lt;/li&gt;
      &lt;li&gt;hence, $E(R,\overrightarrow{t})$ never increases&lt;/li&gt;
      &lt;li&gt;since number of possible assignments is finite, we cannot generate new
permutations in step 4 from a certain point on (pigeonhole/Dirichlet principle) 由于可能的分配数量是有限的，我们不能在第 4 步中从某个点生成新的排列（pigeonhole/Dirichlet principle）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;incremental-localization-增量本地化&quot;&gt;Incremental Localization 增量本地化&lt;/h2&gt;

&lt;h2 id=&quot;mapping-映射&quot;&gt;Mapping 映射&lt;/h2&gt;

&lt;h2 id=&quot;simultaneous-localization-and-mappingslam&quot;&gt;Simultaneous Localization and Mapping(SLAM)&lt;/h2&gt;
</description>
        <pubDate>Mon, 12 Jun 2023 00:00:00 +0200</pubDate>
        <link>https://wenboli-cn-de.github.io/2023/06/SLAM/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2023/06/SLAM/</guid>
        
        <category>专业</category>
        
        <category>汽车视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第二部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习&quot;&gt;深度学习&lt;/h1&gt;

&lt;h2 id=&quot;语义分割和目标检测-semantic-segmentation-and-object-detection&quot;&gt;语义分割和目标检测 (Semantic Segmentation and Object Detection)&lt;/h2&gt;

&lt;h3 id=&quot;场景标注-scene-labeling&quot;&gt;场景标注 Scene Labeling&lt;/h3&gt;

&lt;p&gt;分割图像&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类每个像素&lt;/li&gt;
  &lt;li&gt;自动编码器/解码器结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111358.png&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自：J. Long、E. Shelhamer、T. Darrell，“用于语义分割的全卷积网络”，CVPR，2015&lt;/center&gt;

&lt;h3 id=&quot;实例标签-instance-labeling&quot;&gt;实例标签 Instance Labeling&lt;/h3&gt;

&lt;p&gt;语义标签不提供对象边界！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310111731.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;想法：将方向标记为对象中心&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112000.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;摘自: J. Uhrig, M. Cordts, U. Franke, T. Brox, Pixel-level
encoding and depth layering for instance-level semantic
segmentation, Germ. Conf. on Pattern Recognition, 2016/
provided by Nick Schneider, Daimler AG&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;C:\Users\Wenbo Li\AppData\Roaming\Typora\typora-user-images\image-20220310112145711.png&quot; alt=&quot;image-20220310112145711&quot; /&gt;&lt;/p&gt;

&lt;center&gt;video provided by Nick Schneider, Daimler AG  &lt;/center&gt;

&lt;h3 id=&quot;区域生成网络region-proposal-networks&quot;&gt;区域生成网络Region Proposal Networks&lt;/h3&gt;

&lt;p&gt;Region Proposal Network，直接翻译是“&lt;strong&gt;区域生成网络&lt;/strong&gt;”，通俗讲是“筛选出可能会有目标的框”。其本质是基于滑窗的无类别object检测器，输入是任意尺度的图像，输出是一系列矩形候选区域。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112344.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112421.png&quot; style=&quot;zoom: 68%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310112445.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们在哪里可以找到哪些对象？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将图像划分为单元&lt;/li&gt;
  &lt;li&gt;在每个单元中应用区域生成网络&lt;/li&gt;
  &lt;li&gt;改变划分的单元大小以处理更大/更小的对象&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;深度学习技术&quot;&gt;深度学习技术&lt;/h3&gt;

&lt;p&gt;没有比更多数据更重要的数据了！&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的严格验证&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;训练过程的正则化&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;– 提前停止&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 权重衰减/L2 正则化&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– dropout&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 随机梯度下降&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 多任务学习&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 使用预训练网络&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;– 损失函数&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重用 （他人的）实践知识&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的网络结构&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;– 成功的培训过程&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;训练期间的典型错误进展&quot;&gt;训练期间的典型错误进展&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113429.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么早期停止作为正则化技术起作用？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提前停止更倾向小权重&lt;/li&gt;
  &lt;li&gt;小权重意味着几乎没有非线性&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;小权重正则化&quot;&gt;小权重正则化&lt;/h4&gt;

&lt;p&gt;假设感知器的绝对权重较小&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113609.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113743.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;小权重促进感知器的线性行为&lt;/p&gt;

&lt;p&gt;假设具有线性激活的全连接网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310113904.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→感知器的线性行为降低了非线性表达性&lt;/p&gt;

&lt;p&gt;→正则化&lt;/p&gt;

&lt;h3 id=&quot;权重衰减l2-正则化-weight-decay--l2-regularisation&quot;&gt;权重衰减/L2-正则化 Weight Decay / L2-Regularisation&lt;/h3&gt;

&lt;p&gt;通过正则化规则扩大训练目标&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过在训练期间随机关闭感知器进行正则化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114520.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dropout 迫使神经网络以分布式方式存储相关信息&lt;/p&gt;

&lt;p&gt;dropout 减少过拟合&lt;/p&gt;

&lt;h3 id=&quot;梯度下降的修正&quot;&gt;梯度下降的修正&lt;/h3&gt;

&lt;h4 id=&quot;随机梯度下降&quot;&gt;&lt;strong&gt;随机梯度下降&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310114745.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;加速&lt;/li&gt;
  &lt;li&gt;减少一点过拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;动量梯度下降&quot;&gt;&lt;strong&gt;动量梯度下降&lt;/strong&gt;&lt;/h4&gt;

\[\begin{aligned}
\Delta \vec{w} &amp;amp; \leftarrow \alpha \cdot \Delta \vec{w}-\varepsilon \cdot \frac{\partial}{\partial \vec{w}} \sum_{j \in S} \operatorname{err}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right), \vec{t}^{(j)}\right) \\
\vec{w} \leftarrow \vec{w}+\Delta \vec{w}
\end{aligned}\]

&lt;p&gt;用一个α&amp;gt;0参数来控制后续步骤的一致性&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在平坦区域加速&lt;/li&gt;
  &lt;li&gt;减少曲折&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;多任务学习-multi-task-learning&quot;&gt;多任务学习 Multi Task Learning&lt;/h3&gt;

&lt;p&gt;想法：在单个网络示例中学习多个相关任务：&lt;/p&gt;

&lt;p&gt;场景标记+实例标记+深度估计&lt;/p&gt;

&lt;p&gt;scene labeling + instance labeling + depth estimation&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115128.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;强制网络在隐藏层中开发共同特征&lt;/li&gt;
  &lt;li&gt;减少对单个任务的过度拟合&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;预训练特征网络的使用&quot;&gt;&lt;strong&gt;预训练特征网络的使用&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;想法：重用预训练的网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115236.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用大型训练集训练其他任务&lt;/li&gt;
  &lt;li&gt;丢弃其他任务的分类层&lt;/li&gt;
  &lt;li&gt;为新任务创建新的分类层&lt;/li&gt;
  &lt;li&gt;训练新分类层的权重，同时保留特征层&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;输出层和损失函数-output-layers-and-loss-functions&quot;&gt;输出层和损失函数 Output Layers and Loss Functions&lt;/h3&gt;

&lt;p&gt;损失函数将网络输出与期望的输出进行比较&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115431.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（回归任务）：期望的输出应该是实数&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用线性激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用平方误差，即&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[\operatorname{err}(\vec{y}, \vec{t})=\|\vec{y}-\vec{t}\|^{2}\]

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;情况（分类任务）：期望的输出应该是类别标签&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;在输出层使用softmax激活函数&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;使用交叉熵误差 cross entropy error&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310115748.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;不平衡训练集的变体&quot;&gt;不平衡训练集的变体&lt;/h3&gt;

&lt;p&gt;对于严重不平衡的训练集（即每个类的示例数量不相等），训练可能会失败&lt;/p&gt;

&lt;p&gt;引入加权因子来补偿不平衡&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120231.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;来自深度学习工具箱的其他技术&quot;&gt;来自深度学习工具箱的其他技术&lt;/h2&gt;

&lt;h3 id=&quot;生成对抗网络-gan-generative-adversarial-networks-gan&quot;&gt;生成对抗网络 (GAN) Generative Adversarial Networks (GAN)&lt;/h3&gt;

&lt;p&gt;我们可以使用深度网络生成逼真的图像吗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120527.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120601.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;生成网络应该学会生成逼真的图像&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;鉴别性网络应该学习如何区分图像是真实的还是生成的。&lt;/li&gt;
  &lt;li&gt;训练：两个网络都是零和游戏中的竞争对手&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;应用领域： • 图像渲染 • 域适应 • 为分类器生成（附加）训练数据&lt;/p&gt;

&lt;h3 id=&quot;序列处理sequence-processing&quot;&gt;序列处理Sequence Processing&lt;/h3&gt;

&lt;p&gt;我们如何处理序列，例如 视频序列？&lt;/p&gt;

&lt;p&gt;(1) 多通道输入层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120707.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有在以下情况下才有可能&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2)图像单独处理+拼接层&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;短序列&lt;/li&gt;
  &lt;li&gt;固定长度的序列&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(3) 图像的单独处理+附加层（深度集）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310120924.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;只有当&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;图像的顺序并不重要&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(4)递归网络&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121006.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121023.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;学习算法：通过时间进行反向传播&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;问题：梯度消失&lt;/li&gt;
  &lt;li&gt;解决方案：用适当的处理单元（GRU、LSTM）取代网络C中的感知器。
适当的处理单元(GRU, LSTM)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;循环单元-grulstm-recurrent-units-grulstm&quot;&gt;循环单元 (GRU+LSTM) Recurrent Units (GRU+LSTM)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;实现简单状态机的专用单元&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;状态从不通过双曲切线的逻辑函数→来传递
没有消失的梯度&lt;/li&gt;
  &lt;li&gt;内部结构有几个控制信息流的闸门&lt;/li&gt;
  &lt;li&gt;使用感知器机制打开/关闭闸门&lt;/li&gt;
  &lt;li&gt;LSTM：更早（1997年），更复杂（需要5个感知器）。&lt;/li&gt;
  &lt;li&gt;GRU：较新（2014年），门数较少，参数较少（需要3个感知器）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;门控循环单元-gru&quot;&gt;门控循环单元 (GRU)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121136.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;长短期记忆单元-lstm&quot;&gt;长短期记忆单元 (LSTM)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310121153.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-深度学习(第一部分) Deep Learning</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;深度学习-deep-learning&quot;&gt;深度学习 Deep Learning&lt;/h1&gt;

&lt;h2 id=&quot;多层感知器multi-layer-perceptrons--mlp&quot;&gt;多层感知器Multi-Layer Perceptrons  （MLP）&lt;/h2&gt;

&lt;p&gt;MLP 是高度参数化的非线性函数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094040.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;示例：图像分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$\vec{x}$   特征向量，例如 图像中所有灰度值的向量&lt;/p&gt;

&lt;p&gt;$\vec{y}$  1-of-q-vector 为 q 个可能类别中的每一个建模概率，例如 笑脸是快乐/悲伤/沮丧&lt;/p&gt;

&lt;p&gt;感知器, 感知机&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094519.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094543.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;许多感知器的分层排列：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310094857.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;网络结构创建了一组高度非线性的函数&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;许多权重&lt;/li&gt;
  &lt;li&gt;深层架构：通常 &amp;gt;5 个隐藏层&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们如何确定 MLP 的权重？&lt;/p&gt;

&lt;p&gt;– 基本思想：最小化训练样例的误差&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095152.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解决&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p} \operatorname{err}\left(f_{M L P} ^ {\vec{w} }\left(\vec{x}^ {(j)}\right), \vec{t}^ {(j)}\right)\]

&lt;p&gt;用于适当的误差测量（损失函数）&lt;/p&gt;

&lt;p&gt;for appropriate error measure (loss function)&lt;/p&gt;

&lt;p&gt;算法：梯度下降（反向传播）&lt;/p&gt;

&lt;h2 id=&quot;梯度下降反向传播gradient-descent-backpropagation&quot;&gt;梯度下降（反向传播）Gradient Descent (Backpropagation)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：&lt;/p&gt;

\[\underset{\vec{w}} {\operatorname{minimize}} g(\vec{w}) \text { with } g(\vec{w}):=\sum_{j=1}^{p} \operatorname{err}\left(f_{M L P}^{\vec{w} }\left(\vec{x}^{(j)}\right), \bar{t}^{(j)}\right)\]

&lt;p&gt;&lt;strong&gt;算法&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用小数字随机初始化权重 $\vec{w}$&lt;/li&gt;
  &lt;li&gt;计算梯度 $\frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;以小的学习率$\varepsilon&amp;gt;0$更新权重 $\varepsilon&amp;gt;0\vec{w} \leftarrow \vec{w}-\varepsilon \frac{\partial g(\vec{w})}{\partial \vec{w}}$&lt;/li&gt;
  &lt;li&gt;转到 第2步 直到达到停止标准&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310095811.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;改进： – 稍后讨论&lt;/p&gt;

&lt;h2 id=&quot;训练-mlp传统方法training-mlps-traditional-methods&quot;&gt;训练 MLP（传统方法）Training MLPs (traditional methods)&lt;/h2&gt;

&lt;p&gt;传统训练方法的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重太多，训练样例太少&lt;/li&gt;
  &lt;li&gt;太慢&lt;/li&gt;
  &lt;li&gt;数值问题，局部最小值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;👉过拟合、欠拟合、泛化不足&lt;/p&gt;

&lt;p&gt;克服问题的传统技术：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;正则化（例如提前停止、权重衰减、贝叶斯学习）&lt;/li&gt;
  &lt;li&gt;模式预处理、特征提取、降维&lt;/li&gt;
  &lt;li&gt;选择更小的 MLP、更少的层、更少的隐藏神经元、网络修剪&lt;/li&gt;
  &lt;li&gt;用其他方法替换神经网络 （例如 SVM、boosting 等）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;深度学习&quot;&gt;深度学习&lt;/h2&gt;

&lt;p&gt;深度学习有什么不同的？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更大的训练集（数百万而不是数百）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;更强大的计算机，多核 CPU 和 GPU 上的并行实现&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特殊网络结构&lt;/p&gt;

    &lt;p&gt;自编码器&lt;/p&gt;

    &lt;p&gt;卷积网络&lt;/p&gt;

    &lt;p&gt;循环网络/LSTM&lt;/p&gt;

    &lt;p&gt;(深度信念网络/受限玻尔兹曼机)&lt;/p&gt;

    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;权重共享 weight sharing&lt;/li&gt;
  &lt;li&gt;逐层学习 layer-wise learning&lt;/li&gt;
  &lt;li&gt;Dropout&lt;/li&gt;
  &lt;li&gt;有用特征的学习 learning of useful features&lt;/li&gt;
  &lt;li&gt;从无标签的例子中学习 learning from unlabeled examples&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;特征学习&quot;&gt;特征学习&lt;/h3&gt;

&lt;p&gt;观察：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;许多像素并没有提供太多的信息&lt;/li&gt;
  &lt;li&gt;相邻的像素是高度相关的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例：笑脸&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102320.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们如何将相关信息与无关信息分开？&lt;/p&gt;

&lt;h3 id=&quot;自动编码器-autoencoder&quot;&gt;自动编码器 Autoencoder&lt;/h3&gt;

&lt;p&gt;👉具有这种结构的 MLP&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310102549.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学习识别功能：&lt;/p&gt;

\[\operatorname{minimize}_{\vec{w}} \sum_{j=1}^{p}\left(f_{M L P}^{\vec{w}}\left(\vec{x}^{(j)}\right)-\vec{x}^{(j)}\right)^{2}\]

&lt;p&gt;隐蔽层必须分析压缩图像内容的神经主成分的种类&lt;/p&gt;

&lt;h3 id=&quot;堆叠自动编码器-stacked-autoencoders&quot;&gt;堆叠自动编码器 Stacked Autoencoders&lt;/h3&gt;

&lt;p&gt;多层自动编码器的增量训练&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;训练具有单个隐藏层的自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103140.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103247.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;通过附加隐藏层扩展自动编码器&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103315.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103412.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;类似地重复过程以添加更多隐藏层&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;👉信息压缩逐层增加非线性、多层主成分分析&lt;/p&gt;

&lt;h3 id=&quot;用于分类的堆叠自动编码器&quot;&gt;用于分类的堆叠自动编码器&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;训练堆叠自动编码器&lt;/li&gt;
  &lt;li&gt;用全连接分类器网络替换解码器网络&lt;/li&gt;
  &lt;li&gt;训练分类器网络&lt;/li&gt;
  &lt;li&gt;训练编码器和分类器网络的所有权重进行几次迭代&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103608.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;堆叠式自动编码器可以使用未标记的示例进行训练&lt;/li&gt;
  &lt;li&gt;增量训练获得更好的结果&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;局部感受野local-receptive-fields&quot;&gt;局部感受野Local Receptive Fields&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%84%9F%E5%8F%97%E9%87%8E/8989338&quot;&gt;感受野是什么&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28492837&quot;&gt;深度神经网络中的感受野(Receptive Field)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;评论里有句话：convNets(cnn)每一层输出的特征图(feature map)上的像素点在原始图像上映射的区域大小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310103920.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部感受野迫使网络在本地处理信息。&lt;/p&gt;

&lt;p&gt;示例：图像的局部特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104631.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;权值共享--weight-sharing&quot;&gt;权值共享  Weight Sharing&lt;/h3&gt;

&lt;p&gt;权值共享就是说，给一张输入图片，用一个&lt;a href=&quot;https://baike.baidu.com/item/卷积核/3377590&quot;&gt;卷积核&lt;/a&gt;去扫这张图，卷积核里面的数就叫权重，这张图每个位置是被同样的卷积核扫的，所以&lt;a href=&quot;https://baike.baidu.com/item/权重/10245966&quot;&gt;权重&lt;/a&gt;是一样的，也就是共享。&lt;/p&gt;

&lt;p&gt;我们可以为所有像素生成相同的局部特征吗？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;权重共享：绑定不同感知器的权重&lt;/li&gt;
  &lt;li&gt;卷积层：绑定一层所有感知器的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310104849.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;多通道特征层multi-channel-feature-layers&quot;&gt;多通道特征层Multi-Channel Feature Layers&lt;/h3&gt;

&lt;p&gt;在每个隐藏层中，想为每个像素计算几个不同的特征 → &lt;u&gt;多通道层&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310105353.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积核是大小$h×w×k$的&lt;a href=&quot;https://baike.baidu.com/item/%E5%BC%A0%E9%87%8F/380114&quot;&gt;张量&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;最大池化max-pooling&quot;&gt;最大池化Max-Pooling&lt;/h3&gt;

&lt;p&gt;池化层旨在在空间上聚合信息&lt;/p&gt;

&lt;p&gt;池化（Pooling）是卷积神经网络中的一个重要的概念，它实际上是一种形式的降采样。有多种不同形式的非线性池化函数，而其中“最大池化（Max pooling）”是最为常见的。它是将输入的图像划分为若干个矩形区域，对每个子区域输出最大值。直觉上，这种机制能够有效的原因在于，在发现一个特征之后，它的精确位置远不及它和其他特征的相对位置的关系重要。池化层会不断地减小数据的空间大小，因此参数的数量和计算量也会下降，这在一定程度上也控制了过拟合。通常来说，CNN的卷积层之间都会周期性地插入池化层。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Max-Pooling：从局部感受野计算最大值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110253.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;池化通常与降低层的分辨率相结合&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110357.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;卷积网络convolutional-networks&quot;&gt;卷积网络Convolutional Networks&lt;/h3&gt;

&lt;p&gt;卷积神经网络（CNN）结合了&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;卷积层&lt;/li&gt;
  &lt;li&gt;池化层&lt;/li&gt;
  &lt;li&gt;全连接分类器网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110454.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;例如：Alexnet是2012年Imagenet竞赛的冠军模型，准确率达到了57.1%, top-5识别率达到80.2%。&lt;/p&gt;

&lt;p&gt;AlexNet包含5个卷积层和3个&lt;a href=&quot;https://so.csdn.net/so/search?q=全连接层&amp;amp;spm=1001.2101.3001.7020&quot;&gt;全连接层&lt;/a&gt;，模型示意图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从层到层… – 特征在几何上变得越来越复杂 – 特征变得越来越独立于位置 – 特征变得越来越独立于图案大小 – 特征变得越来越具体&lt;/p&gt;

&lt;h3 id=&quot;resnet层-resnet-layers&quot;&gt;ResNet层 ResNet Layers&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220310110832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV12.0/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV12.0/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-模式识别(第二部分) Pattern Recognition</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;模式识别&quot;&gt;模式识别&lt;/h1&gt;

&lt;h2 id=&quot;组合方法-ensemble-methods&quot;&gt;组合方法 Ensemble Methods&lt;/h2&gt;

&lt;p&gt;如果想解决分类问题，应该怎么做？&lt;/p&gt;

&lt;p&gt;– 创建专家：训练分类器&lt;/p&gt;

&lt;p&gt;– 训练几个分类器 → 并构建一个组合&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;集成学习归属于机器学习，他是一种「训练思路」，并不是某种具体的方法或者算法。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;现实生活中，大家都知道「人多力量大」，「3 个臭皮匠顶个诸葛亮」。而集成学习的核心思路就是「人多力量大」，它并没有创造出新的算法，而是把已有的算法进行结合，从而得到更好的效果。&lt;/p&gt;

&lt;p&gt;那组合怎么工作？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309112402.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;k分类器 $c_{1}, c_{2}, \ldots, c_{k}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将相同的模式应用于所有分类器 → k 个预测&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\begin{array}{c}
c_{1}(\vec{x}) \in{-1,+1} &lt;br /&gt;
c_{2}(\vec{x}) \in{-1,+1} &lt;br /&gt;
c_{k}(\vec{x}) \in{-1,+1}
\end{array}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;总结所有预测并与零进行比较：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\operatorname{ensemble}(\vec{x})=\operatorname{sign}\left(\sum_{j=1}^{k} c_{j}(\vec{x})\right)$&lt;/p&gt;

&lt;p&gt;最好的四种数字识别方法:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– (2) “线拟合”特征：99.7%&lt;/li&gt;
  &lt;li&gt;– (3) 像素值：99.4%&lt;/li&gt;
  &lt;li&gt;– (4) HOG 特征：99.7%&lt;/li&gt;
  &lt;li&gt;– (5) Haar 特征：99.4%&lt;/li&gt;
  &lt;li&gt;– (6) LBP 特征：99.3%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些方法的组合会共享错误（在 1000 个测试示例中）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309112824.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在实验数字识别中, 组合这些方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、像素、Haar&lt;/p&gt;

    &lt;p&gt;错误率：5/1000 • 成员错误：3、6、6/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、HOG、Haar&lt;/p&gt;

    &lt;p&gt;错误率：1/1000&lt;/p&gt;

    &lt;p&gt;成员错误：3、3、6/1000&lt;/p&gt;

    &lt;p&gt;具有联合特征的 SVM 错误：2/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合：线拟合、HOG、LBP&lt;/p&gt;

    &lt;p&gt;错误率 1/1000&lt;/p&gt;

    &lt;p&gt;成员错误：3、3、7/1000&lt;/p&gt;

    &lt;p&gt;具有联合特征的 SVM 错误：5/1000&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组合所有
错误率 1/1000&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;什么时候组合更有利？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最佳情况：分类器不共享错误&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;组合错误：0&lt;/li&gt;
  &lt;li&gt;每个分类器的错误：100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309113528.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最差情况：分类器共享所有错误&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;组合错误：150&lt;/li&gt;
  &lt;li&gt;每个分类器的错误：100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以关键问题就是：&lt;strong&gt;避免分类器共享错误&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接下来引入：Boosting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;训练相互依赖的分类器&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;u&gt;第 n+1 号分类器&lt;/u&gt; 应该专注于被&lt;em&gt;&lt;u&gt;第 1...n号分类器&lt;/u&gt;&lt;/em&gt;   &lt;strong&gt;错误分类&lt;/strong&gt; 的例子&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boosting&quot;&gt;Boosting&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;实现思路：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一、加权训练模式：为每个训练模式引入权重$\gamma_{i} \geq 0$以模拟其重要性&lt;/p&gt;

&lt;p&gt;→ 有必要修改训练算法，例如soft margin SVM。&lt;/p&gt;

&lt;p&gt;$\underset{\vec{w}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{w}|^{2}+C \sum_{i}\left(\gamma_{i} \cdot \xi_{i}\right)$
subject to $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1-\xi_{i} \quad$ for all $i$ $\xi_{i} \geq 0 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;如何确定模式权重？
→ 训练分类器后重新计算权重。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;增加被错误分类的模式的权重&lt;/li&gt;
  &lt;li&gt;降低分类良好的模式的权重&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;实现思路：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;二、 加权表决&lt;/p&gt;

&lt;p&gt;为每个分类器引入权重$\beta_{k} \geq 0$以模拟其可靠性&lt;/p&gt;

&lt;p&gt;→ 修改投票方案：&lt;/p&gt;

&lt;p&gt;$\operatorname{ensemble}(\vec{x})=\operatorname{sign}\left(\sum_{k} \beta_{k} \cdot \text { vote }_{k}\right)$&lt;/p&gt;

&lt;p&gt;如何确定投票权重？&lt;/p&gt;

&lt;p&gt;→根据分类器的性能选择权重：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类器权重大，准确率高&lt;/li&gt;
  &lt;li&gt;权重小，分类器准确率低&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309115611.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;adaboost算法&quot;&gt;AdaBoost算法&lt;/h4&gt;

&lt;p&gt;Boosting是一种集合技术，试图从许多弱分类器中创建一个强分类器。这是通过从训练数据构建模型，然后创建第二个模型来尝试从第一个模型中纠正错误来完成的。添加模型直到完美预测训练集或添加最大数量的模型。&lt;/p&gt;

&lt;p&gt;AdaBoost是第一个为二进制分类开发的真正成功的增强算法。这是理解助力的最佳起点。现代助推方法建立在AdaBoost上，最着名的是随机梯度增强机。&lt;/p&gt;

&lt;p&gt;Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。&lt;/p&gt;

&lt;p&gt;算法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309115745.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AdaBoost 的特性：&lt;/p&gt;

&lt;p&gt;集成的训练误差由以下限制：&lt;/p&gt;

\[\prod_{t=1}^{T}\left(2 \sqrt{\epsilon_{t}\left(1-\epsilon_{t}\right)}\right) \leq \exp \left\{-2 \sum_{t=1}^{T}\left(\frac{1}{2}-\epsilon_{t}\right)^{2}\right\}\]

&lt;p&gt;如果 所有的$\epsilon_{t} \leq \lambda&amp;lt;\frac{1}{2}$ 和$T \rightarrow \infty$ AdaBoost 会产生一个完美的分类器&lt;/p&gt;

&lt;h4 id=&quot;haar分类器&quot;&gt;Haar分类器&lt;/h4&gt;

&lt;p&gt;概括来说:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Haar分类器=Haar-like特征+AdaBoost算法+级联+积分图快速计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;(1) Haar 特性&lt;/p&gt;

&lt;p&gt;$s=\frac{1}{N_{\text {red }}} \sum_{(u, v) \in \text { red area }} g(u, v)-\frac{1}{N_{\text {blue }}} \sum_{(u, v) \in \text { blue area }} g(u, v)$&lt;/p&gt;

&lt;p&gt;(2) 制作分类器&lt;/p&gt;

&lt;p&gt;$c(s)=\operatorname{sign}(z \cdot(s-\theta))$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121157.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参数：&lt;/p&gt;

&lt;p&gt;$\theta \in \mathbb{R}$ 阈值&lt;/p&gt;

&lt;p&gt;$z \in{+1,-1}$ 方向&lt;/p&gt;

&lt;p&gt;(3)从加权示例训练分类器：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;尝试 θ 和 z 的所有可能值&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择最小化加权误差的值&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\sum_{s_{i}&amp;lt;\theta, d^{(i)}=z} \gamma_{i}+\sum_{s_{i}&amp;gt;\theta, d^{(i)}=-z} \gamma_{i}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121411.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(4)具有多种功能的 Haar 分类器：&lt;/p&gt;

&lt;p&gt;​	分类器在一组选项中选择一个 Haar 特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121537.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;boosting-结合haar分类器&quot;&gt;Boosting 结合Haar分类器&lt;/h4&gt;

&lt;p&gt;Idea：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(1) 将 AdaBoost 与 Haar 分类器一起使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数字识别任务的测试错误：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个分类器：56/1000&lt;/li&gt;
  &lt;li&gt;集合大小 5：54/1000&lt;/li&gt;
  &lt;li&gt;集合大小 50：16/1000&lt;/li&gt;
  &lt;li&gt;集合大小 200：10/1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121744.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309121756.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2)每个特征产生一个分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;例如 像素灰度&lt;/p&gt;

&lt;p&gt;数字识别任务的测试错误：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个分类器：193/1000&lt;/li&gt;
  &lt;li&gt;集合大小 5：90/1000&lt;/li&gt;
  &lt;li&gt;集合大小 50：24/1000&lt;/li&gt;
  &lt;li&gt;集合大小 200：18/1000&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309122153.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309122208.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;平衡错误&quot;&gt;平衡错误&lt;/h5&gt;

&lt;p&gt;组合分类器：$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless 0$&lt;/p&gt;

&lt;p&gt;延伸：$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless \delta$&lt;/p&gt;

&lt;p&gt;δ &amp;gt; 0 ：仅当非常确定时才分类为positive&lt;/p&gt;

&lt;p&gt;δ &amp;lt; 0 ：即使不确定，也可以将其归为positive&lt;/p&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;p&gt;具有 Haar 功能的 AdaBoost，组合大小为5&lt;/p&gt;

&lt;p&gt;$\sum_{k}\left(\beta_{k} \cdot c_{k}(\vec{x})\right) \gtrless \delta$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123029.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成. 假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片，那么在这个任务中，飞机就是正例，大雁就是反例。&lt;/p&gt;

&lt;p&gt;现在做如下的定义：
True positives : 飞机的图片被正确的识别成了飞机。
True negatives: 大雁的图片没有被识别出来，系统正确地认为它们是大雁。
False positives: 大雁的图片被错误地识别成了飞机。
False negatives: 飞机的图片没有被识别出来，系统错误地认为它们是大雁。&lt;/p&gt;

&lt;p&gt;Precision其实就是在识别出来的图片中，True positives所占的比率：&lt;/p&gt;

&lt;p&gt;$precision = \frac{tp}{tp+fp} = \frac{tp}{n}$&lt;/p&gt;

&lt;p&gt;其中的n代表的是(True positives + False positives)，也就是系统一共识别出来多少照片 。&lt;/p&gt;

&lt;p&gt;$recall = \frac{tp}{tp+fn}$&lt;/p&gt;

&lt;p&gt;Recall 是被正确识别出来的飞机个数与测试集中所有飞机的个数的比值。&lt;/p&gt;

&lt;p&gt;Recall的分母是(True positives + False negatives)，这两个值的和，可以理解为一共有多少张飞机的照片。&lt;/p&gt;

&lt;h4 id=&quot;搜索对象-searching-for-objects&quot;&gt;搜索对象 Searching for Objects&lt;/h4&gt;

&lt;p&gt;我们如何使用分类器在图像中找到对象？&lt;/p&gt;

&lt;p&gt;– 例如 在字母上找到数字“1”；使用“1”的分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123827.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309123945.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;想法：&lt;/p&gt;

&lt;p&gt;将分类器应用于所有图像中所有可能的区域&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;改变区域的位置&lt;/li&gt;
  &lt;li&gt;改变区域的大小&lt;/li&gt;
  &lt;li&gt;改变区域的方向（可选择）。
→ 需要数百万次的试验
效率如何？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;改进的想法：&lt;/p&gt;

&lt;p&gt;使用两个分类器&lt;/p&gt;

&lt;p&gt;分类器1&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;高效&lt;/li&gt;
  &lt;li&gt;不准确&lt;/li&gt;
  &lt;li&gt;高召回率&lt;/li&gt;
  &lt;li&gt;低精度&lt;/li&gt;
  &lt;li&gt;适用于所有领域&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分类器2&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;低效率&lt;/li&gt;
  &lt;li&gt;精度&lt;/li&gt;
  &lt;li&gt;高召回率&lt;/li&gt;
  &lt;li&gt;高精度&lt;/li&gt;
  &lt;li&gt;适用于由分类器1发现的区域&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;想法可以扩展到一系列许多分类器 → &lt;strong&gt;Viola/Jones 算法&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;violajones-approach&quot;&gt;Viola/Jones Approach&lt;/h5&gt;

&lt;p&gt;结合：&lt;/p&gt;

&lt;p&gt;– Haar 分类器&lt;/p&gt;

&lt;p&gt;– AdaBoost&lt;/p&gt;

&lt;p&gt;– 增加集合大小的分类器系列（“级联”）&lt;/p&gt;

&lt;p&gt;– 调整集合以最大化召回率&lt;/p&gt;

&lt;p&gt;– 搜索具有不同区域位置和大小的整个图像&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309124646.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;violajones算法举例&quot;&gt;Viola/Jones算法举例&lt;/h5&gt;

&lt;p&gt;人脸识别&lt;/p&gt;

&lt;p&gt;轮廓线检测&lt;/p&gt;

&lt;h3 id=&quot;决策树decision-trees&quot;&gt;决策树：Decision Trees&lt;/h3&gt;

&lt;p&gt;决策树。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;树状结构，分支因子2&lt;/li&gt;
  &lt;li&gt;内部节点：二进制分类器&lt;/li&gt;
  &lt;li&gt;叶子结点：类标签&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125041.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从训练示例创建决策树:&lt;/p&gt;

&lt;p&gt;创建具有未知类标签的叶节点作为根节点。&lt;/p&gt;

&lt;p&gt;将所有训练示例分配给它.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125151.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125211.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309125440.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;哪些分类器是合适的？&lt;/p&gt;

&lt;p&gt;– 一般来说：全部&lt;/p&gt;

&lt;p&gt;– 类似的想法，例如 boosting：&lt;/p&gt;

&lt;p&gt;通过组合简单分类器创建一个复杂分类器，即阈值分类器: 如使用 Haar 分类器进行数字识别&lt;/p&gt;

&lt;p&gt;数字识别决策树：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309130254.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;改进决策树的技术&quot;&gt;改进决策树的技术&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;正则化技术Regularization techniques:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;机器学习中的一个核心问题是设计不仅在训练集上误差小，而且在新样本上泛化能力好的算法。许多机器学习算法都需要采取相应的策略来减少测试误差，这些策略被统称为正则化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 早期止损&lt;/strong&gt;
在构建树时使用验证集。当你在验证集上观察到非递减的错误时，停止分割节点。
你观察到验证集上的错误没有减少。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;例如：数字识别的验证误差是。
深度为1的树为54
深度为2的树为37
深度3的树为29
深度4的树为29
深度5的树为29
深度为7的树为36
深度为7的树为37
→ 取深度为3的树&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2.修剪&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先创建完整的决策树。 之后去除不平衡或病态的分支。&lt;/p&gt;

&lt;p&gt;• 几个修剪标准&lt;/p&gt;

&lt;p&gt;• 已经应用过，例如 在决策树算法 C4.5&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.随机决策树和森林&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;u&gt;通过以下方式随机创建决策树&lt;/u&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;随机选择训练数据的子集&lt;/li&gt;
  &lt;li&gt;随机选择作为下一次拆分选项的特征子集&lt;/li&gt;
  &lt;li&gt;随机选择区分阈值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;u&gt;构建许多随机树的集合：&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;→ 随机决策森林&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建决策森林&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 使用 Haar 特征&lt;/p&gt;

&lt;p&gt;– 随机选择特征和阈值（在 k 个试验中最好）&lt;/p&gt;

&lt;p&gt;– 训练集没有变化&lt;/p&gt;

&lt;p&gt;– 允许深度树&lt;/p&gt;

&lt;p&gt;– 改变集合大小 n&lt;/p&gt;

&lt;p&gt;测试集错误：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131242.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用早期停止训练的决策树：29&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AdaBoost 集成&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;大小 5：54&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;大小 50：16&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;大小 200：10&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SVM：6&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;结合多类别分类器的决策树&quot;&gt;结合多类别分类器的决策树&lt;/h4&gt;

&lt;p&gt;扩展到两个以上的类：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131610.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;训练分类器以最小化叶节点中的香农熵&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131637.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309131849.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;熵衡量模式集的同质性&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;所有模式属于同一类：熵最小 (0)&lt;/li&gt;
  &lt;li&gt;相同数量的模式属于每个类：熵最大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309134356.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV8.2/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV8.2/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-模式识别(第一部分) Pattern Recognition</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;模式识别-pattern-recognition&quot;&gt;模式识别 Pattern Recognition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308165314.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分类：将对象分配到类别（classes）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;维基百科：&lt;/p&gt;

&lt;p&gt;模式识别，就是通过计算机用数学技术方法来研究模式的自动处理和判读。我们把环境和客体统称为“模式”。随着计算机技术的发展，人类有可能研究复杂的信息处理过程。&lt;/p&gt;

&lt;p&gt;信息处理过程的一个重要形式是生命体对环境及客体的识别。&lt;/p&gt;

&lt;p&gt;以光学字元识别之“汉字识别”为例：首先将汉字图像进行处理，抽取主要表达特征并将特征与汉字的代码存在计算机中。就像老师教我们“这个字叫什么、如何写”记在大脑中。这一过程叫做“训练”。识别过程就是将输入的汉字图像经处理后与计算机中的所有字进行比较，找出最相近的字就是识别结果。这一过程叫做“匹配”。&lt;/p&gt;

&lt;p&gt;我们如何区分物体？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;几何特征，如长宽比、圆度，……。&lt;/li&gt;
  &lt;li&gt;颜色特征，如主要色调、平均
饱和度，颜色的差异性，…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从实例中学习&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;收集物体的图像&lt;/li&gt;
  &lt;li&gt;为每个物体创建一个特征向量（”模式”）。&lt;/li&gt;
  &lt;li&gt;找到一个决策规则来区分不同类别的特征向量之间的类别&lt;/li&gt;
  &lt;li&gt;从实例模式中创建一个决策规则的过程，决策规则的过程被称为 “学习”或 “训练”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;许多方法用于决策规则和学习&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线性分类器&lt;/li&gt;
  &lt;li&gt;人工神经网络/深度学习&lt;/li&gt;
  &lt;li&gt;基于原型的方法&lt;/li&gt;
  &lt;li&gt;基于案例的推理&lt;/li&gt;
  &lt;li&gt;决策树&lt;/li&gt;
  &lt;li&gt;支持向量机&lt;/li&gt;
  &lt;li&gt;boosting算法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本次我们讨论：
&lt;strong&gt;线性分类器，支持向量机，boosting，决策树，深度学习&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;线性分类器linear-classification&quot;&gt;线性分类器：Linear Classification&lt;/h2&gt;

&lt;p&gt;线性分类器是以下类型的函数：&lt;/p&gt;

&lt;p&gt;$\vec{x} \mapsto \begin{cases}+1 &amp;amp; \text { if }\langle\vec{x}, \vec{w}\rangle+b \geq 0 \ -1 &amp;amp; \text { otherwise }\end{cases}$&lt;/p&gt;

&lt;p&gt;$\vec{w}$是线性分类器的权向量&lt;/p&gt;

&lt;p&gt;$b$是分类器的偏置权重&lt;/p&gt;

&lt;p&gt;线性分类器将&lt;strong&gt;输入空间&lt;/strong&gt;细分为&lt;strong&gt;两个半空间&lt;/strong&gt;。 决策边界是一个超平面&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308190140.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学习任务：&lt;/p&gt;

&lt;p&gt;给定一组训练样例：&lt;/p&gt;

\[\left\{\left(\vec{x}^{(1)}, d^{(1)}\right), \ldots,\left(\vec{x}^{(p)}, d^{(p)}\right)\right\}\]

&lt;p&gt;$d^{(i)}=+1$属于一类的例子（“positive examples”）&lt;/p&gt;

&lt;p&gt;$d^{(i)}=-1$对于属于另一类的示例（“negative examples”）&lt;/p&gt;

&lt;p&gt;寻找 $\vec{w}$和 使其：&lt;/p&gt;

&lt;p&gt;$d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right)&amp;gt;0 \quad$ for all $i \in{1, \ldots, p}$$&lt;/p&gt;

&lt;p&gt;许多可能的解决方案，哪一个是最好的？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308190736.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;g 和 h，两者都不会产生分类错误&lt;/li&gt;
  &lt;li&gt;g 与模式的距离比 h 短&lt;/li&gt;
  &lt;li&gt;g 新模式的错误分类风险大于 h&lt;/li&gt;
  &lt;li&gt;（未知）类概率分布的支持类似于&lt;a href=&quot;https://baike.baidu.com/item/%E5%87%B8%E5%8C%85/179150&quot;&gt;凸包&lt;/a&gt; 训练示例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;边距：超平面和训练模式的凸包之间的最小距离&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\rho=\min _{i}\left(d^{(i)} \cdot \frac{\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b}{|\vec{w}|}\right)$&lt;/p&gt;

&lt;h2 id=&quot;支持向量机-svm&quot;&gt;支持向量机 SVM&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;支持向量机 (SVM)&lt;/strong&gt; ：support vector machine (SVM) ： &lt;strong&gt;最大化边距&lt;/strong&gt;的线性分类器&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308192211.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;支持向量机 (SVM)——训练 SVM 意味着解决：&lt;/p&gt;

&lt;p&gt;$\begin{array}{ll}\underset{\rho, \vec{w}, b}{\operatorname{maximise}} &amp;amp; \rho^{2} \ \text { subject to } &amp;amp; d^{(i)} \cdot \frac{\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b}{|\vec{w}|} \geq \rho \quad \text { for all } i \ &amp;amp; \rho&amp;gt;0\end{array}$&lt;/p&gt;

&lt;p&gt;一个自由度：$|\vec{w}|$&lt;/p&gt;

&lt;p&gt;简化：&lt;/p&gt;

&lt;p&gt;$|\vec{w}|=\frac{1}{\rho}$&lt;/p&gt;

&lt;p&gt;$\underset{\vec{w}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{w}|^{2}$
subject to $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;一个简单的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308192733.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模式是一维的：&lt;/p&gt;

&lt;p&gt;正的：5，10；&lt;/p&gt;

&lt;p&gt;负的：-1，2&lt;/p&gt;

&lt;p&gt;参数：$\vec{w_1},b$&lt;/p&gt;

&lt;p&gt;最优化问题：&lt;/p&gt;

&lt;p&gt;$\underset{w_{1}, b}{\operatorname{minimise}} \frac{1}{2} w_{1}^{2}$&lt;/p&gt;

&lt;p&gt;使其：&lt;/p&gt;

&lt;p&gt;$b \geq 1-5 w_{1}$
$b \geq 1-10 w_{1}$
$b \leq-1+w_{1}$
$b \leq-1-2 w_{1}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308193206.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是如何训练一个SVM呢？&lt;/p&gt;

&lt;p&gt;$\operatorname{minimise}_{\vec{w}, b} \frac{1}{2}|\vec{w}|^{2}$
使其 $d^{(i)} \cdot\left(\left\langle\vec{x}^{(i)}, \vec{w}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;…跳过所有细节…&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 应用拉格朗日乘数理论&lt;/p&gt;

&lt;p&gt;– 每个训练模式一个拉格朗日乘数&lt;/p&gt;

&lt;p&gt;– 解决方案完全由拉格朗日乘数描述&lt;/p&gt;

&lt;p&gt;– 许多拉格朗日乘数为零&lt;/p&gt;

&lt;p&gt;– 存在计算拉格朗日乘数的算法&lt;/p&gt;

&lt;p&gt;解决方案：&lt;/p&gt;

&lt;p&gt;• 由支持向量确定的最优分离超平面&lt;/p&gt;

&lt;p&gt;• 移除非支持向量不会改变解&lt;/p&gt;

&lt;p&gt;• 添加距离大于边距的模式不会改变解&lt;/p&gt;

&lt;p&gt;• 移除支持向量会改变解&lt;/p&gt;

&lt;p&gt;• 添加距离小于边距的模式会改变解&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308204325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;容错svm-fault-tolerant-svms&quot;&gt;容错SVM Fault-tolerant SVMs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;重叠的类迫使制造错误&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;人为错误$\xi_{i}$&lt;/p&gt;

&lt;p&gt;冲突的目标：&lt;/p&gt;

&lt;p&gt;使 $\rho$最大化，使$\xi_{i}$ 最小化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205120.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最优化问题：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205248.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;C&amp;gt;0：正则化参数控制小误差和大余量之间的平衡（必须手动选择）&lt;/p&gt;

&lt;p&gt;容错 SVM 被称为“soft-margin-SVMs”（与“hard-margin-SVMs”相反）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;hard-margin-SVMs有类似的解决方案&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;支持向量是产生单个错误或位于边缘区域边界上的所有模式&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205416.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;非线性svm-nonlinear-svms&quot;&gt;非线性SVM Nonlinear SVMs&lt;/h3&gt;

&lt;p&gt;具有非重叠支持的类可能不是线性可分的 → &lt;strong&gt;非线性分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 直接方式：使用圆形/椭圆/非线性曲线进行分类 → 难以分析&lt;/p&gt;

&lt;p&gt;• 间接方式：非线性变换数据并改为对变换后的数据进行分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205512.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;非线性问题可能在非线性变换后变为线性问题&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308205543.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设非线性变换&lt;/p&gt;

\[\Phi:\left\{\begin{array}{l}\mathbb{R}^{n} \rightarrow \mathbb{R}^{m} \\ \vec{x} \mapsto \Phi(\vec{x})=\vec{X}\end{array}\right.\]

&lt;p&gt;找到解决问题的 SVM：&lt;/p&gt;

&lt;p&gt;$\underset{\vec{W}, b}{\operatorname{minimise}} \frac{1}{2}|\vec{W}|^{2}$
subject to $d^{(i)} \cdot\left(\left\langle\vec{X}^{(i)}, \vec{W}\right\rangle+b\right) \geq 1 \quad$ for all $i$&lt;/p&gt;

&lt;p&gt;在知道拉格朗日乘数的情况下，解决方案完全确定：&lt;/p&gt;

&lt;p&gt;– 不需要计算&lt;/p&gt;

&lt;p&gt;– 模式仅作为点积的参数成对出现&lt;/p&gt;

\[\left\langle\vec{X}^{(i)}, \vec{X}^{(j)}\right\rangle=\left\langle\Phi\left(\vec{x}^{(i)}\right), \Phi\left(\vec{x}^{(j)}\right)\right\rangle\]

&lt;p&gt;考虑到：$\left\langle\Phi\left(\vec{x}^{(i)}\right), \Phi\left(\vec{x}^{(j)}\right)\right\rangle$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308210103.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;快捷方式：核函数$K(\vec{x}, \vec{y})=\langle\Phi(\vec{x}), \Phi(\vec{y})\rangle$&lt;/p&gt;

&lt;p&gt;通过$\phi$ 消除$K(\vec{x}, \vec{y})$ 来代替$\langle\Phi(\vec{x}), \Phi(\vec{y})\rangle$&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://baike.baidu.com/item/%E6%A0%B8%E5%87%BD%E6%95%B0/4693132&quot;&gt;核函数&lt;/a&gt;是隐藏复杂性的肮脏技巧吗？&lt;/p&gt;

&lt;p&gt;例如：$\Phi(x)=\left(\begin{array}{c}x^{2} \ x\end{array}\right)$&lt;/p&gt;

&lt;p&gt;•评估 Φ(x) 和 Φ(y) 需要 2 次乘法&lt;/p&gt;

&lt;p&gt;•评估特征空间中的点积需要 2 次乘法和 1 次加法，总共：4 次乘法和 1 次加法&lt;/p&gt;

&lt;p&gt;$K(x, y)=\langle\Phi(x), \Phi(y)\rangle=(x y)^{2}+(x y)$&lt;/p&gt;

&lt;p&gt;•评估核函数需要 2 次乘法和 1 次加法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一些内核基于无限维的希尔伯特空间&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一些有用的核函数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;点积：$K(\vec{x}, \vec{y})=\langle\vec{x}, \vec{y}\rangle$&lt;/li&gt;
  &lt;li&gt;多项式核函数：$K(\vec{x}, \vec{y})=(\langle\vec{x}, \vec{y}\rangle)^{q}$ or $(\langle\vec{x}, \vec{y}\rangle+1)^{q}$&lt;/li&gt;
  &lt;li&gt;径向基函数 (RBF) 内核 $K(\vec{x}, \vec{y})=e^{-\frac{|\vec{x}-\vec{y}|^{2}}{2 \sigma^{2}}}$&lt;/li&gt;
  &lt;li&gt;直方图交叉核（仅适用于直方图特征）&lt;/li&gt;
&lt;/ul&gt;

\[K(\vec{x}, \vec{y})=\sum_{i} \min \left\{x_{i}, y_{i}\right\}\]

&lt;p&gt;内核参数必须手动设置&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;现在结合所有想法：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;支持向量机最大化边距以最小化错误分类的风险&lt;/li&gt;
  &lt;li&gt;软边距支持向量机允许个别错误。 由参数 C 控制边距大小和误差之间的平衡&lt;/li&gt;
  &lt;li&gt;核函数允许在不改变理论框架的情况下进行非线性分类。 内核类型和内核参数控制非线性程度&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;使用svms&quot;&gt;使用SVMs&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;应用SVM：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308211640.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;训练SVM：&lt;/p&gt;

    &lt;p&gt;我们如何确定 C 和内核？&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308211921.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;评估svm&quot;&gt;评估SVM&lt;/h4&gt;

&lt;p&gt;错误分类的风险 = “false negative”的风险 + “false positive  ”的风险&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308212031.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;E 未知，但可以从样本集中近似&lt;/p&gt;

&lt;p&gt;$E \approx \frac{n_{f n}+n_{f p}}{n}$&lt;/p&gt;

&lt;p&gt;– 样本集中的元素数量&lt;/p&gt;

&lt;p&gt;– 样本集中的假阳误报数量&lt;/p&gt;

&lt;p&gt;– 样本集中的假阴误报数量&lt;/p&gt;

&lt;p&gt;• 验证是在样本集（“测试集”、“验证集”）上测试分类器性能的过程&lt;/p&gt;

&lt;p&gt;• 选择测试集上误分类率最小的 SVM&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;• 测试集必须独立于训练集！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;• 验证允许比较使用不同 C 值和不同内核训练的 SVM 的性能&lt;/p&gt;

&lt;h4 id=&quot;交叉验证-cross-validation&quot;&gt;交叉验证 Cross Validation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213208.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;• 验证过程的缺点：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;– 仅部分数据用于训练

– 仅部分数据用于验证
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;• k -fold 交叉验证&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;– 想法：用不同的训练和验证集重复训练/验证过程几次

–  k 是重复次数（介于 2 和模式数之间）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;K-fold交叉验证法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将模式集细分为K个大小相同的不相干子集&lt;/li&gt;
  &lt;li&gt;对每个子集j重复。
2.1 从子集1,…,j-1,j+1,…k训练SVM
2.2. 评估子集j的错误分类率&lt;/li&gt;
  &lt;li&gt;平均错误分类率&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;p&gt;– 所有模式都用于验证&lt;/p&gt;

&lt;p&gt;– 训练集包含一定比例$\frac{k-1}{k}$的模式&lt;/p&gt;

&lt;p&gt;如果 k 等于模式总数 → leave-one-out-error&lt;/p&gt;

&lt;p&gt;例子 3-fold-cross-validation  ：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213511.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在参数空间中搜索最优参数的可能性，例如&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308213542.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;应该听说过的一些概念：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;过度拟合：分类器在训练数据上表现良好，但在验证或测试数据上表现不佳&lt;/li&gt;
  &lt;li&gt;欠拟合：分类器在训练和验证数据上表现不佳&lt;/li&gt;
  &lt;li&gt;泛化：从训练示例中学习一个概念 也适用于测试数据，而不仅仅是记住训练示例&lt;/li&gt;
  &lt;li&gt;正则化：“帮助”过度拟合的分类器来提高泛化能力&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;实验-数字识别&quot;&gt;实验： 数字识别&lt;/h4&gt;

&lt;p&gt;对手写数字的图像进行分类（美国邮政编码）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309085545.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简化任务：分类——图像显示数字“1”——图像不显示数字“1”&lt;/p&gt;

&lt;p&gt;在这里：&lt;/p&gt;

&lt;p&gt;– 用于训练和验证：500 个“1”图像，500 个“no-1”图像&lt;/p&gt;

&lt;p&gt;– 用于测试：500 个“1”图像，500 个“not-1”数据集图像&lt;/p&gt;

&lt;h5 id=&quot;第一种方法-2-dimensional-patterns&quot;&gt;第一种方法 2-dimensional patterns&lt;/h5&gt;

&lt;p&gt;– 二维模式&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;平均灰度值&lt;/li&gt;
  &lt;li&gt;纵横比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;– 模式重新调整为区间 [-1, +1]&lt;/p&gt;

&lt;p&gt;– 带 RBF 内核的软边距 SVM&lt;/p&gt;

&lt;p&gt;– 5-fold交叉验证&lt;/p&gt;

&lt;p&gt;– 参数空间中的网格搜索：&lt;/p&gt;

&lt;p&gt;$10^{-5} \leq C \leq 10^{15}$(on log scale)&lt;/p&gt;

&lt;p&gt;$-  10^{-3} \leq \sigma \leq 10^{15} $(on log scale)&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：93.1% − 测试集：80.3%&lt;/p&gt;

&lt;p&gt;支持向量数：167（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309093927.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第二种方法-添加第三个特征&quot;&gt;第二种方法 添加第三个特征&lt;/h5&gt;

&lt;p&gt;– 添加第三个特征：拟合线到暗像素的平均距离&lt;/p&gt;

&lt;p&gt;– 准确度： - 交叉验证：98.5% - 测试集：98.7%&lt;/p&gt;

&lt;p&gt;支持向量的数量：95（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5&quot;&gt;混淆矩阵&lt;/a&gt;: (Confusion matrix)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094500.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094606.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第二种方法改进-找到连通分量-ccl-并屏蔽除最大段以外的所有部分&quot;&gt;第二种方法改进 找到连通分量 (CCL) 并屏蔽除最大段以外的所有部分&lt;/h5&gt;

&lt;p&gt;– 找到连通分量 (CCL) 并屏蔽除最大段以外的所有部分&lt;/p&gt;

&lt;p&gt;– 从预处理图像计算特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094647.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：98.5% − 测试集：99.7%&lt;/p&gt;

&lt;p&gt;支持向量数：95（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094804.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第三种方法-统一缩放图片&quot;&gt;第三种方法 统一缩放图片&lt;/h5&gt;

&lt;p&gt;– 将所有图像的大小调整为 28x28 像素，并使用像素的灰度值作为特征&lt;/p&gt;

&lt;p&gt;→ 784-维模式&lt;/p&gt;

&lt;p&gt;准确率：- 交叉验证：99.0% - 测试集：98.7%&lt;/p&gt;

&lt;p&gt;支持向量数量：220（1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309094957.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第三种方法改进-只使用一部分像素&quot;&gt;第三种方法改进 只使用一部分像素&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;观察：很多像素不影响分类，例如 边界像素&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;仅使用所有像素的子集，例如 24x18 子区域 → 432 维图案&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095209.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;准确度：- 交叉验证：99.0% - 测试集：99.4%&lt;/p&gt;

&lt;p&gt;支持向量数：219（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095130.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095151.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;第四种方法-hog-features&quot;&gt;第四种方法 HOG-features&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;HOG-features&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;– 定向梯度直方图 (Dalal&amp;amp;Triggs, 2005)&lt;/p&gt;

&lt;p&gt;使用梯度信息而不是灰度级&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309095854.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309100002.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309100115.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;HOG 排列 4 个相邻单元的归一化块:&lt;/p&gt;

\[\vec{V}_{1}=(\underbrace{2,5,1,0,0,0,0,0,}_{\text {from cell } 1} \underbrace{0,17,13,0,0,5,8,0}_{\text {from cell } 2}, \underbrace{15,0,0,0,0,0,0,7}_{\text {from cell } 5}, \underbrace{0,2,4,3,2,3,2,12}_{\text {from cell } 6})\]

&lt;p&gt;规范化描述符：&lt;/p&gt;

\[\vec{V}_{1}^{n o r m}=\frac{\vec{V}_{1}}{\left\|\vec{V}_{1}\right\|+\epsilon}\]

&lt;p&gt;组装所有块的描述符：&lt;/p&gt;

\[\vec{V}=\left(\vec{V}_{1}^{\text {norm }}, \ldots, \vec{V}_{9}^{\text {norm }}\right)\]

&lt;p&gt;将向量$\vec{V}$应用于 SVM&lt;/p&gt;

&lt;p&gt;第四种方法： – 仅使用 HOG 特征 → 288 维模式&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：99.4% − 测试集：99.7%&lt;/p&gt;

&lt;p&gt;支持向量的数量：174（共 1000 个）&lt;/p&gt;

&lt;h5 id=&quot;第五种方法-哈尔特征-haar-features&quot;&gt;第五种方法 哈尔特征 Haar features&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/哈尔特征&quot;&gt;哈尔特征&lt;/a&gt;（Haar features）&lt;/p&gt;

&lt;p&gt;哈尔特征使用检测窗口中指定位置的相邻矩形，计算每一个矩形的像素和并取其差值。然后用这些差值来对图像的子区域进行分类。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101607.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较矩形区域的灰度，即红色区域的平均灰度减去蓝色区域的平均灰度。&lt;/p&gt;

&lt;p&gt;Haar特征在一定程度上反应了图像灰度的局部变化。&lt;/p&gt;

&lt;p&gt;在人脸检测中，脸部的一些特征可由矩形特征简单刻画，例如，眼睛比周围区域的颜色要深，鼻梁比两侧颜色要浅等。&lt;/p&gt;

&lt;p&gt;有很多可能的特征&lt;/p&gt;

&lt;p&gt;边缘特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101642.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;线特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101716.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;棋盘特征：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101752.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;中心环绕特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101840.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对角线方向的特征&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309101903.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 计算哈尔特征&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;简单的直接操作：&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$s=\sum_{u=u_{0}}^{u_{0}+w-1} \sum_{v=v_{0}}^{v_{0}+h-1} g(u, v)$&lt;/p&gt;

&lt;p&gt;用 for 循环实现这一点需要操作&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102145.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;比较好用的方式&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;$s=\sum_{u=0}^{u_{0}+w-1} \sum_{v=0}^{v_{0}+h-1} g(u, v)-\sum_{u=0}^{u_{0}-1} \sum_{v=0}^{v_{0}+h-1} g(u, v)+\sum_{u=0}^{u_{0}-1} \sum_{v=0}^{v_{0}-1} g(u, v)-\sum_{u=0}^{u_{0}+w-1} \sum_{v=0}^{v_{0}-1} g(u, v)$&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;积分图像：
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$I(x, y):=\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)$&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;计算 s 需要 4 个操作：
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;$\begin{array}{c}
s=I\left(u_{0}+w-1, v_{0}+h-1\right)-I\left(u_{0}-1, v_{0}+h-1\right)+ &lt;br /&gt;
I\left(u_{0}-1, v_{0}-1\right)-I\left(u_{0}+w-1, v_{0}-1\right)
\end{array}$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102650.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. 计算积分图像&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309102838.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$I(x, y):=\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)$&lt;/p&gt;

&lt;p&gt;$\begin{aligned}
I(x+1, y+1) &amp;amp;=\sum_{u=0}^{x+1} \sum_{v=0}^{y+1} g(u, v) &lt;br /&gt;
&amp;amp;=\sum_{u=0}^{x+1} \sum_{v=0}^{y} g(u, v)+\sum_{u=0}^{x} \sum_{v=0}^{y+1} g(u, v)-\sum_{u=0}^{x} \sum_{v=0}^{y} g(u, v)+g(x+1, y+1) &lt;br /&gt;
&amp;amp;=I(x+1, y)+I(x, y+1)-I(x, y)+g(x+1, y+1)
\end{aligned}$&lt;/p&gt;

&lt;p&gt;–&amp;gt; 产生一个迭代算法，通过操作计算$O\left(w_{\text {image }} \cdot h_{\text {image }}\right)$整个积分图像&lt;/p&gt;

&lt;p&gt;–&amp;gt;如果想计算一个矩形，简单的方法更好；如果要计算许多矩形，积分图像会更好&lt;/p&gt;

&lt;p&gt;Haar 特征，在 7x7 位置使用水平和垂直边缘特征 → 98 维模式&lt;/p&gt;

&lt;p&gt;准确率： − 交叉验证：99.1% − 测试集：99.4%&lt;/p&gt;

&lt;p&gt;支持向量数：109（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309103309.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309103325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第六种方法：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zh.wikipedia.org/zh-hans/%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E6%A8%A1%E5%BC%8F&quot;&gt;局部二值模式&lt;/a&gt; [Local binary patterns (LBP) ]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分析局部灰度变化&lt;/li&gt;
  &lt;li&gt;对多个区域执行直方图&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;对于每个相邻像素，检查相邻像素是更亮 (1) 还是更暗 (0)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104104.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算块中所有像素的这些数字&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104159.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104218.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;制作直方图&lt;/li&gt;
  &lt;li&gt;将所有块的直方图排列在一个向量中&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104357.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;局部二进制模式 → 4096 维稀疏模式&lt;/p&gt;

&lt;p&gt;准确度：- 交叉验证：98.6% - 测试集：99.3%&lt;/p&gt;

&lt;p&gt;支持向量的数量：264（共 1000 个）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104503.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104518.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;总结&quot;&gt;总结&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309104833.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;见解：&lt;/p&gt;

&lt;p&gt;– 训练和测试的准确度不一样&lt;/p&gt;

&lt;p&gt;– “智能”特性有很大帮助&lt;/p&gt;

&lt;p&gt;– 更多的功能并不意味着更高的准确度&lt;/p&gt;

&lt;p&gt;–  “智能”特性包括预处理&lt;/p&gt;

&lt;p&gt;– “通用”特征（像素值、HOG、Haar）&lt;/p&gt;

&lt;h4 id=&quot;图像数据增强data-tuning&quot;&gt;图像数据增强Data Tuning&lt;/h4&gt;

&lt;p&gt;训练数据的&lt;strong&gt;质量&lt;/strong&gt;和&lt;strong&gt;数量&lt;/strong&gt;对分类结果的影响很大&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;(一) 我们如何提高数量？&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– 选择和标记更多图像&lt;/li&gt;
  &lt;li&gt;– 搜索数据库/互联网以获取更多训练示例（ImageNet、KITTI、CalTech 数据集、INRIA 数据集、Microsoft COCO，…）&lt;/li&gt;
  &lt;li&gt;– 改变亮度、对比度、ROI 中对象位置、旋转的示例&lt;/li&gt;
  &lt;li&gt;– 添加抖动（ 随机噪声）&lt;/li&gt;
  &lt;li&gt;– 镜像示例，如果对象是对称的&lt;/li&gt;
  &lt;li&gt;– 弹性变形 Elastic Distortion&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;弹性变形&quot;&gt;弹性变形&lt;/h5&gt;

&lt;ol&gt;
  &lt;li&gt;对于每个像素：样本从高斯分布随机偏移&lt;/li&gt;
  &lt;li&gt;通过与高斯滤波器的卷积平滑移位值&lt;/li&gt;
  &lt;li&gt;对于每个像素：将像素移动到新位置&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111157.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;（二）我们如何提高质量？&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;– 检查标签的一致性&lt;/li&gt;
  &lt;li&gt;– 标准化/标准化模式&lt;/li&gt;
  &lt;li&gt;– 从各种来源/具有不同条件的各种图像序列中获取数据 → 增加模式集中的变化&lt;/li&gt;
  &lt;li&gt;– 检查 ROI 是否一致&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\begin{array}{l}
x_{i}^{\prime}=\frac{x_{i}-\bar{x}}{s_{x}} &lt;br /&gt;
\text { with } \bar{x}=\frac{1}{n} \sum_{i} x_{i} &lt;br /&gt;
\text { and } s_{x}=\sqrt{\frac{1}{n} \sum_{i}\left(x_{i}-\bar{x}\right)^{2}}
\end{array}$&lt;/p&gt;

&lt;h4 id=&quot;多种类分类&quot;&gt;多种类分类&lt;/h4&gt;

&lt;p&gt;具有两个以上类别的分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111553.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;一对一的方法&quot;&gt;一对一的方法：&lt;/h5&gt;

&lt;p&gt;为每个类构建一个分类器，对类元素与非类元素进行分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;克服歧义：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220309111726.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV8.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV8.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-图像分割(第二部分) Segmentation</title>
        <description>&lt;head&gt;
    &lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
   &lt;/script&gt;
&lt;/head&gt;

&lt;h1 id=&quot;形态学运算-morphological-operations&quot;&gt;形态学运算 Morphological Operations&lt;/h1&gt;

&lt;p&gt;对于图像具有的问题：孔洞， 参差不齐的轮廓，间隙，微小区域等，我们提出了形态学运算。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;两个关键概念&lt;/strong&gt;：扩展和缩小区域：&lt;/p&gt;

&lt;p&gt;——&lt;strong&gt;腐蚀erosion：&lt;/strong&gt; 将区域缩小一个像素&lt;/p&gt;

&lt;p&gt;——&lt;strong&gt;膨胀dilation&lt;/strong&gt;：将区域扩大一个像素&lt;/p&gt;

&lt;p&gt;最基本的形态学运算是膨胀和腐蚀。膨胀指将像素添加到图像中对象的边界，而腐蚀指删除对象边界上的像素。&lt;/p&gt;

&lt;p&gt;现在我们假设：&lt;/p&gt;

&lt;p&gt;背景的像素用0编码，前景像素用大于1的数字编码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308094220.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;如图是四个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308094331.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;八个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;image/2022-02-08-MV6.1/1646729074143.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;center&gt;24个相邻的像素八个相邻的像素 &lt;/center&gt;

&lt;p&gt;&lt;strong&gt;腐蚀&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \operatorname{erode}\{g\}(u, v)=\min \{&amp;amp; g(u, v) \\ &amp;amp; g(u+1, v), g(u+1, v+1) \\ &amp;amp; g(u, v+1), g(u-1, v+1) \\ &amp;amp; g(u-1, v), g(u-1, v-1) \\ &amp;amp;g(u, v-1), g(u+1, v-1)\} \end{aligned}\]

&lt;p&gt;取相邻的最小值&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;膨胀&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \operatorname{dilate}\{g\}(u, v)=\max &amp;amp;\{g(u, v)\\ &amp;amp; g(u+1, v), g(u+1, v+1), \\ &amp;amp; g(u, v+1), g(u-1, v+1) \\ &amp;amp; g(u-1, v), g(u-1, v-1) \\ &amp;amp;g(u, v-1), g(u+1, v-1)\} \end{aligned}\]

&lt;p&gt;取相邻的最大值&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095334.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095446.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后一个巧妙地知识：腐蚀和膨胀能够结合&lt;/p&gt;

&lt;p&gt;—— 闭合colsing：先膨胀，再腐蚀&lt;/p&gt;

&lt;p&gt;在不改变区域整体延伸的情况下填充间隙和孔洞&lt;/p&gt;

&lt;p&gt;—— 开放opening：先腐蚀，再膨胀&lt;/p&gt;

&lt;p&gt;去除薄区域而不改变大区域的整体延伸&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308095744.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;image/2022-02-08-MV6.1/1646729944200.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;到目前为止，我们的分割是：&lt;/p&gt;

&lt;p&gt;——分割基于颜色（或灰度值）&lt;/p&gt;

&lt;p&gt;——不同的颜色表示和不同的相似度测量&lt;/p&gt;

&lt;p&gt;问题是：我们如何分割颜色不显著的图像&lt;/p&gt;

&lt;p&gt;例如：将图像分割成相同阴影的区域&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100342.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那我们分割图像又需要什么呢？&lt;/p&gt;

&lt;p&gt;对每个像素：对该像素的描述（图像特征）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如：颜色&lt;/li&gt;
  &lt;li&gt;如：纹理信息&lt;/li&gt;
  &lt;li&gt;如：点的深度（三维扫描仪/立体视觉)&lt;/li&gt;
  &lt;li&gt;如：像素的运动（光流）。&lt;/li&gt;
  &lt;li&gt;如：描述像素是否属于某些物体类别的特征&lt;/li&gt;
  &lt;li&gt;再例如，这些特征的组合&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在上述例子中，我们又将找到了什么样子的图像特征呢：&lt;/p&gt;

&lt;p&gt;图像特征：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;颜色和灰度等级不突出&lt;/li&gt;
  &lt;li&gt;线条的方向是突出的&lt;/li&gt;
  &lt;li&gt;例如
    &lt;ul&gt;
      &lt;li&gt;计算灰度等级的梯度&lt;/li&gt;
      &lt;li&gt;确定主要的梯度方向
在像素周围的局部环境中&lt;/li&gt;
      &lt;li&gt;用2维矢量表示方向&lt;/li&gt;
      &lt;li&gt;矢量的长度与平均梯度长度成正比
梯度长度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们的准则和算法：&lt;/p&gt;

&lt;p&gt;• 邻域标准&lt;/p&gt;

&lt;p&gt;• 最小分段大小&lt;/p&gt;

&lt;p&gt;• CCL&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100853.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308100930.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;水平集方法-let-set-methods&quot;&gt;水平集方法 Let Set Methods&lt;/h1&gt;

&lt;p&gt;这个方法我的个人理解是通过一段任意封闭的曲线进行扩张，当扩张到图像梯度明显的地方开始放缓扩张速度直到停止，从而形成一段对具有对明显图像特征的区域进行包络。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102404.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102347.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102429.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;二类图像分割：&lt;/p&gt;

&lt;p&gt;表示分类任务中有两个类别，比如我们想识别一幅图片是不是猫。也就是说，训练一个分类器，输入一幅图片，用特征向量x表示，输出是不是猫，用y=0或1表示。二类分类是假设每个样本都被设置了一个且仅有一个标签 0 或者 1。&lt;/p&gt;

&lt;p&gt;这类分割的特点：&lt;/p&gt;

&lt;p&gt;所有像素的集合都属于分割；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;指示函数indicator function：&lt;/strong&gt;&lt;/p&gt;

\[\phi(\vec{x}) \begin{cases}&amp;lt;0 &amp;amp; \text { if pixel } \vec{x} \text { belongs to segment } \\ &amp;gt;0 &amp;amp; \text { if pixel } \vec{x} \text { belongs to background }\end{cases}\]

&lt;p&gt;边界线&lt;/p&gt;

&lt;p&gt;有符号距离函数&lt;/p&gt;

\[|\phi(\vec{x})|= \text{ distance of } \vec{x} \text{ from contour}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103407.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;轮廓点：&lt;/p&gt;

\[\phi(\vec{x})= 0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103807.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308103922.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对有符号距离函数的时间演化建模: 
\(\phi(\vec{x}, t)\)&lt;/p&gt;

&lt;p&gt;随着时间的推移跟踪边界上的一个点\(\vec{x}(t)\)&lt;/p&gt;

&lt;p&gt;显然：&lt;/p&gt;

\[\phi(\vec{x}(t), t)=0\]

&lt;p&gt;for all \(t\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308104216.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308104804.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由上可得：&lt;/p&gt;

\[\frac{\partial \phi}{\partial t}=-\nabla \phi \cdot \frac{\partial \vec{x}}{\partial t}\]

&lt;p&gt;水平集方法的基本思想：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;初始化：\(\phi(\cdot, 0)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;合理假设：\(\frac{\partial \vec{x}}{\partial t}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;随着时间跟随：\(\phi(\cdot, t)\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;使用数值积分实现，例如欧拉逼近（棘手！）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;与轮廓正交的演化&lt;/strong&gt;：&lt;/p&gt;

\[\begin{aligned} \frac{\partial \vec{x}}{\partial t} &amp;amp;=\alpha \cdot \frac{\nabla \phi}{\|\nabla \phi\|} \\ \frac{\partial \phi}{\partial t} &amp;amp;=-\nabla \phi \cdot \alpha \cdot \frac{\nabla \phi}{\|\nabla \phi\|} \\ &amp;amp;=-\alpha \frac{\|\nabla \phi\|^{2}}{\|\nabla \phi\|}=-\alpha\|\nabla \phi\| \end{aligned}\]

&lt;p&gt;如果 α &amp;gt; 0, 轮廓扩张； 如果 α &amp;lt; 0, 轮廓收缩&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308105251.png&quot; alt=&quot;&quot; /&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308105650.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;水平集演化可用于实现形态学运算：&lt;/p&gt;

&lt;p&gt;膨胀 = 扩张&lt;/p&gt;

&lt;p&gt;腐蚀 = 缩小&lt;/p&gt;

&lt;p&gt;闭运算 = 缩小后扩张&lt;/p&gt;

&lt;p&gt;开运算 = 扩张后缩小&lt;/p&gt;

&lt;p&gt;使轮廓更加平滑&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在凹陷的地方扩大&lt;/li&gt;
  &lt;li&gt;在凸面区域缩小&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i演化水平集&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;正交于轮廓线&lt;/li&gt;
  &lt;li&gt;取决于局部曲率\(\kappa\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在凸区域：局部近似轮廓的圆 \(\kappa = 1/r\)&lt;/p&gt;

&lt;p&gt;在凹面区域：局部近似轮廓的圆\(\kappa = -1/r\)&lt;/p&gt;

&lt;p&gt;一般来说：\(\kappa=\nabla\left(\frac{\nabla \phi}{\|\nabla \phi\|}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;level set update:&lt;/strong&gt; 水平集升级：&lt;/p&gt;

&lt;p&gt;\(\frac{\partial \vec{x}}{\partial t}=-\beta \kappa \frac{\nabla \phi}{\|\nabla \phi\|}\)
\(\frac{\partial \phi}{\partial t}=\beta \kappa\|\nabla \phi\|\)&lt;/p&gt;

&lt;p&gt;对黑白图非常简单的想法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从一个非常大的轮廓线开始&lt;/li&gt;
  &lt;li&gt;在白色像素处缩减轮廓线&lt;/li&gt;
  &lt;li&gt;不要在黑色像素处收缩&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;轮廓包围黑色区域：&lt;/p&gt;

\[\frac{\partial \vec{x}}{\partial t}= \begin{cases}-\gamma \cdot \frac{\nabla \phi}{\|\nabla \phi\|} &amp;amp; \text { if white pixel } \\ 0 &amp;amp; \text { if black pixel }\end{cases}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308102404.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将分割与轮廓矫正相结合&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308152349.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基于梯度的图像分割方法。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从一个非常大的轮廓线开始&lt;/li&gt;
  &lt;li&gt;在梯度长度小的像素处缩小轮廓&lt;/li&gt;
  &lt;li&gt;在梯度长度大的像素处不收缩（边缘像素）。
→ 等高线包裹边缘的区域&lt;/li&gt;
&lt;/ul&gt;

\[\frac{\partial \vec{x}}{\partial t}=-\epsilon(g) \cdot \frac{\nabla \phi}{\|\nabla \phi\|}\]

\[\epsilon(g)=\frac{\gamma}{\gamma+\mid \text { Gauss }\left.* \nabla g\right|^{p}}\]

&lt;p&gt;with appropriate \(\gamma&amp;gt;0, p \geq 1\) \(g\)denotes gray level image&lt;/p&gt;

&lt;h2 id=&quot;基于-mumford-shah-的分割&quot;&gt;基于 Mumford-Shah 的分割&lt;/h2&gt;

&lt;p&gt;理念：像素应被分配到具有最相似分割的灰度值（颜色值）。&lt;/p&gt;

&lt;p&gt;\(\bar{g}_{\text {foreground }}\)：前景段像素的平均灰度值（颜色）&lt;/p&gt;

&lt;p&gt;\(\bar{g}_{\text {background }}\):背景段中像素的平均灰度值（颜色）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308152913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用灰色（颜色）值检查边界上的像素 &lt;em&gt;Ⅰ&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;像素更类似于外部区域
 缩小轮廓&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;像素更类似于外部区域：&lt;/p&gt;

\[\left(g-\bar{g}_{\text {foreground }}\right)^{2}&amp;lt;\left(g-\bar{g}_{\text {background }}\right)^{2}\]

    &lt;p&gt;扩张轮廓&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于 Mumford-Shah 的分割：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308154055.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;随机场&quot;&gt;随机场&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;每个像素属于一个分割。 但是哪一个？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308160246.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;每个像素的分段标签被看作是一个变量
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;
    &lt;p&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;像素的特征向量&lt;/strong&gt;与其&lt;strong&gt;标签&lt;/strong&gt;有关&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308161049.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;像素的特征向量也被视为变量，然而，它的值是被观察到的&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\phi_{f}(l(u, v), f(u, v)) \begin{cases}\text { is small } &amp;amp; \text { if } f(u, v) \text { supports label } l(u, v) \\ \text { is large } &amp;amp; \text { if } f(u, v) \text { does not support label } l(u, v)\end{cases}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308155748.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;相邻像素的标签也相关&lt;/p&gt;

&lt;p&gt;\(l(u, v) \leftrightarrow l(u+1, v)\)
\(l(u, v) \leftrightarrow l(u, v+1)\)&lt;/p&gt;

&lt;p&gt;该关系再次由势函数建模&lt;/p&gt;

&lt;p&gt;\(\phi_{n}(l(u, v), l(u+1, v))\)
\(\phi_{n}(l(u, v), l(u, v+1))\)&lt;/p&gt;

\[\phi_{n}(l(u, v), l(u+1, v))\left\{\begin{array}{l}\text { is small } \\ \text { if } l(u, v) \text { and } l(u+1, v) \text { are similar } \\ \text { is large } \\ \text { if } l(u, v) \text { and } l(u+1, v) \text { are dissimilar }\end{array}\right.\]

&lt;p&gt;找到标签 l(u,v) 使得势函数最小化&lt;/p&gt;

\[\begin{aligned} \operatorname{minimize}_{l(\cdot, \cdot)} &amp;amp; \alpha_{f} \cdot \sum_{u, v} \phi_{f}(l(u, v), f(u, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u+1, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u, v+1)) \end{aligned}\]

&lt;p&gt;带权重因子\(\alpha_{f}, \alpha_{n}&amp;gt;0\)&lt;/p&gt;

&lt;p&gt;优化问题的解决方案： 精确 → 困难（一般来说，存在例外）；近似&lt;/p&gt;

&lt;p&gt;例如：从深色背景中提取明亮的前景对象&lt;/p&gt;

&lt;p&gt;\(l=0 \quad\) background
\(l=1 \quad\) foreground
\(f \quad\) gray value \(0 \leq f \leq 255\)&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\phi_{f}(l, f)=\left(l-\frac{1}{255} f\right)^{2} \\
&amp;amp;\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}
\end{aligned}\]

&lt;p&gt;实现分割标准。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;预定的颜色标准&lt;/li&gt;
  &lt;li&gt;空间标准&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164349.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随机场建模的优势。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分割问题被表述为优化问题&lt;/li&gt;
  &lt;li&gt;潜在函数允许对许多分割标准进行建模，例如
    &lt;ul&gt;
      &lt;li&gt;种子点
对种子点保持标签函数不变&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;对某些分段标签的一般偏好（先验的）。
→ 增加单项潜力函数
例如，指定前景物体应在图像的中心位置&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164451.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;原型分割特征向量。像素应该被分配到具有最相似原型特征向量的分割。
原型特征最相似的分割。
→ 将原型变量添加到随机域中，每分割一个。
→ 添加势函数，对原型特征和像素特征的相似性进行建模 f&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164649.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;–&amp;gt;应用同质性标准&lt;/p&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;假设前景和背景的划分是
    &lt;ul&gt;
      &lt;li&gt;前景物体位于图像的中心位置&lt;/li&gt;
      &lt;li&gt;前景物体和背景物体具有独特的颜色&lt;/li&gt;
      &lt;li&gt;使用像素颜色（例如在RGB中）作为特征&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\phi_{\text {prior }}(l(u, v))= \begin{cases}\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{|2 v-h e i g h t|}{h e i g h t}\right\} &amp;amp; \text { if } l(u, v)=1 \\ 1-\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{\mid 2 v-h e i g h t}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=0\end{cases}\]

\[\phi_{\text {prototype }}(l, f, p)=\|f-p(l)\|^{2}\]

\[\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}\]

&lt;p&gt;\(\phi_{\text {prior }}(l(u, v))= \begin{cases}\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{\mid 2 v-\text { height } \mid}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=1 \\ 1-\max \left\{\frac{\mid 2 u-\text { width } \mid}{\text { width }}, \frac{|2 v-h e i g h t|}{\text { height }}\right\} &amp;amp; \text { if } l(u, v)=0\end{cases}$
$\phi_{\text {prototype }}(l, f, p)=\|f-p(l)\|^{2}\)
\(\phi_{n}\left(l, l^{\prime}\right)=\left(l-l^{\prime}\right)^{2}\)&lt;/p&gt;

\[\begin{aligned} \operatorname{minimize}_{l(\cdot, \cdot), p(\cdot)} &amp;amp; \alpha_{\text {prior }} \cdot \sum_{u, v} \phi_{\text {prior }}(l(u, v)) \\ &amp;amp;+\alpha_{f} \cdot \sum_{u, v} \phi_{\text {prototype }}(l(u, v), f(u, v), p) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u+1, v)) \\ &amp;amp;+\alpha_{n} \cdot \sum_{u, v} \phi_{n}(l(u, v), l(u, v+1)) \end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220308164951.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV6.1/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV6.1/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-图像分割(第一部分) Segmentation</title>
        <description>&lt;head&gt;
    &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
    &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: [&apos;script&apos;, &apos;noscript&apos;, &apos;style&apos;, &apos;textarea&apos;, &apos;pre&apos;],
            inlineMath: [[&apos;$&apos;,&apos;$&apos;]]
            }
        });
    &lt;/script&gt;
&lt;/head&gt;
&lt;h1 id=&quot;机器视觉-图像分割第一部分&quot;&gt;机器视觉-图像分割(第一部分)&lt;/h1&gt;

&lt;p&gt;在计算机视觉领域， &lt;strong&gt;图像分割&lt;/strong&gt; （segmentation）指的是将数字图像细分为多个图像子区域（像素的集合）（也被称作超像素）的过程。图像分割的目的是&lt;strong&gt;简化或改变图像的表示形式&lt;/strong&gt;，使得图像更容易理解和分析。图像分割通常用于定位图像中的物体和边界（线，曲线等）。更精确的，图像分割是对图像中的每个像素加标签的一个过程，&lt;strong&gt;这一过程使得具有相同标签的像素具有某种共同视觉特性&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;图像分割在&lt;strong&gt;实际中的应用&lt;/strong&gt;：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;在卫星图像中定位物体（道路、森林等）

人脸识别

指纹识别

交通控制系统

刹车灯检测 Brake light detection
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;分割的准则&quot;&gt;分割的准则&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;预定义的颜色标准 predefined color criterion&lt;/li&gt;
  &lt;li&gt;邻域准则 neighborhood criterion&lt;/li&gt;
  &lt;li&gt;均匀性准则 homogeneity criterion&lt;/li&gt;
  &lt;li&gt;连通性准则 connectedness criterion&lt;/li&gt;
  &lt;li&gt;空间准则 spatial criterion&lt;/li&gt;
  &lt;li&gt;边界光滑准则 boundary smoothness criterion&lt;/li&gt;
  &lt;li&gt;尺寸准则 size criteria&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302202410.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;预定义的颜色标准-predefined-color-criterion&quot;&gt;预定义的颜色标准 predefined color criterion&lt;/h2&gt;

&lt;p&gt;像素颜色属于一组预定义的”有趣”的颜色，它指定了哪些颜色值是相关的，哪些像素是彩色的。&lt;/p&gt;

&lt;p&gt;例如，我们在下面的足球机器人场地上找到橙色的球。&lt;/p&gt;

&lt;p&gt;橙色的像素点是在HSV值在以下范围的：&lt;/p&gt;

&lt;p&gt;$0^{\circ} \leq H \leq 24^{\circ}, 0.4 \leq S \leq 1,0.4 \leq V \leq 1$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302193913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302194516.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注： HSV值(Hue, Saturation, Value)是是根据颜色的直观特性由A. R. Smith在1978年创建的一种颜色空间, 也称六角锥体模型(Hexcone Model)。这个模型中颜色的参数分别是：色调（H），饱和度（S），亮度（V）。&lt;/p&gt;

&lt;p&gt;色调H：用角度度量，取值范围为0°～360°，从红色开始按逆时针方向计算，红色为0°，绿色为120°,蓝色为240°。它们的补色是：黄色为60°，青色为180°,品红为300°；&lt;/p&gt;

&lt;p&gt;饱和度S：取值范围为0.0～1.0；&lt;/p&gt;

&lt;p&gt;亮度V：取值范围为0.0(黑色)～1.0(白色)。&lt;/p&gt;

&lt;p&gt;RGB和CMY颜色模型都是面向硬件的，而HSV（Hue Saturation Value）颜色模型是面向用户的。&lt;/p&gt;

&lt;p&gt;HSV模型的三维表示从RGB立方体演化而来。设想从RGB沿立方体对角线的白色顶点向黑色顶点观察，就可以看到立方体的六边形外形。六边形边界表示色彩，水平轴表示纯度，明度沿垂直轴测量。&lt;/p&gt;

&lt;p&gt;根据颜色进行分割的优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;非常快速&lt;/li&gt;
  &lt;li&gt;如果事先知道物体的颜色，并且颜色具有辨别力，则&lt;strong&gt;可以应用&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;如果不同的对象共享相同的颜色，则&lt;strong&gt;不适用&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;找到合适的颜色规格通常很麻烦&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;邻域准则-neighborhood-criterion&quot;&gt;邻域准则 neighborhood criterion&lt;/h2&gt;

&lt;p&gt;像素颜色与相邻像素的颜色相似，指定哪些颜色相似，将一段中的所有像素分组，这些像素至少有一个已属于该段的相邻像素&lt;/p&gt;

&lt;p&gt;例如：如果RGB三元组的欧氏距离小于7/255，则像素是相邻的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302193913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302195234.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据邻域准则进行图片细分的优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;简单&lt;/li&gt;
  &lt;li&gt;物体的颜色不需要知道&lt;/li&gt;
  &lt;li&gt;对象边界必须是高对比度，内部必须是低对比度&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;模糊的图像可能导致分段不足，嘈杂的图像可能导致分段过度&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;均匀性准则-homogeneity-criterion&quot;&gt;均匀性准则 homogeneity criterion&lt;/h2&gt;

&lt;p&gt;像素颜色与线段的分割颜色相似，指定如何计算平均的颜色并确定两种颜色是否相似。将所有像素分组到一段中，这些像素与分割的平均颜色相似&lt;/p&gt;

&lt;p&gt;例如：与球的平均颜色相似的像素，都属于此分割颜色&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302193913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302195909.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过均匀性准测进行图像分割的优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;物体的颜色不需要知道&lt;/li&gt;
  &lt;li&gt;对象的所有部分都必须具有相似的颜色&lt;/li&gt;
  &lt;li&gt;不支持低频率的颜色变化&lt;/li&gt;
  &lt;li&gt;循环定义&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;连通性准则-connectedness-criterion&quot;&gt;连通性准则 connectedness criterion&lt;/h2&gt;

&lt;p&gt;同一段中的所有像素必须连接，即在该段的两个像素之间有一条不离开该段的路径&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302200517.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优缺点：&lt;/p&gt;

&lt;p&gt;此标准可以与其他标准相结合&lt;/p&gt;

&lt;h2 id=&quot;空间准则-spatial-criterion&quot;&gt;空间准则 spatial criterion&lt;/h2&gt;

&lt;p&gt;被另一部分的像素包围的像素应该属于该部分（另一部分）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302201711.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;标准与其他标准相结合&lt;/li&gt;
  &lt;li&gt;提高了抗噪性&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;边界光滑准则-boundary-smoothness-criterion&quot;&gt;边界光滑准则 boundary smoothness criterion&lt;/h2&gt;

&lt;p&gt;分割的边界应平滑，而不是参差不齐。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302201944.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302202044.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;标准与其他标准相结合&lt;/li&gt;
  &lt;li&gt;提高了抗噪性&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;尺寸准则-size-criteria&quot;&gt;尺寸准则 size criteria&lt;/h2&gt;

&lt;p&gt;分割的大小应在一定范围内/不太小/不太大&lt;/p&gt;

&lt;h1 id=&quot;分割算法&quot;&gt;分割算法&lt;/h1&gt;

&lt;p&gt;基础算法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;区域增长 region growing&lt;/li&gt;
  &lt;li&gt;连接组件标记 connected components labeling&lt;/li&gt;
  &lt;li&gt;K-means和mean-shift算法&lt;/li&gt;
  &lt;li&gt;形态学运算 morphological operations&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;更详尽的算法：&lt;/p&gt;

&lt;p&gt;1.&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E6%B0%B4%E5%B9%B3%E9%9B%86%E6%96%B9%E6%B3%95&quot;&gt;水平集方法&lt;/a&gt;
     level set methods&lt;/p&gt;

&lt;p&gt;2.&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%9C%BA&quot;&gt;随机场&lt;/a&gt; 
    random fields&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302202529.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;区域增长-region-growing&quot;&gt;区域增长 region growing&lt;/h2&gt;

&lt;p&gt;区域生长（region growing）是指将成组的像素或区域发展成更大区域的过程。从种子点的集合开始，从这些点的区域增长是通过将与每个种子点有相似属性像强度、灰度级、纹理颜色等的相邻像素合并到此区域。&lt;/p&gt;

&lt;p&gt;区域生长算法的基本思想是将有相似性质的像素点合并到一起。对每一个区域要先指定一个种子点作为生长的起点，然后将种子点周围领域的像素点和种子点进行对比，将具有相似性质的点合并起来继续向外生长，直到没有满足条件的像素被包括进来为止。这样一个区域的生长就完成了。这个过程中有几个关键的问题：（原文链接：https://blog.csdn.net/weixin_40647819/article/details/90215872）&lt;/p&gt;

&lt;p&gt;核心思想：从一个/多个种子点开始（必须提供种子点）；增量扩展段，直到无法添加更多像素；实现连通性标准+同质性或邻域标准；产生单一的片段。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302203819.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;易于实现（广度优先搜索）&lt;/li&gt;
  &lt;li&gt;需要一个或多个种子点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220316112419.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;连接组件标记算法-connected-components-labelingccl&quot;&gt;连接组件标记算法 connected components labeling（CCL）&lt;/h2&gt;

&lt;p&gt;连接组件标记算法(connected component labeling algorithm)是图像分析中最常用的算法之一，算法的实质是扫描一幅图像的每个像素，对于像素值相同的分为相同的组(group),最终得到图像中所有的像素连通组件。
扫描的方式可以是从上到下，从左到右，对于一幅有N个像素的图像来说，最大连通组件个数为N/2。扫描是基于每个像素单位，对于二值图像而言，连通组件集合可以是V={1|白色}或者V={0|黑色}, 取决于前景色与背景色的不同。
对于灰度图像来说，连图组件像素集合可能是一系列在0 ～ 255之间k的灰度值。&lt;/p&gt;

&lt;p&gt;引用自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/81959284&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;核心思想：创建图像的完整分割；实现连通性标准+邻域标准；仅通过确定与两个相邻像素的相似性，将每个像素分配给分段&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302205133.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们从左上角到右下角逐行访问像素，并立即将它们分配给一个段。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302205336.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们访问一个像素（u，v）时，我们已经访问了（u-1，v）和（u，v-1）。&lt;strong&gt;我们比较颜色（u，v）和颜色（u-1，v），颜色（u，v-1），五种情况：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;（u，v）和（u-1，v）处的像素颜色相似，（u，v）和（u，v-1）处的像素颜色不同&lt;/p&gt;

    &lt;p&gt;→ 像素（u，v）和（u-1，v）属于同一段&lt;/p&gt;

    &lt;p&gt;→ 我们将像素（u，v）分配给像素（u-1，v）的部分&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302205643.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;（u，v）和（u-1，v）处的像素颜色不同，（u，v）和（u，v-1）处的像素颜色相似&lt;/p&gt;

    &lt;p&gt;→ 像素（u，v）和（u，v-1）属于同一段&lt;/p&gt;

    &lt;p&gt;→ 我们将像素（u，v）分配给像素（u，v-1）的部分&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302205709.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;（u，v）和（u-1，v）处的像素颜色不同，（u，v）和（u，v-1）处的像素颜色不同&lt;/p&gt;

    &lt;p&gt;→ 为什么像素（u，v）应该属于（u-1，v）或（u，v-1）的段？&lt;/p&gt;

    &lt;p&gt;→ 我们创建一个新段，并为其指定像素（u，v）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302210249.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;（u，v）和（u-1，v）处的像素颜色是相似的，（u，v）和（u，v-1）处的像素颜色是相似的，像素（u-1，v）和（u，v-1）属于同一段。&lt;/p&gt;

    &lt;p&gt;→ 像素（u，v）也属于该部分&lt;/p&gt;

    &lt;p&gt;→ 我们将像素（u，v）分配给该段&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302210306.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;（u，v）和（u-1，v）处的像素颜色相似，（u，v）和（u，v-1）处的像素颜色相似，像素（u-1，v）和（u，v-1）不属于同一段&lt;/p&gt;

    &lt;p&gt;→ 像素（u，v）属于两个相邻的部分&lt;/p&gt;

    &lt;p&gt;→ 我们合并两个相邻的段，并将像素（u，v）分配给合并的段&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302210325.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302210354.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;k均值聚类算法-k-means&quot;&gt;K均值聚类算法 K-means&lt;/h2&gt;

&lt;p&gt;k均值聚类算法（k-means clustering algorithm）是一种迭代求解的聚类分析算法，其步骤是，预将数据分为K组，则随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。聚类中心以及分配给它们的对象就代表一个聚类。每分配一个样本，聚类的聚类中心会根据聚类中现有的对象被重新计算。这个过程将不断重复直到满足某个终止条件。终止条件可以是没有（或最小数目）对象被重新分配给不同的聚类，没有（或最小数目）聚类中心再发生变化，误差平方和局部最小。&lt;/p&gt;

&lt;p&gt;核心思想：图像由相似颜色的区域组成; 寻找颜色的簇; 将每个像素指定给其颜色簇; 实现同质性标准; 创建完整的分割。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302193913.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上面图片中的颜色簇：绿色，白色，橙色，黑色，品红，蓝，黄色，灰色&lt;/p&gt;

&lt;p&gt;怎么找到颜色簇呢？ 如果我们知道簇的数量 –&amp;gt; k-means 算法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;随机初始化k原型颜色c1、c2、…、ck（例如，从图像中随机选取像素）&lt;/li&gt;
  &lt;li&gt;将每个像素指定给最相似的原型颜色&lt;/li&gt;
  &lt;li&gt;通过对步骤2中指定的像素颜色进行平均，重新计算原型颜色&lt;/li&gt;
  &lt;li&gt;重复第2步和第3步，直到收敛（即第2步中的赋值不再改变）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;例如：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302211110.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第1步：从两个像素中随机选择颜色；&lt;/p&gt;

&lt;p&gt;第2步：将像素分配给最相似的簇；&lt;/p&gt;

&lt;p&gt;第3步：重新计算原型颜色；&lt;/p&gt;

&lt;p&gt;第2步：重新分配像素；&lt;/p&gt;

&lt;p&gt;第3步：重新计算原型颜色；&lt;/p&gt;

&lt;p&gt;第2步：重新分配像素→ 汇聚&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302211413.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302211438.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302211525.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302211638.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;k-均值算法&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;p&gt;•简单、易于实现&lt;/p&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;p&gt;•必须知道聚类数（k）&lt;/p&gt;

&lt;p&gt;•通常会收敛到次优聚类（取决于初始原型颜色）&lt;/p&gt;

&lt;p&gt;未知聚类数的改进： &lt;strong&gt;mean-shift&lt;/strong&gt; 均值漂移&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要颜色的相似性度量&lt;/li&gt;
  &lt;li&gt;对于每个像素p，按如下步骤进行：
1.确定p的颜色并将其分配给变量c
    &lt;ol&gt;
      &lt;li&gt;找到图像中与c相似的所有像素的集合S&lt;/li&gt;
      &lt;li&gt;计算S的平均颜色并将其分配给变量c（不要改变图像中p的像素值
不要改变图像中p的像素值！)&lt;/li&gt;
      &lt;li&gt;重复步骤2和3，直到收敛（即直到步骤2中的S保持不变）。&lt;/li&gt;
      &lt;li&gt;最后，c是像素p所属区段的原型颜色。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例: 沿一个轴排列所有像素颜色（灰度值）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302212227.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第1步：选择目标像素的颜色并初始化c
第2步：找到相似像素的集合S
第3步：计算S的平均颜色并将其分配给c
第2步：重新计算S
第3步：重新计算S的平均颜色并将其分配给c
第2步：重新计算S
第3步：重新计算S的平均颜色并将其分配给c
第2步：重新计算S→收敛&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220302212319.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Mar 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/03/MV6/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/03/MV6/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
      <item>
        <title>机器视觉-相机光学 Ｏptics</title>
        <description>&lt;head&gt;
    &lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
   &lt;/script&gt;
&lt;/head&gt;
&lt;h1 id=&quot;针孔照相机&quot;&gt;针孔照相机&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311204148.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;点\((x,y,z)\)投影到\((x&apos;,y&apos;)\)截距定理：&lt;/p&gt;

\[\frac{x}{z}=\frac{x^{\prime}}{f}, \quad \frac{y}{z}=\frac{y^{\prime}}{f} \quad \Rightarrow \quad z \cdot\left(\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right)=\left(\begin{array}{ll}f &amp;amp; 0 \\ 0 &amp;amp; f\end{array}\right) \cdot\left(\begin{array}{l}x \\ y\end{array}\right)\]

&lt;h1 id=&quot;世界到图像映射&quot;&gt;世界到图像映射&lt;/h1&gt;

&lt;p&gt;相机坐标系&lt;/p&gt;

&lt;p&gt;图像坐标系&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;u 方向平行于 x’ 方向&lt;/li&gt;
  &lt;li&gt;v 方向可能倾斜 θ=u 和 v 方向之间的角度&lt;/li&gt;
  &lt;li&gt;主点 = 图像坐标中相机坐标系的原点 (u0,v0)&lt;/li&gt;
  &lt;li&gt;单位向量 u 和 v 的长度与单位向量 x’、y’ 的长度不同 比例因子 α、β&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311204556.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将点 Z 从相机坐标映射到图像坐标：&lt;/p&gt;

&lt;p&gt;三角形 ZBC：&lt;/p&gt;

\[\begin{aligned} \sin \theta &amp;amp;=\frac{\beta y^{\prime}}{v-v_{0}} \\ \Rightarrow v &amp;amp;=\frac{\beta}{\sin \theta} y^{\prime}+v_{0} \\ \cot \theta &amp;amp;=\frac{\alpha x^{\prime}+u_{0}-u}{\beta y^{\prime}} \\ \Rightarrow u &amp;amp;=\alpha x^{\prime}-(\cot \theta) \cdot \beta y^{\prime}+u_{0} \end{aligned}\]

&lt;p&gt;==从相机到图像帧的映射：==&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312211920.png&quot; alt=&quot;&quot; /&gt;
\(\left(\begin{array}{l}
u \\
v
\end{array}\right)=\left(\begin{array}{cc}
\alpha &amp;amp; -\beta \cot \theta \\
0 &amp;amp; \frac{\beta}{\sin \theta}
\end{array}\right) \cdot\left(\begin{array}{l}
x^{\prime} \\
y^{\prime}
\end{array}\right)+\left(\begin{array}{l}
u_{0} \\
v_{0}
\end{array}\right)\)
&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311204822.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;物体在相机坐标上的位置通常未知&lt;/p&gt;

&lt;p&gt;外部坐标系（“世界框架”）（ξ，η，ζ）&lt;/p&gt;

&lt;p&gt;映射：
\(\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=R \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta
\end{array}\right)+\vec{t}\)
R是旋转矩阵，t是转移矩阵&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;坐标变换&lt;/p&gt;

    &lt;p&gt;世界框架→相机框架&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=R \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta
\end{array}\right)+\vec{t}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311205018.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;透视投影；中心投影法&lt;/li&gt;
&lt;/ol&gt;

\[z \cdot\left(\begin{array}{l}
x^{\prime} \\
y^{\prime}
\end{array}\right)=\left(\begin{array}{ll}
f &amp;amp; 0 \\
0 &amp;amp; f
\end{array}\right) \cdot\left(\begin{array}{l}
x \\
y
\end{array}\right)\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311205103.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;坐标变换&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;​		相机帧→图像帧
\(\left(\begin{array}{l}
u \\
v
\end{array}\right)=\left(\begin{array}{cc}
\alpha &amp;amp; -\beta \cot \theta \\
0 &amp;amp; \frac{\beta}{\sin \theta}
\end{array}\right) \cdot\left(\begin{array}{l}
x^{\prime} \\
y^{\prime}
\end{array}\right)+\left(\begin{array}{l}
u_{0} \\
v_{0}
\end{array}\right)\)
\(cot\theta=cos\theta/sin\theta\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220311205201.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;重写步骤3：
\(\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=\left(\begin{array}{ccc}
\alpha &amp;amp; -\beta \cot \theta &amp;amp; u_{0} \\
0 &amp;amp; \frac{\beta}{\sin \theta} &amp;amp; v_{0} \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right) \cdot\left(\begin{array}{l}
x^{\prime} \\
y^{\prime} \\
1
\end{array}\right)\)
重写步骤2：
\(z \cdot\left(\begin{array}{l}
x^{\prime} \\
y^{\prime} \\
1
\end{array}\right)=\left(\begin{array}{lll}
f &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; f &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right) \cdot\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)\)
结合第 2 步和第 3 步：
\(\begin{aligned}
z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right) &amp;amp;=\left(\begin{array}{ccc}
\alpha &amp;amp; -\beta \cot \theta &amp;amp; u_{0} \\
0 &amp;amp; \frac{\beta}{\sin \theta} &amp;amp; v_{0} \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right) \cdot\left(\begin{array}{lll}
f &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; f &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right) \cdot\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right) \\
&amp;amp;=\left(\begin{array}{ccc}
f \alpha &amp;amp; -f \beta \cot \theta &amp;amp; u_{0} \\
0 &amp;amp; \frac{f \beta}{\sin \theta} &amp;amp; v_{0} \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right) \cdot\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right) \\
&amp;amp;=\underbrace{\left(\begin{array}{ccc}
\alpha^{\prime} &amp;amp; -\beta^{\prime} \cot \theta &amp;amp; u_{0} \\
0 &amp;amp; \frac{\beta^{\prime}}{\sin \theta} &amp;amp; v_{0} \\
0 &amp;amp; 0 &amp;amp; 1
\end{array}\right)}_{=: A} \cdot\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)
\end{aligned}\)
with&lt;br /&gt;
\(\alpha^{\prime}=f \alpha, \quad \beta^{\prime}=f \beta\)
重写步骤1：
\(\left(\begin{array}{l}
x \\
y \\
z
\end{array}\right)=(R \mid \vec{t}) \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta \\
1
\end{array}\right)\)
 将 1 与之前的结果相结合：&lt;/p&gt;

\[z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=A \cdot(R \mid \vec{t}) \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta \\
1
\end{array}\right)z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=A \cdot(R \mid \vec{t}) \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta \\
1
\end{array}\right)\]

&lt;p&gt;给定 (ξ,η,ζ)，我们如何计算 (u,v) ？&lt;/p&gt;

\[\begin{array}{l}
\left(\begin{array}{c}
\tilde{x} \\
\tilde{y} \\
\tilde{z}
\end{array}\right)=A \cdot(R \mid \vec{t}) \cdot\left(\begin{array}{l}
\xi \\
\eta \\
\zeta \\
1
\end{array}\right) \\
\left(\begin{array}{l}
u \\
v
\end{array}\right)=\frac{1}{\widetilde{z}}\left(\begin{array}{l}
\tilde{x} \\
\tilde{y}
\end{array}\right)
\end{array}\]

&lt;p&gt;给定 (u,v)，我们如何计算 (ξ,η,ζ) ？&lt;/p&gt;

\[\left(\begin{array}{l}
\xi \\
\eta \\
\zeta
\end{array}\right)=z R^{T} A^{-1}\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)-R^{T} \vec{t} \quad \text { with } z \geq 0\]

&lt;p&gt;(ξ,η,ζ) 不是唯一的，而是射线的元素&lt;/p&gt;

&lt;p&gt;相机原点坐标：&lt;/p&gt;

\[(\xi, \eta, \zeta)^{T}=-R^{T} \vec{t}\]

&lt;p&gt;参数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;内在参数：描述相机（5个参数）&lt;/p&gt;

\[u_{0}, v_{0}, \alpha^{\prime}, \beta^{\prime}, \theta\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;外部参数：相机的位姿（6个参数）&lt;/p&gt;

\[R,\vec{t}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;有时，模型被简化假设&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\theta=90^{\circ}, \alpha^{\prime}=\beta^{\prime}\]

&lt;h1 id=&quot;体积测量&quot;&gt;体积测量&lt;/h1&gt;

&lt;p&gt;测量体积：&lt;/p&gt;

&lt;p&gt;– 是一个矩形金字塔&lt;/p&gt;

&lt;p&gt;– 焦点是金字塔的顶点&lt;/p&gt;

&lt;p&gt;– 水平孔径角（张角）&lt;/p&gt;

\[\arccos \frac{\left\langle A^{-1}\left(0, v_{0}, 1\right)^{T}, A^{-1}\left(u_{\max }, v_{0}, 1\right)^{T}\right\rangle}{\left\|A^{-1}\left(0, v_{0}, 1\right)^{T}\right\| \cdot\left\|A^{-1}\left(u_{\max }, v_{0}, 1\right)^{T}\right\|}\]

&lt;p&gt;– 垂直孔径角&lt;/p&gt;

\[arccos \frac{\left\langle A^{-1}\left(u_{0}, 0,1\right)^{T}, A^{-1}\left(u_{0}, v_{\max }, 1\right)^{T}\right\rangle}{\left\|A^{-1}\left(u_{0}, 0,1\right)^{T}\right\| \cdot\left\|A^{-1}\left(u_{0}, v_{\max }, 1\right)^{T}\right\|}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312163116.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;透视投影中心投影法&quot;&gt;透视投影；中心投影法&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312163742.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312163805.png&quot; style=&quot;zoom: 38.5%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312163832.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164207.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164237.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;透视投影不：&lt;/p&gt;

&lt;p&gt;– 保留角度&lt;/p&gt;

&lt;p&gt;– 保留长度&lt;/p&gt;

&lt;p&gt;– 保留面积&lt;/p&gt;

&lt;p&gt;– 保留长度比&lt;/p&gt;

&lt;p&gt;– 将圆/椭圆的中心映射到所映射的椭圆的中心（除非：如果平面与光轴正交）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164333.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;镜头&quot;&gt;镜头&lt;/h1&gt;

&lt;p&gt;针孔相机很难让光线通过&lt;/p&gt;

&lt;p&gt;→ 镜头 • 斯涅尔折射定律&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164413.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;📌&lt;strong&gt;Snell’s law:&lt;/strong&gt;  📌&lt;/p&gt;

\[n_{e} \sin \theta_{e}=n_{t} \sin \theta_{t}\]

\[n_{\text {medium }}=\frac{v_{\text {vacuum }}}{v_{\text {medium }}}\]

&lt;p&gt;镜头焦距：镜头到焦点的距离，平行于光轴的光线被折射后的交汇点&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164804.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;镜片的折射&lt;/p&gt;

&lt;p&gt;– 表面空气/玻璃&lt;/p&gt;

&lt;p&gt;– 表面玻璃/空气&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312164839.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可忽略的厚度&lt;/li&gt;
  &lt;li&gt;双折射可以通过中心线的单折射来近似&lt;/li&gt;
  &lt;li&gt;更简单的几何建模&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;C:\Users\Wenbo Li\AppData\Roaming\Typora\typora-user-images\image-20220312164906393.png&quot; alt=&quot;image-20220312164906393&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;薄镜片&quot;&gt;薄镜片&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;清晰的图像必须满足什么条件？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312165020.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;截距定理：&lt;/p&gt;

\[\frac{x^{\prime}}{x}=\frac{f_{\text {camera }}}{z}\]

\[\frac{x^{\prime}}{x}=\frac{f_{\text {camera }}-f_{\text {lens }}}{f_{\text {lens }}}\]

&lt;p&gt;由上可得 👉&lt;/p&gt;

\[\frac{1}{f_{\text {lens }}}=\frac{1}{f_{\text {camera }}}+\frac{1}{z}\]

&lt;p&gt;（透镜方程）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;当违反透镜方程时会发生什么？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312165242.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以改变z多少程度才影响不大？&lt;/p&gt;

&lt;h2 id=&quot;depth-of-field--景深视野深度&quot;&gt;Depth of Field  景深；视野深度&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312165422.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;截距定理：&lt;/p&gt;

\[\frac{\epsilon}{D}=\frac{f_{0}-f_{f a r}}{f_{f a r}}=\cdots=\frac{f_{\text {lens }} \cdot\left(z_{\text {far }}-z_{0}\right)}{z_{\text {far }} \cdot\left(z_{0}-f_{\text {lens }}\right)}\]

&lt;p&gt;截距定理：&lt;/p&gt;

\[\frac{\epsilon}{D}=\frac{f_{\text {near }}-f_{0}}{f_{\text {near }}}=\cdots=\frac{f_{\text {lens }} \cdot\left(z_{0}-z_{\text {near }}\right)}{z_{\text {near }} \cdot\left(z_{0}-f_{\text {lens }}\right)}\]

&lt;p&gt;由上可得：&lt;/p&gt;

\[z_{f a r}=\frac{z_{0} \cdot d_{h}}{d_{h}-\left(z_{0}-f_{l e n s}\right)}\]

\[z_{\text {near }}=\frac{z_{0} \cdot d_{h}}{d_{h}+\left(z_{0}-f_{\text {lens }}\right)}\]

&lt;p&gt;\(d_{h}=\frac{D \cdot f_{\text {lens }}}{\epsilon}\)(hyperfocal distance)  （超焦距）&lt;/p&gt;

\[\Delta z=z_{\text {far }}-z_{\text {near }}=2 \frac{z_{0} \cdot d_{h} \cdot\left(z_{0}-f_{\text {lens }}\right)}{d_{h}^{2}-\left(z_{0}-f_{\text {lens }}\right)^{2}}\]

&lt;p&gt;观察:&lt;/p&gt;

&lt;p&gt;对于&lt;/p&gt;

\[z_{0} \rightarrow d_{h}+f_{\text {lens }}\]

&lt;p&gt;holds：&lt;/p&gt;

\[z_{\text {far }} \rightarrow \infty\]

\[\Delta z \rightarrow \infty\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170009.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;对焦&quot;&gt;对焦&lt;/h2&gt;

&lt;p&gt;对焦包围/对焦堆叠图像系列具有不同的镜头和图像平面之间的距离，以克服有限的景深&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170237.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;像差-lens-aberrations&quot;&gt;像差 Lens Aberrations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;几何像差：由于镜头几何形状不完善，没有唯一焦点&lt;/p&gt;

    &lt;p&gt;– 球面像差、散光、彗差&lt;/p&gt;

    &lt;p&gt;geometric aberrations: no unique focal point due to imperfect lens geometry
– spherical aberration, astigmatism, coma&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;色差：因不同波长的不同折射率引起的色散（“彩虹效应”）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;chromatic aberrations:
  dispersion caused by different refraction index for different wavelength (“rainbow effect”)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;渐晕：图像周边的光强度和饱和度降低&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;vignetting:
  reduced light intensity and saturation in the image periphery&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170349.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170407.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;图象失真&quot;&gt;图象失真&lt;/h2&gt;

&lt;p&gt;图像失真：透视投影应将线映射到线。&lt;/p&gt;

&lt;p&gt;但大多数相机不会 → 畸变&lt;/p&gt;

&lt;p&gt;– 径向畸变 镜头形状欠佳&lt;/p&gt;

&lt;p&gt;– 切向畸变 镜头安装欠佳&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170604.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;径向畸变&quot;&gt;径向畸变&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;点偏离主点&lt;/li&gt;
  &lt;li&gt;径向畸变是对称的&lt;/li&gt;
  &lt;li&gt;偏移量与到主点的距离呈非线性关系&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170728.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;矩形对象在图像中呈桶形或枕形&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312170704.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;偶数多项式的数学建模：&lt;/p&gt;

\[\left(\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right)=\left(1+k_{1} r^{2}+k_{2} r^{4}\right)\left(\begin{array}{l}x_{d} \\ y_{d}\end{array}\right) \quad \text{ with } r^{2}=x_{d}^{2}+y_{d}^{2}\]

&lt;p&gt;或在图像坐标中：&lt;/p&gt;

\[\left(\begin{array}{l}u^{\prime} \\ v^{\prime}\end{array}\right)=\left(\begin{array}{l}u_{0} \\ v_{0}\end{array}\right)+\left(1+k_{1} r^{2}+k_{2} r^{4}\right)\left(\begin{array}{l}u_{d}-u_{0} \\ v_{d}-v_{0}\end{array}\right) \text{with } r^{2}=\left(u_{d}-u_{0}\right)^{2}+\left(v_{d}-v_{0}\right)^{2}\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171211.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

\[k_1 = 0, k_2=0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171407.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

\[k_1&amp;gt;0，k_2≥0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171536.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

\[k_1&amp;lt;0，k_2≤0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171627.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

\[k_1&amp;lt;0，k_2＞0\]

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171659.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

\[k_1&amp;gt;0，k_2&amp;lt;0\]

&lt;h1 id=&quot;相机标定-camera-calibration&quot;&gt;相机标定 Camera Calibration&lt;/h1&gt;

&lt;p&gt;常用术语
内参矩阵: Intrinsic Matrix
焦距: Focal Length
主点: Principal Point
径向畸变: Radial Distortion
切向畸变: Tangential Distortion
旋转矩阵: Rotation Matrices
平移向量: Translation Vectors
平均重投影误差: Mean Reprojection Error
重投影误差: Reprojection Errors
重投影点: Reprojected Points
————————————————
版权声明：本文为CSDN博主「AI人工智能科学」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/lql0716/article/details/71973318&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;建立相机成像几何模型并矫正透镜畸变&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;参数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;内在参数：描述相机（5个参数）&lt;/p&gt;

\[u_{0}, v_{0}, \alpha^{\prime}, \beta^{\prime}, \theta\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;外部参数：相机的位姿（2个参数）&lt;/p&gt;

\[R,\vec{t}\]

    &lt;p&gt;失真参数：&lt;/p&gt;

\[k_1,k_2\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;校准 = 确定参数的过程&lt;/p&gt;

&lt;p&gt;校准：从成对的图像点和世界点确定相机参数&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312171947.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从一张或几张图片我们得到对应的点：&lt;/p&gt;

\[\left(\xi_{i}, \eta_{i}, \zeta_{i}\right) \mapsto\left(u_{i}, v_{i}\right)\]

&lt;p&gt;找到映射
\(\left(\xi_{i}, \eta_{i}, \zeta_{i}\right)\)
到尽可能好的相机参数
\(A,R,\vec{t}\) 在 \(\left(u_{i}, v_{i}\right)\)&lt;/p&gt;

&lt;p&gt;几种方法。 这里： 1. Tasi的方法 2. 张氏方法&lt;/p&gt;

&lt;p&gt;世界到图像映射：&lt;/p&gt;

\[z \cdot\left(\begin{array}{l}u \\ v \\ 1\end{array}\right)=\underbrace{A \cdot(R \mid \vec{t})}_{=: M} \cdot\left(\begin{array}{l}\xi \\ \eta \\ \zeta \\ 1\end{array}\right)\]

&lt;p&gt;M 是 3x4 矩阵&lt;/p&gt;

\[M=\left(\begin{array}{ccc}m_{1,1} &amp;amp; \ldots &amp;amp; m_{1,4} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ m_{3,1} &amp;amp; \ldots &amp;amp; m_{3,4}\end{array}\right)\]

&lt;p&gt;我们得到：&lt;/p&gt;

\[\vec{m}_{1,1: 3}\left(\begin{array}{l}\xi \\ \eta \\ \zeta\end{array}\right)+m_{1,4}-u\left(\vec{m}_{3,1: 3}\left(\begin{array}{l}\xi \\ \eta \\ \zeta\end{array}\right)+m_{3,4}\right)=0\]

\[\vec{m}_{2,1: 3}\left(\begin{array}{l}\xi \\ \eta \\ \zeta\end{array}\right)+m_{2,4}-v\left(\vec{m}_{3,1: 3}\left(\begin{array}{l}\xi \\ \eta \\ \zeta\end{array}\right)+m_{3,4}\right)=0\]

&lt;p&gt;通过最小化确定相机参数&lt;/p&gt;

\[\sum_{i}\left(\left(\vec{m}_{1,1: 3}\left(\begin{array}{c}\xi_{i} \\ \eta_{i} \\ \zeta_{i}\end{array}\right)+m_{1,4}-u_{i}\left(\vec{m}_{3,1: 3}\left(\begin{array}{c}\xi_{i} \\ \eta_{i} \\ \zeta_{i}\end{array}\right)+m_{3,4}\right)\right)^{2}\right.\left.+\left(\vec{m}_{2,1: 3}\left(\begin{array}{c}\xi_{i} \\ \eta_{i} \\ \zeta_{i}\end{array}\right)+m_{2,4}-v_{i}\left(\vec{m}_{3,1: 3}\left(\begin{array}{c}\xi_{i} \\ \eta_{i} \\ \zeta_{i}\end{array}\right)+m_{3,4}\right)\right)^{2}\right)\]

&lt;p&gt;归零偏导数：&lt;/p&gt;

&lt;p&gt;\(\left(\begin{array}{ccc}\sum_{i} S_{i} &amp;amp; 0 &amp;amp; -\sum_{i} u_{i} S_{i} \\0 &amp;amp; \sum_{i} S_{i} &amp;amp; -\sum_{i} v_{i} S_{i} \\-\sum_{i} u_{i} S_{i} &amp;amp; -\sum_{i} v_{i} S_{i} &amp;amp; \sum_{i}\left(u_{i}^{2}+v_{i}^{2}\right) S_{i}\end{array}\right) \cdot\left(\begin{array}{l}\vec{m}_{1,1: 4}^{T} \\\vec{m}_{2,1: 4}^{T} \\\vec{m}_{3,1: 4}^{T}\end{array}\right)=\overrightarrow{0}\)  with  \(S_{i}=\left(\xi_{i}, \eta_{i}, \zeta_{i}, 1\right)^{T}\left(\xi_{i}, \eta_{i}, \zeta_{i}, 1\right)\)&lt;/p&gt;

&lt;p&gt;解：关于最小特征值的特征向量&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1 个自由度：解的长度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解的结构：&lt;/p&gt;

&lt;p&gt;\(M=A \cdot(R \mid \vec{t})=\left(\begin{array}{ll}\vec{m}_{1,1: 3} &amp;amp; m_{1,4} \\\vec{m}_{2,1: 3} &amp;amp; m_{2,4} \\\vec{m}_{3,1: 3} &amp;amp; m_{3,4}\end{array}\right)\) with \(\vec{m}_{1,1: 3}=\alpha^{\prime} \vec{r}_{1,1: 3}-\beta^{\prime} \cot \theta \vec{r}_{2,1: 3}+u_{0} \vec{r}_{3,1: 3}\) 
\(\begin{aligned}m_{1,4} &amp;amp;=\alpha^{\prime} t_{1}-\beta^{\prime} \cot \theta t_{2}+u_{0} t_{3} \\\vec{m}_{2,1: 3} &amp;amp;=\frac{\beta^{\prime}}{\sin \theta} \vec{r}_{2,1: 3}+v_{0} \vec{r}_{3,1: 3} \\m_{2,4} &amp;amp;=\frac{\beta^{\prime}}{\sin \theta} t_{2}+v_{0} t_{3} \\\vec{m}_{3,1: 3} &amp;amp;=\vec{r}_{3,1: 3} \\m_{3,4} &amp;amp;=t_{3}\end{aligned}\)&lt;/p&gt;

&lt;p&gt;R 是一个旋转矩阵：&lt;/p&gt;

\[\left\|\vec{r}_{1,1: 3}\right\|=1 \\  \| \vec{r}_{2,1: 3} \|=1 \\\| \vec{r}_{3,1: 3}\|=1\\\left\langle\vec{r}_{1,1: 3}, \vec{r}_{2,1: 3}\right\rangle=0 \left\langle\vec{r}_{2,1: 3,}, \vec{r}_{3,1: 3}\right\rangle=0 \left\langle\vec{r}_{3,1: 3,}, \vec{r}_{1,1: 3}\right\rangle=0\]

&lt;p&gt;由于 
\(\vec{m}_{3,1: 3}=\vec{r}_{3,1: 3}\)　
选择解决方案　
\(\left|\vec{m}_{3,1: 3}\right|^{2}=1\)
（两种可能性，检查　
\(\operatorname{det}(R)=+1）\)&lt;/p&gt;

&lt;p&gt;给定 M，我们如何推导出相机参数 R, t, α’, β’, θ, u0, v0 ？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312173958.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：Tsai 的方法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用校准标记（一般位置的标记）创建一个人工场景&lt;/li&gt;
  &lt;li&gt;测量校准标记的 3d 世界位置&lt;/li&gt;
  &lt;li&gt;制作图片&lt;/li&gt;
  &lt;li&gt;测量校准标记的 2d 图像位置&lt;/li&gt;
  &lt;li&gt;解决优化问题 估计矩阵 M&lt;/li&gt;
  &lt;li&gt;将 M 分解为 A, R, t&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;相机校准：张 Camera Calibration: Zhang&lt;/p&gt;

&lt;p&gt;假设平面上的 3d-点\(\zeta=0\)&lt;/p&gt;

&lt;p&gt;这些点由相机映射到
\(\begin{aligned}
z \cdot\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right) &amp;amp;=A \cdot\left(R \cdot\left(\begin{array}{l}
\xi \\
\eta \\
0
\end{array}\right)+\vec{t}\right) \\
&amp;amp;=\underbrace{A \cdot\left(\vec{r}_{1: 3,1}, \vec{r}_{1: 3,2}, \vec{t}\right)}_{=: H} \cdot\left(\begin{array}{l}
\xi \\
\eta \\
1
\end{array}\right)
\end{aligned}\)
H 称为单应性 H is called a homography&lt;br /&gt;
\(H=A \cdot\left(\vec{r}_{1: 3,1}, \vec{r}_{1: 3,2}, \vec{t}\right)\)
如果我们知道几个单应性$H_1,H_2…H_n$，我们能推导出来$A$吗？让我们首先考虑
\(B=A^{-T} A^{-1}\)
A是满秩的，上三角矩阵&lt;/p&gt;

&lt;p&gt;→ \(A^{-1}\) 存在并且也是上三角矩阵&lt;/p&gt;

&lt;p&gt;→ B是对称的，有 6 个不同的条目&lt;/p&gt;

&lt;p&gt;→ \(A^{-1}\) 可以通过 Cholesky 分解计算&lt;/p&gt;

&lt;p&gt;→ 如果我们知道B，我们可以很容易地推导出
\(B=\left(\begin{array}{lll}
b_{1,1} &amp;amp; b_{1,2} &amp;amp; b_{1,3} \\
b_{1,2} &amp;amp; b_{2,2} &amp;amp; b_{2,3} \\
b_{1,3} &amp;amp; b_{2,3} &amp;amp; b_{3,3}
\end{array}\right)\)&lt;/p&gt;

\[H=A \cdot\left(\vec{r}_{1: 3,1}, \vec{r}_{1: 3,2}, \vec{t}\right)\]

&lt;p&gt;R是一个旋转矩阵，因此&lt;/p&gt;

&lt;p&gt;(1)
\(\begin{aligned}
0=\left\langle\vec{r}_{1: 3,1}, \vec{r}_{1: 3,2}\right\rangle &amp;amp;=\left\langle A^{-1} \vec{h}_{1: 3,1}, A^{-1} \vec{h}_{1: 3,2}\right\rangle \\
&amp;amp;=\vec{h}_{1: 3,1}^{T} \cdot\left(A^{-T} A^{-1}\right) \cdot \vec{h}_{1: 3,2} \\
&amp;amp;=\vec{h}_{1: 3,1}^{T} \cdot B \cdot \vec{h}_{1: 3,2}
\end{aligned}\)&lt;/p&gt;

&lt;p&gt;(2)
\(\begin{aligned}
\left\langle\vec{r}_{1: 3,1}, \vec{r}_{1: 3,1}\right\rangle=1=&amp;amp;\left\langle\vec{r}_{1: 3,2}, \vec{r}_{1: 3,2}\right\rangle \\
\left\langle A^{-1} \vec{h}_{1: 3,1}, A^{-1} \vec{h}_{1: 3,1}\right\rangle &amp;amp;\left\langle A^{-1} \vec{h}_{1: 3,2}, A^{-1} \vec{h}_{1: 3,2}\right\rangle \\
\vec{h}_{1: 3,1}^{T} \cdot B \cdot \vec{h}_{1: 3,1} &amp;amp; \vec{h}_{1: 3,2}^{T} \cdot B \cdot \vec{h}_{1: 3,2} \\
\Rightarrow 0=\vec{h}_{1: 3,1}^{T} \cdot B \cdot \vec{h}_{1: 3,1}-\vec{h}_{1: 3,2}^{T} \cdot B \cdot \vec{h}_{1: 3,2}
\end{aligned}\)
因此，从一个单应性我们得到两个约束（1）,（2）&lt;/p&gt;

&lt;p&gt;如果我们知道几个单应性，我们能推导出来A吗？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从每个单应性我们得到两个约束&lt;/li&gt;
  &lt;li&gt;3 个单应性产生总共 6 个约束以估计 6 个参数&lt;/li&gt;
  &lt;li&gt;3 个单应性产生一个超定的约束系统&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;​	→ 最小二乘法找到一个使残差最小化的矩阵&lt;/p&gt;

&lt;p&gt;概述：张的方法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;估计单应性 H&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;求解优化问题以估计矩阵 B&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将 B 分解为 A, R, t&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;…&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们如何得到单应性？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312192013.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;假设平面上点的一组点对应关系&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;找到单应性使得&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

\[z \cdot\left(u_{i}, v_{i}, 1\right)^{T} \approx H \cdot\left(\xi_{i}, \eta_{i}, 1\right)^{T}\]

&lt;ol&gt;
  &lt;li&gt;一个对应产生两个约束&lt;/li&gt;
&lt;/ol&gt;

\[\begin{aligned}
&amp;amp;\vec{h}_{1,1: 3} \cdot\left(\xi_{i}, \eta_{i}, 1\right)^{T}-u_{i} \cdot \vec{h}_{3,1: 3} \cdot\left(\xi_{i}, \eta_{i}, 1\right)^{T} \approx 0 \\
&amp;amp;\vec{h}_{2,1: 3} \cdot\left(\xi_{i}, \eta_{i}, 1\right)^{T}-v_{i} \cdot \vec{h}_{3,1: 3} \cdot\left(\xi_{i}, \eta_{i}, 1\right)^{T} \approx 0
\end{aligned}\]

&lt;ol&gt;
  &lt;li&gt;最小二乘以最小化残差并找到最佳单应性H&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;概述：张的方法&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在已知位置创建一个带有校准标记的平面&lt;/li&gt;
  &lt;li&gt;制作几张平面不同位置和方向的图片&lt;/li&gt;
  &lt;li&gt;测量标记的二维图像位置&lt;/li&gt;
  &lt;li&gt;估计每张图片的单应性 H&lt;/li&gt;
  &lt;li&gt;求解 估计矩阵 B 的优化问题&lt;/li&gt;
  &lt;li&gt;将 B 分解为 A, R, t&lt;/li&gt;
  &lt;li&gt;使用非线性最小二乘法优化所有参数&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后，我们得到&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;内在参数 A&lt;/li&gt;
  &lt;li&gt;每个平面的旋转 R 和平移 t&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;Z. Zhang,
A flexible new technique for camera calibration.
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 22, no. 11,
    pp. 1330-1334, 2000  &lt;/center&gt;

&lt;p&gt;校准失真参数 k1、k2：&lt;/p&gt;

&lt;p&gt;– 非线性优化过程&lt;/p&gt;

&lt;p&gt;– 内在、外在参数和失真参数的迭代估计&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312192616.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;无畸变的效果图&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312192705.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不失真（需要更复杂的失真模型）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312192752.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;校准指示器：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;性能特点&lt;/li&gt;
  &lt;li&gt;清晰可识别&lt;/li&gt;
  &lt;li&gt;易于确定世界位置&lt;/li&gt;
  &lt;li&gt;易于在图像中高精度定位&lt;/li&gt;
  &lt;li&gt;世界上不共面的特征（对于 Tsai 的方法）&lt;/li&gt;
  &lt;li&gt;避免遮挡&lt;/li&gt;
  &lt;li&gt;避免阴影&lt;/li&gt;
  &lt;li&gt;尽可能多&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;棋盘标记&lt;/p&gt;

&lt;p&gt;​	确定图像位置，计算水平和垂直边缘的交点&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193003.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193016.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;正方形和矩形&lt;/strong&gt; - 确定图像位置，计算水平和垂直边缘的交点&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193103.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193051.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;圆&lt;/strong&gt; 确定结果椭圆的中心 - 圆心映射误差的迭代校正&lt;/p&gt;

&lt;h1 id=&quot;非标相机&quot;&gt;非标相机&lt;/h1&gt;

&lt;p&gt;远心镜头 Telecentric Lenses&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193259.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优点：– 放大倍率与物距无关 – 改善景深&lt;/p&gt;

&lt;p&gt;缺点：– 小光圈，让光线很差 – 大、重且昂贵&lt;/p&gt;

&lt;p&gt;应用领域：显微镜&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193636.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;折反射相机 = 带镜子的相机&lt;/p&gt;

&lt;p&gt;平面镜&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193708.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;– 曲面镜&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193742.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;折反射相机&quot;&gt;折反射相机&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;单视点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果所有物镜光线都在一个点相交（例如，如果镜子可以用针孔相机代替），则折反射相机具有单一视点&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312193851.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;单视点相机设置：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312194016.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20220312194039.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Feb 2022 00:00:00 +0100</pubDate>
        <link>https://wenboli-cn-de.github.io/2022/02/MV7-Optics/</link>
        <guid isPermaLink="true">https://wenboli-cn-de.github.io/2022/02/MV7-Optics/</guid>
        
        <category>专业</category>
        
        <category>机器视觉</category>
        
        
      </item>
    
  </channel>
</rss>
