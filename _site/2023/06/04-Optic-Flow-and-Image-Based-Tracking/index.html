<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking</title>
  <meta name="description" content="">
  <meta name="author" content="leopardpan">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking">
  <meta name="twitter:description" content="">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking">
  <meta property="og:description" content="">
  
  <link rel="icon" type="image/png" href="/images/favicon.png" />
  <link href="/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="https://wenboli-cn-de.github.io/2023/06/04-Optic-Flow-and-Image-Based-Tracking/">
  <link rel="alternate" type="application/rss+xml" title="高傲的电工李" href="https://wenboli-cn-de.github.io/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />


<!-- 站点统计 -->
  <script 
  async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>  


</head>


  <body>

    <span class="mobile btn-mobile-menu">        
      <div class="nav_container">
         <nav class="nav-menu-item" style = "float:right">
            <i class="nav-menu-item">
              <a href="/#blog" title="" class="blog-button">  博客主页
              </a>
            </i>
            
                <i class="nav-menu-item">

                  <a href="/archive" title="archive" class="btn-mobile-menu__icon">
                      所有文章
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/tags" title="tags" class="btn-mobile-menu__icon">
                      标签
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/about" title="about" class="btn-mobile-menu__icon">
                      关于我
                  </a>
                </i>
            
          </nav>
      </div>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <!-- 头像效果-start -->
        <div class="ih-item circle effect right_to_left">            
            <a href="/#blog" title="前往 高傲的电工李 的主页" class="blog-button">
                <div class="img"><img src="/images/avatar.jpg" alt="img"></div>
                <div class="info">
                    <div class="info-back">
                        <h2> 
                            
                                李文博
                            
                        </h2>
                        <p>
                           
                                机电 / 机器学习
                            
                        </p>
                    </div>
                </div>
            </a>
        </div>
        <!-- 头像效果-end -->
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for 高傲的电工李" class="blog-button">高傲的电工李</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">个人博客</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">欢迎来到我的个人博客</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        

        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">博客主页</a></li>
                
                  <li class="navigation__item"><a href="/archive" title="archive">所有文章</a></li>
                
                  <li class="navigation__item"><a href="/tags" title="tags">标签</a></li>
                
                  <li class="navigation__item"><a href="/about" title="about">关于我</a></li>
                
              </ul>
            </nav>
          </div>          
        </div>


        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-clear"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <head>
  <link rel="stylesheet" href="/css/post.css">
</head>

<article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title">汽车视觉 Automotive Vision - Optical Flow and Image Based Tracking</h1>
    <div class="post-meta">
      <img src="/images/calendar.png" width="20px"/> 
      <time datetime="2023-06-12 00:00:00 +0200" itemprop="datePublished" class="post-meta__date date">2023-06-12</time>  

      <span id="busuanzi_container_page_pv"> | 阅读：<span id="busuanzi_value_page_pv"></span>次</span>
    </p>
    </div>
  </header>

  
    <h2 class="post-title">目录</h2>
    <ul>
  <li><a href="#chapter-4-optical-flow-and-image-based-tracking--光流和基于图像的跟踪">Chapter 4: Optical Flow and Image Based Tracking <br /> 光流和基于图像的跟踪</a>
    <ul>
      <li><a href="#image-sequences-图像序列">Image Sequences 图像序列</a></li>
      <li><a href="#optical-flow-光流">Optical Flow 光流</a>
        <ul>
          <li><a href="#lucas-kanade-method-卢卡斯-卡纳德方法">Lucas-Kanade Method 卢卡斯-卡纳德方法</a></li>
          <li><a href="#线性近似的极限">线性近似的极限</a></li>
          <li><a href="#aperture-problem-光圈问题">Aperture Problem 光圈问题</a></li>
          <li><a href="#variational-approach-变分法">Variational Approach 变分法</a></li>
          <li><a href="#optical-flow-and-stereo-vision-光流和立体视觉">Optical Flow and Stereo Vision 光流和立体视觉</a></li>
          <li><a href="#稀疏流">稀疏流</a></li>
          <li><a href="#image-based-tracking-基于图像的跟踪">Image Based Tracking 基于图像的跟踪</a></li>
          <li><a href="#example-kernelized-correlation-filter-kcf-核化相关滤波器-kcf">Example: Kernelized Correlation Filter (KCF) 核化相关滤波器 (KCF)</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

  

  <section class="post">
    <head>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>

<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    packages: ['base', 'newcommand', 'configMacros']
  },
  svg: {
    fontCache: 'global'
  }
};
</script>

<script> 
MathJax = {
  tex: {
    inlineMath: [['$', '$']],
    processEscapes: true
  }
};
</script>

<h1 id="chapter-4-optical-flow-and-image-based-tracking--光流和基于图像的跟踪">Chapter 4: Optical Flow and Image Based Tracking <br /> 光流和基于图像的跟踪</h1>

<p><strong>References</strong></p>

<p>• B. Jähne, Digitale Bildverarbeitung, Springer, 2005, Chapter 14
• E.R. Davies, Machine Vision. Theory. Algorithms. Practicalities. Elsevier, 2005,
Section 21.6 ff
• R. Jain, R. Kasturi, B. G. Schunck, Machine Vision. McGraw Hill, 1995, Section
14.1-14.4
• B. K. P. Horn, B. G. Schunck, Determining Optical Flow. Artificial Intelligence 17,
1981, pg. 185-203
• J. F. Henriques, R. Caseiro, P. Martins, J. Batista, High-Speed Tracking with
Kernelized Correlation Filters, IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 37, no. 3, pp. 583-596, 2015</p>

<h2 id="image-sequences-图像序列">Image Sequences 图像序列</h2>

<p>到目前为止我们有：</p>
<ul>
  <li>examined single images $g(u, v)$</li>
  <li>examined stereo images $\left(g_l(u, v), g_r(u, v)\right)$</li>
</ul>

<p>图像序列：</p>

<ul>
  <li>examine a sequence of images $g(u, v, t)$</li>
  <li>观测图像随时间的变化</li>
  <li>自我运动(ego motion)引起的变化</li>
  <li>观察物体运动引起的变化</li>
</ul>

<h2 id="optical-flow-光流">Optical Flow 光流</h2>

<p>光流是由相机和观察对象之间的相对运动引起的图像中任何点的明显移动</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203147.png" alt="" /></p>

<p>– 密集流：我们确定图像中每个点的流矢量
– 稀疏流：我们仅为（一小部分）显着点（例如特征点）确定流向量</p>

<p><strong>Typical Optical Flow Fields 典型光流场</strong></p>

<p>道路上的预期流</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203326.png" alt="" /></p>

<p>假设：</p>
<ul>
  <li>光照是恒定的。</li>
  <li>目标点没有被遮挡。</li>
</ul>

<p>光流的必要条件：</p>

\[g(u, v, t)=g(u+\Delta u, v+\Delta v, t+\Delta t)\]

<ul>
  <li>必要但不充分。</li>
  <li>不够清晰</li>
</ul>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203515.png" alt="" /></p>

<p><strong>运动约束方程：</strong></p>

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

<p>– 偏导数从何而来？</p>

<p>使用导数滤波器掩模（例如Sobel）进行滤波会产生$\frac{\partial g}{\partial u}, \frac{\partial g}{\partial v}$</p>

<p>灰度值差异产生 $\frac{\partial g}{\partial t} \approx g(u, v, t+1)-g(u, v, t)$</p>

<p>一维信号的图示：</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614203815.png" alt="" /></p>

<p><strong>运动约束方程：</strong></p>

\[-\frac{\partial g}{\partial t}=\Delta u \cdot \frac{\partial g}{\partial u}+\Delta v \cdot \frac{\partial g}{\partial v}\]

<p>– 问题：一个方程，两个未知变量
– 附加假设：光流在局部环境中是恒定的。</p>

\[\begin{aligned}
-\frac{\partial g(u, v, t)}{\partial t} &amp; \approx \Delta u \cdot \frac{\partial g(u, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v, t)}{\partial v} \\
-\frac{\partial g(u-1, v, t)}{\partial t} &amp; \approx \Delta u \cdot \frac{\partial g(u-1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u-1, v, t)}{\partial v} \\
-\frac{\partial g(u+1, v, t)}{\partial t} &amp; \approx \Delta u \cdot \frac{\partial g(u+1, v, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u+1, v, t)}{\partial v} \\
-\frac{\partial g(u, v-1, t)}{\partial t} &amp; \approx \Delta u \cdot \frac{\partial g(u, v-1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v-1, t)}{\partial v} \\
-\frac{\partial g(u, v+1, t)}{\partial t} &amp; \approx \Delta u \cdot \frac{\partial g(u, v+1, t)}{\partial u}+\Delta v \cdot \frac{\partial g(u, v+1, t)}{\partial v}
\end{aligned}\]

<h3 id="lucas-kanade-method-卢卡斯-卡纳德方法">Lucas-Kanade Method 卢卡斯-卡纳德方法</h3>

<blockquote>
  <p>在计算机视觉中，卢卡斯-卡纳德方法是一种广泛使用的<strong>光流估计的差分方法</strong>，这个方法是由Bruce D. Lucas和Takeo Kanade发明的。<strong>它假设光流在像素点的邻域是一个常数，然后使用最小平方法对邻域中的所有像素点求解基本的光流方程</strong></p>

  <p>通过结合几个邻近像素点的信息，卢卡斯-卡纳德方法(简称为L-K方法)<strong>通常能够消除光流方程里的多义性</strong>。而且，与逐点计算的方法相比，<strong>L-K方法对图像噪声不敏感</strong>。不过，由于这是一种局部方法，所以在图像的均匀区域内部，<strong>L-K方法无法提供光流信息</strong>。</p>
</blockquote>

<p>可以通过最小化二次误差来估计光流</p>

\[\begin{aligned}
\operatorname{minimize}_{\Delta u, \Delta v} \sum_{(i, j) \in\{-1,0,1\}^2}\left(\frac{\partial g(u+i, v+j, t)}{\partial t}\right. &amp; +\Delta u \cdot \frac{\partial g(u+i, v+j, t)}{\partial u} \left.+\Delta v \cdot \frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

<p>在推导后并置零:</p>

\[\begin{aligned}
\left(\begin{array}{ll}
G_{u u} &amp; G_{u v} \\
G_{u v} &amp; G_{v v}
\end{array}\right)\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \quad \text { with } G_{u u} &amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
G_{u v} &amp; =\sum\left(\frac{\partial g(u+i, v+j, t) \partial g(u+i, v+j, t)}{\partial v}\right) \\
G_{v v} &amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2 \\
G_{u t} &amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial t}\right) \\
G_{v t} &amp; =\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v} \frac{\partial g(u+i, v+j, t)}{\partial t}\right)
\end{aligned}\]

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204331.png" alt="" />
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204345.png" alt="" />
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png" alt="" /></p>

<p>编码：
• 饱和度（saturation）= 向量长度
• 色调（hue）= 方向</p>

<h3 id="线性近似的极限">线性近似的极限</h3>

<p>线性近似不足以进行较大的偏移</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204456.png" alt="" /></p>

<p>– 也可以使用迭代计算（牛顿法）确定光流</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204518.png" alt="" />
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204527.png" alt="" />
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614204416.png" alt="" /></p>

<p>编码：
• 饱和度（saturation）= 向量长度
• 色调（hue）= 方向</p>

<h3 id="aperture-problem-光圈问题">Aperture Problem 光圈问题</h3>

<p>除了可以使用迭代的Lucas Granada方法解决的问题外，还存在另一个问题，称为光圈问题（aperture problem），它会给Lucas Granada方法带来麻烦。让我们进行一个实验，假设有一个场景，我们只能通过百叶窗中的一个小孔来看到，这意味着整个场景可以被视为相机的镜头，百叶窗则可以被视为相机内部的百叶窗。因此，我们只能看到世界的一个小区域，在我们的实验中，我们感知到的这个小区域有一些白色背景和一些黑色物体，这些物体最初只出现在孔的左边界上。现在这个物体进行了一次移动，我们来看一下。</p>

<p>最后，物体以某种方式移动了，问题是我们观察到了哪种运动？显然，物体似乎是从左向右移动的，但这是完整的事实吗？我们能够唯一确定这个运动吗？</p>

<p>为了回答这个问题，让我们看一下百叶窗的背面，看看实际发生了什么。</p>

<p>在这里，我们可以看到我们实验的初始情况。现在我们开始这个运动，我们可以看到这个运动不仅仅是从左到右，而是沿着对角线方向的运动，因此还涉及到垂直运动，这是我们在示例中无法看到的。这个例子表明，我们可以感知到运动的部分，但无法完全感知到整个运动，在某些情况下。让我们稍微改变一下我们的例子，在这个例子中，我们改变了我们看到的物体的形状，现在我们再次进行运动，我们清楚地看到这是一个沿对角线方向的运动。因此，虽然场景只稍微改变，但完整的运动变得明显起来，那么这两个例子之间的区别是什么？在第一个例子中，我们只能观察到一个灰度值的边缘，而在第二个例子中，我们可以观察到一个灰度值的角落，这就产生了重要的区别。如果我们能观察到一个角落，我们就能确定完整的运动，如果我们只能观察到一个边缘，我们只能观察到运动的部分。</p>

<p>我们看到什么样的运动？</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/03832927-14d5-495f-b065-cff87f9ea7ab.gif" alt="" /></p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/0963d66a-dabc-413f-a168-328f524f8e54.gif" alt="" /></p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/8ced9aa5-60e4-415e-ae86-fe9f085c179e.gif" alt="" /></p>

<p>那么什么情况下可以解决Lucas-Kanade方法呢？
如果我们观察公式，我们可以看到涉及一个2x2矩阵，其中包含一些偏导数。当矩阵G具有满秩时，我们可以得到线性方程组的唯一解。
如果它的秩只有1，我们可能得到一组解，也就是说我们没有唯一解；
如果这个矩阵的秩为零，那么所有可能的向量或光流向量都满足这个矩阵，这意味着所有向量都能解决这个方程，我们就无法得到Lucas-Kanade的唯一解。
重要的性质是矩阵G具有满秩，因此它是可逆的。
如果满足条件，我们就能得到唯一解。这适用于当这个矩阵的两个特征值都大于零且远大于零时。</p>

<p>需要强调的是，这种矩阵始终具有两个实特征值，并且它们都是非负的，但重要的是它们不等于零，也不接近零，而是远离零。如果这两个特征值都满足条件，那么矩阵G是可逆的，并且这种反转也对相机图像中的随机影响具有稳定性。</p>

\[\begin{aligned}
&amp; \underbrace{\left(\begin{array}{ll}
G_{u u} &amp; G_{u v} \\
G_{u v} &amp; G_{v v}
\end{array}\right)}_{=: G}\left(\begin{array}{c}
\Delta u \\
\Delta v
\end{array}\right)=-\left(\begin{array}{l}
G_{u t} \\
G_{v t}
\end{array}\right) \\
&amp; G_{u u}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u}\right)^2 \\
&amp; G_{u v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial u} \frac{\partial g(u+i, v+j, t)}{\partial v}\right) \\
&amp; G_{v v}=\sum\left(\frac{\partial g(u+i, v+j, t)}{\partial v}\right)^2
\end{aligned}\]

<ul>
  <li>矩阵 G 是可逆的</li>
  <li>G 的特征值都近似相等且 &gt; 0</li>
</ul>

<p>那么什么情况下会发生这种情况呢？</p>

<ul>
  <li>
    <p>如果我们观察均匀区域，我们会发现矩阵G的元素几乎都等于零，如果它们都等于零，特征值将是0和0，这意味着我们无法得到唯一解，这是一个糟糕的情况。</p>
  </li>
  <li>
    <p>另一个糟糕的情况是灰度边缘，无论是水平还是垂直的边缘，在这种情况下，矩阵G有两个特征值，其中一个是零或接近零，另一个与零不同，对于所有灰度边缘（包括对角线边缘等），都是如此。
这也是我们无法得到Lucas-Kanade方法唯一解的情况。然而，正如我们所见，该方法仍然能够揭示关于运动的一些信息，但不是全部信息。</p>
  </li>
  <li>
    <p>在灰度角点的情况下，我们通常会得到两个不为零的特征值，因此这是一个好的情况。</p>
  </li>
  <li>
    <p>同样地，如果我们处理孤立点，我们会得到与零不同的特征值，所以这也是一个好的情况。这个思想类似于Stephen Harris角点检测器，并且在位移计算中也可以找到。基本思想仍然是相同的。</p>
  </li>
</ul>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211225.png" alt="" /></p>

<h3 id="variational-approach-变分法">Variational Approach 变分法</h3>

<p>由于我们面临着获取满秩矩阵G的问题，我们可能会问，我们计算矩阵G时应该考虑多大的环境范围。
我们只应该考虑像素感兴趣的直接邻居，还是应该考虑间接邻居？
我们应该考虑多少像素？我们可以一般性地增加环境的面积，也可以减小它。
那么最好的做法是什么呢？如果我们选择一个非常小的环境，很明显，我们很可能遇到我们刚刚看到的问题，也就是所谓的光圈问题。在这种情况下，矩阵G的秩不满，我们无法得到唯一解，因为环境中没有足够的纹理、结构，这使我们无法观察到完整的运动。</p>

<p>因此，我们可能会提出这样的问题：为什么不使用较大的环境来计算这个大写字母G呢？
然而，如果我们选择一个非常大的环境，我们可能会遇到其他问题。
当然，环境越大，我们需要进行所有计算的计算时间就越长。
更重要的是，如果我们选择了大的环境，我们可能会将不同物体的运动混淆在一起，因为在大的环境中，很可能我们不只观察到一个单独的物体，而是可能观察到几个不同的物体，它们以不同的方式运动。
因此，我们计算出的是几个物体不同运动方式的混合。</p>

<p>因此，这两种选择都不是最佳的，我们可能需要在这两个思想之间做出一些平衡。</p>

<p>这些方法的优点是我们可以获得几乎所有图像像素的光流向量。然而，缺点是需要大量计算来解决这些大规模优化问题，因此无法实时运行，只适用于批量处理记录的图像。这些方法更适合于批量处理记录的图像。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614211701.png" alt="" /></p>

<p>霍恩和肖克最初的方法奠定了变分方法的基础。</p>

<p><strong>变分方法：假设光流在相邻像素中相似。</strong></p>

<p>在变分方法中，基本思想是根据环境的特性进行自适应选择。如果处于均匀区域，可能需要选择较大的环境；如果处于纹理丰富的区域，可能更倾向于选择较小的环境。这是一种基本的思路，如何表达这个思想并使其更加普适呢？</p>

<p>早在上世纪80年代，Horn和Schunck提出了一套基于变分方法的光流计算方法，后来的一系列方法都是基于这个思路。这些方法的基本思想是，不是单独估计每个点或单个点的光流向量，而是并行估计所有像素点的光流向量，并建立一个大规模的优化问题，将相邻像素的光流向量之间建立关系。通过这种方式，避免了对环境的特定选择，使其更加灵活。</p>

<p>具体来说，假设我们有一幅灰度图像，包含一组像素点。对于每个像素点，我们可以推导出运动约束方程，该方程建立了像素点的灰度值和光流向量之间的关系。我们假设相邻像素的光流向量是相似的，它们可能是相等的，或者至少在像素之间变化不大。我们通过一个条件来表达这种相似性，即希望相邻像素的光流向量之间的差异接近于零。</p>

<p>现在，我们有了一组从运动约束方程得出的条件，以及确定相邻光流向量相似性的条件。我们可以基于这些条件建立一个大规模的优化问题，然后使用数值方法来解决这个优化问题，以并行地找到所有像素点的光流向量。这里不详细介绍具体的方法，只是介绍了这个基本思路。</p>

<p>这些方法的优点是可以为几乎所有像素点计算光流向量，缺点是需要大量计算来解决这些大规模的优化问题，因此无法实时工作，只适用于批量处理记录的图像或视频。</p>

<p>如果想了解更详细的信息，请参考提供的参考文献，其中介绍了变分方法在光流计算中的基本原理和扩展。当然，Horn和Schunck的方法已经不再是最新技术，现在有许多对这种方法进行了改进并获得更好结果的扩展方法。不过，让我们先看一下Horn和Schunck方法的结果，以了解这些变分方法的工作原理。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212309.png" alt="" /></p>

<p>然而，当今已经有很多对这种方法的扩展，比基本的霍恩和肖克方法表现更好。
不过，让我们看一下霍恩和肖克的结果，以了解这些变分方法是如何工作的。
我们从之前使用卢卡斯-卡纳达方法的示例开始，然后应用霍恩和肖克的方法，经过长时间的计算后，我们得到下面的结果。</p>

<p>我们可以看到，现在光流向量的估计比之前要好得多，尽管仍然存在一些估计错误和箭头状的伪影，但整体估计效果更好。我们还可以看到，平均光流向量的长度比卢卡斯-卡纳达方法更大，并且相邻像素更可能具有相似的光流向量，因为这是变分方法中引入的内容。</p>

<p>基于变分方法的解决方案：</p>

<ul>
  <li>变分优化问题，类似于随机场</li>
  <li>数值迭代计算</li>
  <li><strong>无法实时运行</strong>！</li>
  <li>有关详细信息，请参考提供的参考资料</li>
</ul>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614212943.png" alt="" /></p>

<h3 id="optical-flow-and-stereo-vision-光流和立体视觉">Optical Flow and Stereo Vision 光流和立体视觉</h3>

<p><strong>光流计算 ≈ 立体视觉的对应问题</strong></p>

<p>总结一下光流计算，我们已经了解了一些光流计算方法。
在之前的章节中，我们介绍了双目视觉，在双目视觉中，我们也面临着类似的问题，即我们想计算两幅图像中某个点的像素位置之间的关系，因此我们有了对应问题。</p>

<p>虽然光流计算与双目重建不同，但我们仍然可以认为这两个问题之间存在密切的联系。
在光流问题中，我们比较图像序列中的图像，而在双目视觉中，我们比较立体图像对。
在光流计算中，我们希望获得两个对应点之间的矢量，而在双目视觉中，我们希望计算视差，也可以将其解释为矢量。</p>

<p>因此，我们确定了一些可能的方法。</p>

<p>例如，可以使用<em>运动约束方程进行光流计算，但如果需要的话，也可以用于双目重建</em>。
<strong>变分方法</strong>主要用于光流计算，但也有非常类似的变分方法用于立体重建。
<strong>极线几何</strong>是在双目视觉背景下引入的概念，但也可以用于光流计算。
<strong>块匹配</strong>也是用于双目重建的方法，但也可以用于光流计算。
当然，特征点方法也可用于两个问题，至少可以用于获取稀疏光流或稀疏视差。</p>

<p>可能的方法（适用于两者）包括：</p>

<ul>
  <li>运动约束方程</li>
  <li>变分方法</li>
  <li>极线几何</li>
  <li>块匹配/相关过程</li>
  <li>特征点方法</li>
</ul>

<h3 id="稀疏流">稀疏流</h3>

<p>为了说明特征点方法的有用性，这里有一个标准图像序列的示例。我使用SURF特征点为两幅图像创建了特征点，并连接那些相互匹配的特征点对。结果如下图所示，每条黄线表示一个光流矢量，我们可以看到大多数光流矢量是有意义的。当然，右上角存在一些特征点连接不合理的伪影，导致了一些奇怪的光流，我们并不期望这种情况发生。当然，汽车部分也产生了一些奇怪的光流，这也是我们所预期的。然而，总体结果还是相当不错的。当然，这只是对于光流的稀疏估计，我们并没有获得每个像素的光流，但至少对于那些获得光流的像素，结果还是相当好的。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614213941.png" alt="" /></p>

<h3 id="image-based-tracking-基于图像的跟踪">Image Based Tracking 基于图像的跟踪</h3>

<p>在许多应用中，不需要计算每个像素的光流矢量，而是只对跟踪物体感兴趣，也就是确定属于某个特定物体的像素的光流。我们希望为整个物体获取一个单一的光流矢量。我们假设我们使用某种物体检测器，在第一帧中提供了一个感兴趣区域（ROI）。基于此，我们希望在整个视频序列中跟踪这个区域。我们假设我们不知道当前检测到的是什么物体，可能是汽车、人或动物等，我们只是想能够在整个视频中跟踪这个物体。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214319.png" alt="" /></p>

<p>这里有一个例子，仅包含了一系列图像中的四个图像。我们可以看到几个物体。假设在第一幅图像中，物<em>体检测器给出了三个感兴趣区域，用红色、绿色和蓝色矩形表示</em>。我们的任务是在随后的图像中再次找到这些物体，并确定相应的感兴趣区域。
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214155.png" alt="" />
<strong>解决这个问题的基本思路如下</strong>：</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614214514.png" alt="" /></p>

<p>从第一幅图像中，我们获取了对感兴趣物体的一些信息，即我们对物体的外观有一些概念。我们可以将这个外观作为该物体的模板，即我们只需将图像中的这个矩形区域作为模板。</p>

<p>然后在下一幅图像中，我们可以搜索相同的模板出现的位置。我们将该区域在整个图像上进行移动，对于每个位置，我们检查模板是否与图像中所见的内容匹配，并确定相似度的度量。在这种情况下，我们可能发现在这里显示的第一个区域的左侧区域不匹配，因此模板与该区域的内容的相似度非常低，而在右侧的另一个模板中，模板与图像内容的相似度相对较高。我们可以将其视为一种块匹配，再次比较图像的感兴趣区域的灰度值，并尝试找到最佳匹配。一旦我们找到了最佳匹配，我们就知道这个物体在第二幅图像中最有可能再次出现的位置。</p>

<p>现在，我们可以利用这第二幅图像，因为我们知道同一物体在第二幅图像中的位置，我们可以得到显示相同物体（或至少可能是相同物体）的第二个感兴趣区域。现在，我们可以使用第一幅图像和第二幅图像的两个感兴趣区域，并以最佳方式调整模板，使其适应两者。</p>

<p>这样就得到了一个适应的模板。有了这个适应的模板，我们可以进入第三幅图像，并根据最佳匹配搜索第三幅图像中最合适的区域。基于这个最佳匹配，我们可以再次调整模板以适应新找到的感兴趣区域的外观。</p>

<p>通过这样的步骤，我们可以逐步变得越来越好，以确定代表这种物体的良好模板。</p>

<p><strong>基于图像的跟踪：超越块匹配 Beyond Block Matching</strong></p>

<p>因此，创建模板并将其与图像块进行比较的方法既可以视为一种块匹配，也可以以不同的方式处理，并将其解释为分类任务。也就是说，我们想要搜索特定类别的物体，这些分类器通常使用一些示例图像进行训练。</p>

<p>在我们的情况下，我们从一个正例图像开始，即来自图像序列中的第一幅图像的感兴趣区域，然后我们选择一些其他图像块作为负例。一旦我们在第二幅图像中找到了感兴趣区域，我们可以将第二幅图像中的感兴趣区域视为第二个训练示例，用于训练专门针对相关对象类别的分类器，通过这种方式我们可以不断进行下去。</p>

<p>因此，我们对模板匹配使用可训练的分类器。参加过机器视觉或相关模式识别讲座的人可能已经对我们可以使用哪些分类器有一些了解，例如人工神经网络、支持向量机、决策树等等。在我们这里，我们将坚持支持向量机的思想，但不使用纯粹的支持向量机，而是经过改进的某种机器。</p>

<h3 id="example-kernelized-correlation-filter-kcf-核化相关滤波器-kcf">Example: Kernelized Correlation Filter (KCF) 核化相关滤波器 (KCF)</h3>

<p>这导致了一种被称为核化相关滤波器的方法。相关滤波器让我们想起了块匹配方法，而核化则提醒我们支持向量机的思想，因为这些方法的基本思想是将一种块匹配与核化相结合。</p>

<p>在这种情况下，训练示例的创建如下所示：
<img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/20230614215729.png" alt="" /></p>

<p>假设我们在最初的图像中的感兴趣区域显示了这个骑自行车的补丁，然后我们将这个补丁复制并填充整个平面。此外，我们创建了一种类似原始补丁大小的标签图像，这个标签图像的值介于0和1之间。中心点的值为1，在边界处的值为0，两者之间的值从1递减。然后我们创建一组训练示例，第一个示例是从原始图像补丁和相应的标签创建的，标签的值是标签图像中心处的值。然后，我们围绕原始图像补丁转动这个红色矩形，并以相同的方式转动用于确定相应训练示例标签的标签图像中的点。当然，标签不仅仅是0和1，这是纯粹分类任务的预期，而是介于0和1之间的实数。因此，这些标签在某种程度上告诉我们一个正确示例的级别，我们就是这样创建训练示例的。对于你所看到的红色矩形的每个位置，我们创建一个训练示例。之后，我们可能会在灰度图像或彩色图像上计算一些之前计算的特征，并将其应用于这些灰度图或者彩色图。</p>

<p>之后，我们可能会在灰度图像或彩色图像上计算一些特征，并将其应用于这些训练示例，而不是直接使用颜色或灰度值。之前参加过机器视觉讲座的人会了解到一些特征，例如HOG特征或LBP特征，这些特征也可以用来创建训练示例，而不是直接使用原始图像数据。</p>

<p>然后，我们应用一个分类器，它类似于支持向量机，但不完全是支持向量机。在我们的情况下，可以使用快速傅里叶变换以高效地进行训练，因此这种训练只需现代计算机上的10到20毫秒，可以实时进行。这样，我们就训练出了一个分类器，现在我们可以在下一幅图像中搜索适当的最佳匹配。在这种的情况下，也可以使用快速傅里叶变换来实现这一点，从而获得非常快速的响应时间。</p>

<hr />
<p><strong>Example: Tracking with Occlusions 使用遮挡进行跟踪</strong></p>

<p>是的，我们在获取新图像时逐步更新模板。在这里，我们可以看到核化相关滤波方法的一个例子，它通过一种额外的技术扩展以处理遮挡。这是我们团队中Weitian的工作成果。让我们开始视频，我们可以看到这种方法跟踪了一个骑自行车的人，即使自行车被汽车遮挡，它仍然能够跟踪。这里的思路是分析物体的哪些部分仍然可见，然后在这个可见区域上初始化第二个核化相关滤波器，可见区域显示为绿色。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/bb28588d-b509-4bcd-bfd6-94c43a518c5d.gif" alt="" /></p>

<hr />
<p><strong>Example: Tracking in Fog 雾中跟踪</strong></p>

<p>让我们看另一个示例视频，在右下方的图像中，你可以看到初始情况，绿色矩形定义了一开始提供的感兴趣区域，很难确定我们实际上正在跟踪的是什么。如果你看左上方的图像，也显示相同的图片，我们可以看到有些东西，但很难说那是什么，即使我们放大并查看右上方的图像，我们几乎无法确定我们真正看到了什么，只有一些与周围的雾有些不同的深灰色区域。然而，让我们启动这个核化相关滤波器来跟踪物体。</p>

<p>现在我们可以看到物体的真正是什么，即一辆汽车。然而，从第一幅图像来看，几乎不可能确定这确实是一辆车，因此在第一幅图像中，车辆检测器无法确定这是一辆车，但我们仍然能够跟踪它，这真的很有趣。</p>

<p><img src="https://raw.githubusercontent.com/WenboLi-CN-DE/Picture/main/d96751c9-e29a-4f87-baf7-87295e60fa47.gif" alt="" /></p>

<hr />

<p>现在让我们总结一下光流计算和基于图像的跟踪这一章节。我们开始讨论光流，介绍了光流的基本概念，推导了运动约束方程，并基于此引入了Lucas-Kanade方法。然后，我们更详细地分析了Lucas-Kanade方法，推导了光圈问题，并介绍了变分流计算方法的一些基本思想。</p>

<p>对于基于图像的跟踪，我们引入了模板匹配的思想和核化相关滤波器作为一种有用且实时可行的方法来实现这种模板匹配思想，用于真实图像序列。</p>

<p>今天就到这里，谢谢大家的聆听。</p>

  </section>

</article>

<section>


            <script type="text/javascript">
            function dashangToggle(){
              $(".hide_box-play").fadeToggle();
              $(".shang_box-play").fadeToggle();
            }
            </script>

            <div style="text-align:center;margin:50px 0; font:normal 14px/24px 'MicroSoft YaHei';"></div>

            <style type="text/css">
              .content-play{width:80%;margin-top: 20px;margin-bottom: 10px;height:40px;}
              .hide_box-play{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
              .shang_box-play{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
              .shang_box-play img{border:none;border-width:0;}
              .dashang{display:block;width:100px;margin:5px auto;height:25px;line-height:25px;padding:10px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
              .dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
              .shang_close-play{float:right;display:inline-block;
                margin-right: 10px;margin-top: 20px;
              }
              .shang_logo{display:block;text-align:center;margin:20px auto;}
              .shang_tit-play{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;background: url('/images/payimg/cy-reward-title-bg.jpg');font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
              .shang_tit-play p{color:#a3a3a3;text-align:center;font-size:16px;}
              .shang_payimg{width:140px;padding:10px;padding-left: 80px; /*border:6px solid #EA5F00;**/margin:0 auto;border-radius:3px;height:140px;display:inline-block;}
              .shang_payimg img{display:inline-block;margin-right:10px;float:left;text-align:center;width:140px;height:140px; }
              .pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
              .shang_payselect{text-align:center;margin:0 auto;margin-top:40px;cursor:pointer;height:60px;width:500px;margin-left:110px;}
              .shang_payselect .pay_item{display:inline-block;margin-right:140px;float:left;}
              .shang_info-play{clear:both;}
              .shang_info-play p,.shang_info-play a{color:#C3C3C3;text-align:center;font-size:12px;text-decoration:none;line-height:2em;}
            </style>

       <ul class="pager">
        
        <li class="previous">
            <a href="/2023/06/02-BinocularVision/" data-toggle="tooltip" data-placement="top" title="汽车视觉 Automotive Vision - Binocular Vision / Stereo Vision 双目视觉/立体视觉">上一篇：  <span>汽车视觉 Automotive Vision - Binocular Vision / Stereo Vision 双目视觉/立体视觉</span>
            </a>
        </li>
        
        
        <li class="next">
            <a href="/2023/06/06-SLAM/" data-toggle="tooltip" data-placement="top" title="汽车视觉 Automotive Vision - SLAM">下一篇：  <span>汽车视觉 Automotive Vision - SLAM</span>
            </a>
        </li>
        
    </ul>
</section>


<section class="post-comments">

    <script>

        setInterval(function () 
        {
            var box = document.querySelector(".trc_rbox_container");
            if(box) box.outerHTML = "";
        }, 2000);
        
    </script>

<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81NTIzMy8zMTcwMA==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


</section>


            <section class="footer">
    <footer>
        <div class = "footer_div">  
        <nav class="cover-navigation navigation--social">
          <ul class="navigation">

          
          <!-- Github -->
          <li class="navigation__item_social">
            <a href="https://github.com/WenboLi-CN-DE" title="@WenboLi-CN-DE 的 Github" target="_blank">
              <div class="footer-social-icon" style="background:url(/images/github.png);"></div>
            </a>
          </li>
          

          

          

          

          

          
          


          
          <!-- Email -->
          <li class="navigation__item_social">
            <a href="mailto:lwb_010@163.com" title="Contact me">
              <div class="footer-social-icon" style="background:url(/images/email.png);"></div>
            </a>
          </li>
          
          
          <!-- RSS -->
          <li class="navigation__item_social">
            <a href="/feed.xml" rel="author" title="RSS" target="_blank">
              <div class="footer-social-icon" style="background:url(/images/rss.png);"></div>
              <span class="label">RSS</span>
            </a>
          </li>

          </ul>
        </nav>

        </div>

        <div class = "footer_div">  
           <p class="copyright text-muted">
            Copyright &copy; 高傲的电工李 2023 Theme by <a href="https://leopardpan.cn/">leopardpan</a> |
            <iframe
                style="margin-left: 2px; margin-bottom:-5px;"
                frameborder="0" scrolling="0" width="91px" height="20px"
                src="https://ghbtns.com/github-btn.html?user=leopardpan&repo=leopardpan.github.io&type=star&count=true" >
            </iframe>
            </p>
        	<div align="right">
    			<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

          <!-- 访问统计 -->
          <span id="busuanzi_container_site_pv">
            本站总访问量
            <span id="busuanzi_value_site_pv"></span>次
          </span>

        </div>
        <div>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



    
  </body>

</html>
